{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "527f544a-cf31-4d61-abb9-ce28a7edc549",
      "metadata": {
        "id": "527f544a-cf31-4d61-abb9-ce28a7edc549"
      },
      "source": [
        "## load library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1467d0-3460-45ee-859b-365907bfcdde",
      "metadata": {
        "id": "7d1467d0-3460-45ee-859b-365907bfcdde"
      },
      "outputs": [],
      "source": [
        "#python\n",
        "import random\n",
        "from tqdm import tqdm, trange,notebook\n",
        "import argparse\n",
        "import json\n",
        "import pickle\n",
        "import re\n",
        "import collections\n",
        "import wandb\n",
        "\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#tokenizer\n",
        "from konlpy.tag import Mecab\n",
        "from nltk import FreqDist\n",
        "\n",
        "#embedding\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from rank_bm25 import BM25Okapi,BM25L,BM25Plus\n",
        "\n",
        "#numpy\n",
        "import numpy as np\n",
        "\n",
        "#pandas\n",
        "import pandas as pd\n",
        "\n",
        "#dataset\n",
        "\n",
        "from datasets import load_dataset,load_from_disk,load_metric,DatasetDict,Dataset,Features,Value,concatenate_datasets,Sequence\n",
        "\n",
        "#transformer\n",
        "\n",
        "from transformers import AutoTokenizer,AutoConfig, EvalPrediction, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
        "from transformers import BertModel, BertPreTrainedModel,AdamW,get_linear_schedule_with_warmup,BertTokenizerFast,ElectraTokenizerFast\n",
        "\n",
        "#utility\n",
        "\n",
        "from trainer_qa import QuestionAnsweringTrainer\n",
        "from utils_qa import postprocess_qa_predictions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "38dc83ba-09d1-428f-bec9-8cf3aa6c0d47",
      "metadata": {
        "id": "38dc83ba-09d1-428f-bec9-8cf3aa6c0d47"
      },
      "source": [
        "## hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34196821-ac06-4f04-9202-be3beeb21eda",
      "metadata": {
        "id": "34196821-ac06-4f04-9202-be3beeb21eda"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 384 # 질문과 컨텍스트, special token을 합한 문자열의 최대 길이\n",
        "max_length = 384\n",
        "pad_to_max_length = True\n",
        "doc_stride = 128 # 컨텍스트가 너무 길어서 나눴을 때 오버랩되는 시퀀스 길이\n",
        "max_train_samples = 16\n",
        "max_val_samples = 16\n",
        "preprocessing_num_workers = 4\n",
        "batch_size = 8\n",
        "num_train_epochs = 1\n",
        "n_best_size = 20\n",
        "max_answer_length = 30\n",
        "data_collator = default_data_collator\n",
        "dense_batch_size = 16\n",
        "k = 20\n",
        "save_strategy='no'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9a5ae6b2-94c1-4a9d-b3a4-741811c5c104",
      "metadata": {
        "id": "9a5ae6b2-94c1-4a9d-b3a4-741811c5c104"
      },
      "source": [
        "## fixed seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf19aba3-ccb5-4e53-b81b-952c3d8ad279",
      "metadata": {
        "id": "bf19aba3-ccb5-4e53-b81b-952c3d8ad279"
      },
      "outputs": [],
      "source": [
        "#torch seed\n",
        "torch.manual_seed(30)\n",
        "torch.cuda.manual_seed(30)\n",
        "\n",
        "#numpy seed\n",
        "np.random.seed(30)\n",
        "\n",
        "#python seed\n",
        "random.seed(30)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "193bc831-ffd3-44c1-9ae9-774fb103bd8a",
      "metadata": {
        "id": "193bc831-ffd3-44c1-9ae9-774fb103bd8a"
      },
      "source": [
        "## read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb86f94-0346-4c6d-aed6-f8622f9826d3",
      "metadata": {
        "id": "cbb86f94-0346-4c6d-aed6-f8622f9826d3",
        "outputId": "10fe4987-8206-4dfa-db31-7a8a6847b463"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
          ]
        }
      ],
      "source": [
        "datasets_base = load_from_disk(\"input/data/data/train_dataset\")\n",
        "datasets_korquad = load_dataset(\"squad_kor_v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c430cb5-972b-4d9f-9d44-91002639d422",
      "metadata": {
        "id": "5c430cb5-972b-4d9f-9d44-91002639d422",
        "outputId": "65ff409e-764c-4a97-8847-6e974323264d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
              "        num_rows: 3952\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
              "        num_rows: 240\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 189,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f00b706-14e3-49af-9cd7-2df2237906ff",
      "metadata": {
        "id": "5f00b706-14e3-49af-9cd7-2df2237906ff",
        "outputId": "fcbff517-b1d3-4609-c2c5-be8944c1bf13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 60407\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 5774\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 190,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets_korquad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9415dee-4ab3-4e3e-9002-7bb036e610d1",
      "metadata": {
        "id": "d9415dee-4ab3-4e3e-9002-7bb036e610d1"
      },
      "outputs": [],
      "source": [
        "# train & valid set\n",
        "train_datasets_base = datasets_base['train']\n",
        "train_datasets_korquad = datasets_korquad['train']\n",
        "valid_datasets_base = datasets_base['validation']\n",
        "valid_datasets_korquad = datasets_korquad['validation']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "250d6a58-1151-4cb0-a8bc-2f22e8b823ce",
      "metadata": {
        "id": "250d6a58-1151-4cb0-a8bc-2f22e8b823ce"
      },
      "source": [
        "## prepare ai hub dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2968b4c-2d34-45b9-aa25-b27c9ab8ff56",
      "metadata": {
        "id": "e2968b4c-2d34-45b9-aa25-b27c9ab8ff56"
      },
      "outputs": [],
      "source": [
        "#read ai hub data\n",
        "\n",
        "with open('ko_nia_normal_squad_all.json' , 'r', encoding='utf-8') as f:\n",
        "    dataset_koquad = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0c9fc6-ff21-4e78-bacf-5c891f98231e",
      "metadata": {
        "id": "8b0c9fc6-ff21-4e78-bacf-5c891f98231e"
      },
      "outputs": [],
      "source": [
        "dataset_koquad = dataset_koquad['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77575ebd-a6fa-44bc-a492-287e02da1fa1",
      "metadata": {
        "id": "77575ebd-a6fa-44bc-a492-287e02da1fa1",
        "outputId": "9d99a644-c3c4-413f-a018-946505ffac96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47314"
            ]
          },
          "execution_count": 196,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_koquad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47374cd3-7afc-4f73-b8ea-8dae215ea2ee",
      "metadata": {
        "id": "47374cd3-7afc-4f73-b8ea-8dae215ea2ee"
      },
      "outputs": [],
      "source": [
        "#first preprocess ai hub dataset\n",
        "\n",
        "data_list = []\n",
        "\n",
        "data_dict = {}\n",
        "\n",
        "\n",
        "for data in dataset_koquad:\n",
        "    \n",
        "    context = data['paragraphs'][0]['context']\n",
        "    \n",
        "    for qna in data['paragraphs'][0]['qas']:\n",
        "        \n",
        "        answers = {}\n",
        "        \n",
        "        question = qna['question']\n",
        "        answer = qna['answers'][0]\n",
        "        \n",
        "        answers['answer_start'] = [answer['answer_start']]\n",
        "        answers['text'] = [answer['text']]\n",
        "        \n",
        "        data_dict['context'] = context\n",
        "        data_dict['question'] = question\n",
        "        data_dict['answers'] = answers\n",
        "        \n",
        "        data_list.append(data_dict)\n",
        "        \n",
        "        data_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cdd614-d908-4b64-9420-8a78da8a43e3",
      "metadata": {
        "id": "64cdd614-d908-4b64-9420-8a78da8a43e3",
        "outputId": "f55e93f9-e691-4037-a104-e15da6025d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243425"
            ]
          },
          "execution_count": 198,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2823489-c7d8-4342-9444-393b620353a3",
      "metadata": {
        "id": "a2823489-c7d8-4342-9444-393b620353a3",
        "outputId": "8aea724c-b169-4dc8-fccf-53af1a8ffb7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': \"한국청소년단체협의회와 여성가족부는 22일부터 28일까지 서울과 충북 괴산에서 '국제청소년포럼'을 연다고 21일 밝혔다. 한국 미국 캐나다 호주 등 전 세계 32개국 75여명의 대학생, 청소년들이 모여 전 세계적 현안문제에 대한 대안과 해결책을 모색하는 자리다. 이번 포럼의 주제는 '청소년과 뉴미디어'다. 스마트폰 SNS 태블릿PC 등 새로운 커뮤니케이션 매체인 '뉴미디어'에 대한 성찰과 문제점에 대해 토론한다. 기조강연을 시작으로 국가별 주제관련 사례발표, 그룹 토론 및 전체총회, '청소년선언문' 작성 및 채택 등 다양한 프로그램을 운영한다. 개회식은 22일 서울 방화동에 있는 국제청소년센터 국제회의장에서 한다. 전 세계 32개국 대학생ㆍ청소년 참가자와 전국의 청소년기관단체장과 청소년지도자 여성가족부 주한외교사절 등 100여명이 참석할 예정이다. 23일에는 유엔미래포럼 박영숙 대표가 '뉴미디어의 균형 있는 발전을 위한 청소년의 역할'에 대해 기조강연을 한다. 뉴미디어의 올바른 활용방안과 청소년문화의 형성에 대해 설명할 계획이다. 27일 폐회식에서는 '청소년선언문'을 채택한다. 선언문에는 전 세계적으로 뉴미디어의 바람직한 발전을 촉구하며 각국 청년들이 함께 실천할 수 있는 내용 등이 담길 예정이다. 한국청소년단체협의회는 포럼이 끝난 뒤 UN 등 국제기구와 참가자 각국 정부 등 국제사회에 선언문을 전달할 예정이다.\",\n",
              " 'question': \"서울과 충북 괴산에서 '국제청소년포럼'을 여는 곳은?\",\n",
              " 'answers': {'answer_start': [0], 'text': ['한국청소년단체협의회와 여성가족부']}}"
            ]
          },
          "execution_count": 199,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6744a3db-d445-4544-bacd-e30ca07d9957",
      "metadata": {
        "id": "6744a3db-d445-4544-bacd-e30ca07d9957"
      },
      "outputs": [],
      "source": [
        "#second preprocess ai hub dataset\n",
        "\n",
        "context_list = []\n",
        "question_list = []\n",
        "answer_list = []\n",
        "\n",
        "for data in data_list:\n",
        "    \n",
        "    context,question,answers = data.values()\n",
        "    \n",
        "    context_list.append(context)\n",
        "    question_list.append(question)\n",
        "    answer_list.append(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fefb0f09-943d-4c78-99ea-e19ae71a786c",
      "metadata": {
        "id": "fefb0f09-943d-4c78-99ea-e19ae71a786c",
        "outputId": "d1e7c803-2d60-466d-ab7e-5d9ecf5da03d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243425"
            ]
          },
          "execution_count": 201,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf23e1a6-2c03-4305-a80a-9be6b0ed34d3",
      "metadata": {
        "id": "bf23e1a6-2c03-4305-a80a-9be6b0ed34d3",
        "outputId": "b779ea1c-714c-4792-81c1-218fbb1b1126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243425"
            ]
          },
          "execution_count": 202,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea026cf9-91c0-4d7c-9d2b-637549c3c09d",
      "metadata": {
        "id": "ea026cf9-91c0-4d7c-9d2b-637549c3c09d",
        "outputId": "cb532c08-5647-4d58-8b58-b55666d175e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243425"
            ]
          },
          "execution_count": 203,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(answer_list)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "17ef7f28-5dee-4c30-9ec6-86402747ac38",
      "metadata": {
        "id": "17ef7f28-5dee-4c30-9ec6-86402747ac38"
      },
      "source": [
        "## concatenation ai hub dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3f1293-d30c-4542-8c3c-0c7b193c4a60",
      "metadata": {
        "id": "9f3f1293-d30c-4542-8c3c-0c7b193c4a60"
      },
      "outputs": [],
      "source": [
        "train_datasets_korquad = concatenate_datasets([train_datasets_korquad,valid_datasets_korquad])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57bcfd98-ab73-4860-9711-da7164b5223f",
      "metadata": {
        "id": "57bcfd98-ab73-4860-9711-da7164b5223f"
      },
      "outputs": [],
      "source": [
        "korquad_context_list = train_datasets_korquad['context']\n",
        "korquad_question_list = train_datasets_korquad['question']\n",
        "korquad_answer_list = train_datasets_korquad['answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4406de5f-0d3c-49a4-a1d4-f1f8d428c43e",
      "metadata": {
        "id": "4406de5f-0d3c-49a4-a1d4-f1f8d428c43e",
        "outputId": "e0008fcf-f556-4b5e-d1cd-e516b7b15f22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66181"
            ]
          },
          "execution_count": 206,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(korquad_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb82644-783d-4f5f-8e9e-82f00cd672c0",
      "metadata": {
        "id": "cbb82644-783d-4f5f-8e9e-82f00cd672c0",
        "outputId": "ddbecbed-0a6a-42ca-9248-57b755128212"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66181"
            ]
          },
          "execution_count": 207,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(korquad_question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408ab9e5-a105-4365-8a54-868efc94cae3",
      "metadata": {
        "id": "408ab9e5-a105-4365-8a54-868efc94cae3",
        "outputId": "2575794b-2e3b-439b-f3f9-3e559d702209"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66181"
            ]
          },
          "execution_count": 208,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(korquad_answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f53675-9ed1-4dcb-86eb-e6c84361e797",
      "metadata": {
        "id": "b0f53675-9ed1-4dcb-86eb-e6c84361e797"
      },
      "outputs": [],
      "source": [
        "base_context_list = train_datasets_base['context']\n",
        "valid_context_list = valid_datasets_base['context']\n",
        "base_question_list =train_datasets_base['question']\n",
        "base_answer_list = train_datasets_base['answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2014a007-5511-47ef-bd25-543dbd222194",
      "metadata": {
        "id": "2014a007-5511-47ef-bd25-543dbd222194",
        "outputId": "37e0a04e-3f3b-41a0-ed4f-0487aa109643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3952"
            ]
          },
          "execution_count": 210,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(base_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3142da85-b9cc-4d8d-ba97-1a0ee001f80f",
      "metadata": {
        "id": "3142da85-b9cc-4d8d-ba97-1a0ee001f80f",
        "outputId": "4879658c-4c38-41d3-f178-0346e65c850e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3952"
            ]
          },
          "execution_count": 211,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(base_question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8183ae-12d7-46f1-88bb-09f0ad02c78c",
      "metadata": {
        "id": "2c8183ae-12d7-46f1-88bb-09f0ad02c78c",
        "outputId": "3cdec0cb-0ffe-4e11-ef8c-9520dcbec7fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3952"
            ]
          },
          "execution_count": 212,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(base_answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c93a87-bca7-43db-b58e-5f82f3a11d30",
      "metadata": {
        "id": "78c93a87-bca7-43db-b58e-5f82f3a11d30"
      },
      "outputs": [],
      "source": [
        "context_list.extend(korquad_context_list)\n",
        "question_list.extend(korquad_question_list)\n",
        "answer_list.extend(korquad_answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce54ee35-ca7a-4204-a39b-1a1ab15464ef",
      "metadata": {
        "id": "ce54ee35-ca7a-4204-a39b-1a1ab15464ef"
      },
      "outputs": [],
      "source": [
        "context_list.extend(base_context_list)\n",
        "question_list.extend(base_question_list)\n",
        "answer_list.extend(base_answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8b0952-9175-40ef-96da-84c993b55beb",
      "metadata": {
        "id": "ad8b0952-9175-40ef-96da-84c993b55beb"
      },
      "outputs": [],
      "source": [
        "context_list.extend(valid_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b422e9-5b6c-4972-b7bb-4124662c9f81",
      "metadata": {
        "id": "b0b422e9-5b6c-4972-b7bb-4124662c9f81",
        "outputId": "33ee88d2-38cf-4895-bed5-df4e0816684a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "313798"
            ]
          },
          "execution_count": 216,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9ce10a-0fb7-4543-9ac4-3bdab04a1a71",
      "metadata": {
        "id": "cb9ce10a-0fb7-4543-9ac4-3bdab04a1a71",
        "outputId": "754c0b3a-d852-4036-ca4a-8897ad4008d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "313558"
            ]
          },
          "execution_count": 160,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e149656-679e-4330-958e-314ab07d2b33",
      "metadata": {
        "id": "5e149656-679e-4330-958e-314ab07d2b33",
        "outputId": "e86c6521-4f70-4846-bd90-9ccbda79f8c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "313558"
            ]
          },
          "execution_count": 161,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(answer_list)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0e2b0b8c-0418-4091-867d-0eed0f259c77",
      "metadata": {
        "id": "0e2b0b8c-0418-4091-867d-0eed0f259c77"
      },
      "source": [
        "## create top20 bm25 score dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9879071-1c0e-40ba-9461-94229ae74ae6",
      "metadata": {
        "id": "e9879071-1c0e-40ba-9461-94229ae74ae6"
      },
      "outputs": [],
      "source": [
        "corpus = context_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f247d9d-b978-4b62-91bc-f9e9ab016d7e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ec91e3010ab546f28f027351a9a38453"
          ]
        },
        "id": "7f247d9d-b978-4b62-91bc-f9e9ab016d7e",
        "outputId": "a2a488be-0c29-43ca-96ae-abe42cdaa8d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec91e3010ab546f28f027351a9a38453",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=313798.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clean_corpus = get_clean_wikipedia_text_v4(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7fac11-7526-4c7e-9547-5d76f5585057",
      "metadata": {
        "id": "5e7fac11-7526-4c7e-9547-5d76f5585057"
      },
      "outputs": [],
      "source": [
        "clean_corpus = list(set(clean_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7477a2e7-c6c2-4bba-8aa0-825ebe1ad8df",
      "metadata": {
        "id": "7477a2e7-c6c2-4bba-8aa0-825ebe1ad8df",
        "outputId": "139d0ac2-0bd9-4ecf-cc04-9e5be7954f4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "59528"
            ]
          },
          "execution_count": 220,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691ad12f-3119-4333-bbfe-0a398e896adf",
      "metadata": {
        "id": "691ad12f-3119-4333-bbfe-0a398e896adf",
        "outputId": "5da5102a-b658-4055-d4f1-9dabcf8e9d99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
              "    num_rows: 3952\n",
              "})"
            ]
          },
          "execution_count": 221,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70099fbf-6e83-4789-9444-3ad7b9ec8729",
      "metadata": {
        "id": "70099fbf-6e83-4789-9444-3ad7b9ec8729"
      },
      "outputs": [],
      "source": [
        "ground_truth_context_list = train_datasets_base['context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49753bfa-4eab-4366-8d40-37e6f79161b1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0d0a67b43a4d4b7596f3ca881a7ef8e2"
          ]
        },
        "id": "49753bfa-4eab-4366-8d40-37e6f79161b1",
        "outputId": "d4782880-c18b-434c-ae03-a577ebb671b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d0a67b43a4d4b7596f3ca881a7ef8e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3952.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ground_truth_context_list = get_clean_wikipedia_text_v4(ground_truth_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2752ef7b-f6b3-4501-9b9d-57a1b7c8af91",
      "metadata": {
        "id": "2752ef7b-f6b3-4501-9b9d-57a1b7c8af91"
      },
      "outputs": [],
      "source": [
        "gt_id_list = []\n",
        "\n",
        "for index,gt in enumerate(ground_truth_context_list):\n",
        "    \n",
        "    for idx,document in enumerate(clean_corpus):\n",
        "        if gt == document:\n",
        "            gt_id_list.append(idx)\n",
        "            break\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaee039-cc18-4fa1-890c-8bee649062d4",
      "metadata": {
        "id": "deaee039-cc18-4fa1-890c-8bee649062d4"
      },
      "outputs": [],
      "source": [
        "question_list = train_datasets_base['question']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4c0b8d-36fa-4ea7-b626-90244700f6ab",
      "metadata": {
        "id": "9d4c0b8d-36fa-4ea7-b626-90244700f6ab",
        "outputId": "3078f3e4-0656-4891-c9fd-04635a3fd53c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3952"
            ]
          },
          "execution_count": 226,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e96e62b-516a-4608-abdb-c1ccecb92484",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "08fcb0d229814b93a7a5b2426f99d6f2",
            "9d5c03283bf74ef2b26ec1ab9e53eae1"
          ]
        },
        "id": "4e96e62b-516a-4608-abdb-c1ccecb92484",
        "outputId": "4ce59e2f-a527-4493-acb9-1d3b5b988ccb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08fcb0d229814b93a7a5b2426f99d6f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59528.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d5c03283bf74ef2b26ec1ab9e53eae1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3952.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_bm25_list = get_relevant_doc_bm25(clean_corpus,question_list,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888001cc-66b5-4dc9-857d-2a484f3a2897",
      "metadata": {
        "id": "888001cc-66b5-4dc9-857d-2a484f3a2897"
      },
      "outputs": [],
      "source": [
        "with open('query_bm25_list_train.pkl', 'wb') as f:\n",
        "    pickle.dump(query_bm25_list, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f292c2fd-ced5-478b-823a-1b909cef7e6e",
      "metadata": {
        "id": "f292c2fd-ced5-478b-823a-1b909cef7e6e"
      },
      "outputs": [],
      "source": [
        "with open('query_bm25_list_train.pkl', 'rb') as f:\n",
        "    query_bm25_list = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ce49d1-5be2-41a1-bc65-9e5c48d0036b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "39535912a53c4380a1466bf36e4da300"
          ]
        },
        "id": "18ce49d1-5be2-41a1-bc65-9e5c48d0036b",
        "outputId": "549c2edc-7e8f-483c-c607-f561246010fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39535912a53c4380a1466bf36e4da300",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "context_list = []\n",
        "\n",
        "for idx,a in notebook.tqdm(enumerate(query_bm25_list)):\n",
        "    \n",
        "    _,context_id,_ = a\n",
        "\n",
        "    context = []\n",
        "    \n",
        "    context_id = context_id.numpy()\n",
        "    \n",
        "    if gt_id_list[idx] in list(context_id):\n",
        "        \n",
        "        np.random.shuffle(context_id)\n",
        "        \n",
        "        for idx in context_id:\n",
        "            context.append(clean_corpus[idx])\n",
        "            \n",
        "        context_string = ' '.join(context)\n",
        "\n",
        "        context_list.append(context_string)\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        context_id = list(context_id[:19])\n",
        "        context_id.append(gt_id_list[idx])\n",
        "        \n",
        "        context_id = np.array(context_id)\n",
        "        \n",
        "        np.random.shuffle(context_id)\n",
        "        \n",
        "        for idx in context_id:\n",
        "            context.append(clean_corpus[idx])\n",
        "            \n",
        "        context_string = ' '.join(context)\n",
        "\n",
        "        context_list.append(context_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8771258b-c9c0-4a6b-86a3-2e6f5156f685",
      "metadata": {
        "id": "8771258b-c9c0-4a6b-86a3-2e6f5156f685"
      },
      "outputs": [],
      "source": [
        "base_answer_list = train_datasets_base['answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cda0eee-e1e9-4c76-9c3e-a4ea385b91c8",
      "metadata": {
        "id": "5cda0eee-e1e9-4c76-9c3e-a4ea385b91c8"
      },
      "outputs": [],
      "source": [
        "new_answer_list = []\n",
        "\n",
        "for answer,context in zip(base_answer_list,context_list):\n",
        "    \n",
        "    new_answer = {}\n",
        "    \n",
        "    answer_text = answer['text'][0]\n",
        "    \n",
        "    answer_start = [context.index(answer_text)]\n",
        "    \n",
        "    new_answer['answer_start']=answer_start\n",
        "    new_answer['text'] = [answer_text]\n",
        "    \n",
        "    new_answer_list.append(new_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "853e3500-fe5e-430a-b8aa-1260626854d2",
      "metadata": {
        "id": "853e3500-fe5e-430a-b8aa-1260626854d2"
      },
      "outputs": [],
      "source": [
        "base_question_list =train_datasets_base['question']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3bfd93-a623-4bd6-96af-c92a793368b3",
      "metadata": {
        "id": "dc3bfd93-a623-4bd6-96af-c92a793368b3"
      },
      "outputs": [],
      "source": [
        "#finally exchange dataset class\n",
        "data_dict = {'answers':new_answer_list,'question':base_question_list,'context':context_list}\n",
        "    \n",
        "f = Features({'context': Value(dtype='string', id=None),\n",
        " 'question': Value(dtype='string', id=None),\n",
        " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)})\n",
        "    \n",
        "train_datasets_final = DatasetDict({'train': Dataset.from_dict(data_dict, features=f)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7f7c4d-3ff3-42d8-8802-02d4b2356138",
      "metadata": {
        "id": "4b7f7c4d-3ff3-42d8-8802-02d4b2356138"
      },
      "outputs": [],
      "source": [
        "train_datasets_base = train_datasets_final['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7bde7a2-27c5-40d0-97a7-74e465ae5fde",
      "metadata": {
        "id": "d7bde7a2-27c5-40d0-97a7-74e465ae5fde",
        "outputId": "a9fa7e86-4fb4-41bd-81bf-96bb49c781ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers'],\n",
              "    num_rows: 3952\n",
              "})"
            ]
          },
          "execution_count": 235,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base #train set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "JG-7yAU0zmYF",
      "metadata": {
        "id": "JG-7yAU0zmYF"
      },
      "source": [
        "## top20 bm25 score valid set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c028ac-b629-4fbb-b8fe-bc7286b9bfa3",
      "metadata": {
        "id": "10c028ac-b629-4fbb-b8fe-bc7286b9bfa3"
      },
      "outputs": [],
      "source": [
        "valid_context_list = valid_datasets_base['context']\n",
        "valid_question_list =valid_datasets_base['question']\n",
        "valid_answer_list = valid_datasets_base['answers']\n",
        "valid_id_list = valid_datasets_base['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3825bfa-ab2a-4bfa-941f-181c9fe39734",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0d476de169cf420fbaddb9ba9a846812"
          ]
        },
        "id": "c3825bfa-ab2a-4bfa-941f-181c9fe39734",
        "outputId": "2d0d560a-efc5-44e7-967d-d5ba0f605941"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d476de169cf420fbaddb9ba9a846812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ground_truth_valid_context_list = get_clean_wikipedia_text_v4(valid_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd50534d-9b37-4daf-8682-36917b986d26",
      "metadata": {
        "id": "cd50534d-9b37-4daf-8682-36917b986d26"
      },
      "outputs": [],
      "source": [
        "gt_id_valid_list = []\n",
        "\n",
        "for index,gt in enumerate(ground_truth_valid_context_list):\n",
        "    \n",
        "    for idx,document in enumerate(clean_corpus):\n",
        "        if gt == document:\n",
        "            gt_id_valid_list.append(idx)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4539650c-3613-4801-8a79-45d6b5b60c5f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "149fe4c12e2c463ca2c83df42573d931",
            "ca1be721fde24290affe75e071854474"
          ]
        },
        "id": "4539650c-3613-4801-8a79-45d6b5b60c5f",
        "outputId": "cfd9fbb6-b6e7-422b-b5b8-097e87fc5ba4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "149fe4c12e2c463ca2c83df42573d931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59528.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca1be721fde24290affe75e071854474",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_bm25_valid_list = get_relevant_doc_bm25(clean_corpus,valid_question_list,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90d2989-a50b-4471-8ddf-4132978a3891",
      "metadata": {
        "id": "b90d2989-a50b-4471-8ddf-4132978a3891"
      },
      "outputs": [],
      "source": [
        "with open('query_bm25_list_valid.pkl', 'wb') as f:\n",
        "    pickle.dump(query_bm25_valid_list, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3523b8c7-d5be-4633-b35c-831c403b2811",
      "metadata": {
        "id": "3523b8c7-d5be-4633-b35c-831c403b2811"
      },
      "outputs": [],
      "source": [
        "with open('query_bm25_list_valid.pkl', 'rb') as f:\n",
        "    query_bm25_valid_list = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb73a73-f545-4a98-b23b-f9205676675f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "dc25fe97d1e54c05a61f0909677cf2e4"
          ]
        },
        "id": "1eb73a73-f545-4a98-b23b-f9205676675f",
        "outputId": "2073d90f-57e8-480b-ea8c-91e2f07b6eae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc25fe97d1e54c05a61f0909677cf2e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "new_context_list = []\n",
        "\n",
        "for idx,a in notebook.tqdm(enumerate(query_bm25_valid_list)):\n",
        "    \n",
        "    _,context_id,_ = a\n",
        "\n",
        "    context = []\n",
        "    \n",
        "    context_id = context_id.numpy()\n",
        "    \n",
        "    if gt_id_valid_list[idx] in list(context_id):\n",
        "        \n",
        "        np.random.shuffle(context_id)\n",
        "        \n",
        "        for idx in context_id:\n",
        "            context.append(clean_corpus[idx])\n",
        "            \n",
        "        context_string = ' '.join(context)\n",
        "\n",
        "        new_context_list.append(context_string)\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        context_id = list(context_id[:19])\n",
        "        context_id.append(gt_id_valid_list[idx])\n",
        "        \n",
        "        context_id = np.array(context_id)\n",
        "        \n",
        "        np.random.shuffle(context_id)\n",
        "        \n",
        "        for idx in context_id:\n",
        "            context.append(clean_corpus[idx])\n",
        "            \n",
        "        context_string = ' '.join(context)\n",
        "\n",
        "        new_context_list.append(context_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af003bd3-6ae9-4cb7-9681-d6719c3a21f0",
      "metadata": {
        "id": "af003bd3-6ae9-4cb7-9681-d6719c3a21f0"
      },
      "outputs": [],
      "source": [
        "new_answer_list = []\n",
        "\n",
        "for answer,context in zip(valid_answer_list,new_context_list):\n",
        "    \n",
        "    new_answer = {}\n",
        "    \n",
        "    answer_text = answer['text'][0]\n",
        "    \n",
        "    answer_start = [context.index(answer_text)]\n",
        "    \n",
        "    new_answer['answer_start']=answer_start\n",
        "    new_answer['text'] = [answer_text]\n",
        "    \n",
        "    new_answer_list.append(new_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c1af3d-1650-4f28-baeb-2a02d6c54df5",
      "metadata": {
        "id": "61c1af3d-1650-4f28-baeb-2a02d6c54df5"
      },
      "outputs": [],
      "source": [
        "data_dict = {'answers':new_answer_list,'question':valid_question_list,'context':new_context_list,'id':valid_id_list}\n",
        "    \n",
        "f = Features({'context': Value(dtype='string', id=None),\n",
        " 'question': Value(dtype='string', id=None),\n",
        " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
        "'id': Value(dtype='string', id=None)\n",
        "             })\n",
        "    \n",
        "valid_datasets_final = DatasetDict({'valid': Dataset.from_dict(data_dict, features=f)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c03810-9a47-486a-be88-3ed8c0e7e990",
      "metadata": {
        "id": "c8c03810-9a47-486a-be88-3ed8c0e7e990"
      },
      "outputs": [],
      "source": [
        "valid_datasets_base= valid_datasets_final['valid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d12252a-cbf9-4fce-8841-c6ca283af139",
      "metadata": {
        "id": "3d12252a-cbf9-4fce-8841-c6ca283af139",
        "outputId": "32c0fbc2-5f94-42a5-eada-7c06c5be1a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers', 'id'],\n",
              "    num_rows: 240\n",
              "})"
            ]
          },
          "execution_count": 245,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_datasets_base #validation set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "afffa2db-c798-49a1-b1a4-e61b869c26cc",
      "metadata": {
        "id": "afffa2db-c798-49a1-b1a4-e61b869c26cc"
      },
      "source": [
        "## check dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2511087d-a21e-445d-bbd6-7c1bb4b0bf33",
      "metadata": {
        "collapsed": true,
        "id": "2511087d-a21e-445d-bbd6-7c1bb4b0bf33",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "288c41d4-58f9-45f4-f9fb-5af727756242",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answers': {'answer_start': [0], 'text': ['한국청소년단체협의회와 여성가족부']}, 'question': \"서울과 충북 괴산에서 '국제청소년포럼'을 여는 곳은?\", 'context': \"한국청소년단체협의회와 여성가족부는 22일부터 28일까지 서울과 충북 괴산에서 '국제청소년포럼'을 연다고 21일 밝혔다. 한국 미국 캐나다 호주 등 전 세계 32개국 75여명의 대학생, 청소년들이 모여 전 세계적 현안문제에 대한 대안과 해결책을 모색하는 자리다. 이번 포럼의 주제는 '청소년과 뉴미디어'다. 스마트폰 SNS 태블릿PC 등 새로운 커뮤니케이션 매체인 '뉴미디어'에 대한 성찰과 문제점에 대해 토론한다. 기조강연을 시작으로 국가별 주제관련 사례발표, 그룹 토론 및 전체총회, '청소년선언문' 작성 및 채택 등 다양한 프로그램을 운영한다. 개회식은 22일 서울 방화동에 있는 국제청소년센터 국제회의장에서 한다. 전 세계 32개국 대학생ㆍ청소년 참가자와 전국의 청소년기관단체장과 청소년지도자 여성가족부 주한외교사절 등 100여명이 참석할 예정이다. 23일에는 유엔미래포럼 박영숙 대표가 '뉴미디어의 균형 있는 발전을 위한 청소년의 역할'에 대해 기조강연을 한다. 뉴미디어의 올바른 활용방안과 청소년문화의 형성에 대해 설명할 계획이다. 27일 폐회식에서는 '청소년선언문'을 채택한다. 선언문에는 전 세계적으로 뉴미디어의 바람직한 발전을 촉구하며 각국 청년들이 함께 실천할 수 있는 내용 등이 담길 예정이다. 한국청소년단체협의회는 포럼이 끝난 뒤 UN 등 국제기구와 참가자 각국 정부 등 국제사회에 선언문을 전달할 예정이다.\"}\n"
          ]
        }
      ],
      "source": [
        "print(train_datasets_base[0]) #train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14598e69-30a8-4e75-8b0f-d003e85337eb",
      "metadata": {
        "collapsed": true,
        "id": "14598e69-30a8-4e75-8b0f-d003e85337eb",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "04af0a56-cfdc-4ca1-dde3-7d975708fff2",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answers': {'answer_start': [54], 'text': ['교향곡']}, 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.', 'id': '6566495-0-0', 'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?', 'title': '파우스트_서곡'}\n"
          ]
        }
      ],
      "source": [
        "print(train_datasets_korquad[0]) #korquad train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f321741-a95a-4946-afb5-12af5361c23b",
      "metadata": {
        "collapsed": true,
        "id": "1f321741-a95a-4946-afb5-12af5361c23b",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e4241f67-66f1-4036-8fb3-b985086b7952",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'title': '교황 그레고리오 4세', 'context': '한편 그레고리오 4세는 로마의 건축 발전에 크게 기여하였다. 833년 그레고리오 4세는 산 마르코 성당을 비잔티움 양식의 모자이크로 벽을 장식하는 등 완전히 새로운 형태로 탈바꿈하는 등 로마 시내의 많은 성당을 보수하거나 신축하였다. 그는 성 베드로 대성전의 안마당을 새로 포장했으며, 교황 그레고리오 1세의 유해를 대성전 안에 새로 설치한 부속 경당 안에 이장하였다. 그리고 로마의 카타콤베에서 성 세바스티아노와 성 티부르시오, 성 고르고니오의 유해를 다른 곳으로 이장하였다. 더불어 산타 마리아 인 트라스테베레 성당의 제대를 높이 만들고, 성당과 가까운 곳에 수도원을 세우도록 지시하였다. \\\\n\\\\n그레고리오 4세는 또한 교황 레오 3세 재위기간 중에 훼손되었던 트라야나 수도를 보수하였다. 841년에는 사라센족의 침입에 대비하기 위해 오스티아 항구를 다시 지어 요새화하였다. 동시에 그는 포폴리아 가도 언저리에 있는 갈레리아 개척지를 복구하였으며, 테베레 강가를 따라 왼쪽으로 드라라고 불리는 새로운 개척지를 구축하였다. 이곳은 로마로부터 오스티엔시스 가도를 따라 약 17킬로미터 정도 떨어진 곳이었다. 이는 교회 역사상 처음으로 교황이 자신의 관리구역을 토지 개발한 사례가 되었다. \\\\n\\\\n그레고리오 4세의 재위기간 동안 동로마 제국에서는 성화상 논쟁이 종지부를 찍었으며, 교황 자신은 프랑크 제국 영역인 라인 강 인근에서 모든 성인 대축일 기념 행사를 성대하게 개최하였다. 그레고리오 4세는 또한 832년에 안스가리오를 함부르크와 브레멘의 주교로 서임했으며, 유럽의 북동부 지역을 담당하는 교황 사절을 겸임하도록 하였다. \\\\n\\\\n844년 1월 25일 그레고리오 4세는 선종하였으며, 시신은 성 베드로 대성전에 안장되었다.', 'question': '교황에 의해 새롭게 토지 개발된 최초의 관리지역은?', 'id': 'mrc-1-000297', 'answers': {'answer_start': [493], 'text': ['드라']}, 'document_id': 6718, '__index_level_0__': 195}\n"
          ]
        }
      ],
      "source": [
        "print(valid_datasets_base[111]) #valid set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951d97d9-e610-4862-9cf1-e7a0a4e62ac4",
      "metadata": {
        "collapsed": true,
        "id": "951d97d9-e610-4862-9cf1-e7a0a4e62ac4",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0eaa2875-2791-4200-d1c8-a623c1f4b804",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answers': {'answer_start': [87], 'text': ['임종석']}, 'context': '1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.', 'id': '6332405-0-0', 'question': '1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?', 'title': '임종석'}\n"
          ]
        }
      ],
      "source": [
        "print(valid_datasets_korquad[5]) #korquad valid set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbd5fb0-0d85-46d1-afff-d60d6db3b39d",
      "metadata": {
        "collapsed": true,
        "id": "ccbd5fb0-0d85-46d1-afff-d60d6db3b39d",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "4f2db639-143c-46ee-9b11-d3eb506ed9f4",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base.features #train feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031528be-ed86-4df7-9667-1e00c3774ef3",
      "metadata": {
        "collapsed": true,
        "id": "031528be-ed86-4df7-9667-1e00c3774ef3",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f1a6043a-aef4-43ff-811e-9739a911201a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'title': Value(dtype='string', id=None),\n",
              " 'context': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_korquad.features #korquad train feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99717308-daf5-4aea-a421-b48881c5f8b1",
      "metadata": {
        "collapsed": true,
        "id": "99717308-daf5-4aea-a421-b48881c5f8b1",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "758ab4fd-f38a-4236-f58f-315f673242d6",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'__index_level_0__': Value(dtype='int64', id=None),\n",
              " 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              "  'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)},\n",
              " 'context': Value(dtype='string', id=None),\n",
              " 'document_id': Value(dtype='int64', id=None),\n",
              " 'id': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'title': Value(dtype='string', id=None)}"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_datasets_base.features #valid feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4bc81c-bf3e-44e0-9308-afeaead3d1a4",
      "metadata": {
        "collapsed": true,
        "id": "8b4bc81c-bf3e-44e0-9308-afeaead3d1a4",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b5f813a3-bfc5-4e1a-983a-415548964dc7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'title': Value(dtype='string', id=None),\n",
              " 'context': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_datasets_korquad.features #valid feature"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3fb8bafa-a290-41c6-a2f3-5e0de1e81e9c",
      "metadata": {
        "id": "3fb8bafa-a290-41c6-a2f3-5e0de1e81e9c"
      },
      "source": [
        "## load metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36fb0999-70d5-4e12-827c-534623b0b085",
      "metadata": {
        "id": "36fb0999-70d5-4e12-827c-534623b0b085"
      },
      "outputs": [],
      "source": [
        "metric = load_metric('squad')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1d1d82e3-86ca-49a2-8d67-513468cf369e",
      "metadata": {
        "id": "1d1d82e3-86ca-49a2-8d67-513468cf369e"
      },
      "source": [
        "## define preprocess function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891a56e9-edb1-43b1-a3d4-d71ecea725db",
      "metadata": {
        "id": "891a56e9-edb1-43b1-a3d4-d71ecea725db"
      },
      "outputs": [],
      "source": [
        "def prepare_train_features(examples):\n",
        "    # 주어진 텍스트를 토크나이징 한다. 이 때 텍스트의 길이가 max_seq_length를 넘으면 stride만큼 슬라이딩하며 여러 개로 쪼갬.\n",
        "    # 즉, 하나의 example에서 일부분이 겹치는 여러 sequence(feature)가 생길 수 있음.\n",
        "    tokenized_examples = mrc_tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",  # max_seq_length까지 truncate한다. pair의 두번째 파트(context)만 잘라냄.\n",
        "        max_length=max_seq_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True, # 길이를 넘어가는 토큰들을 반환할 것인지\n",
        "        return_offsets_mapping=True,  # 각 토큰에 대해 (char_start, char_end) 정보를 반환한 것인지\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    \n",
        "    # example 하나가 여러 sequence에 대응하는 경우를 위해 매핑이 필요함.\n",
        "    overflow_to_sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # offset_mappings으로 토큰이 원본 context 내 몇번째 글자부터 몇번째 글자까지 해당하는지 알 수 있음.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # 정답지를 만들기 위한 리스트\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(mrc_tokenizer.cls_token_id)\n",
        "        \n",
        "        # 해당 example에 해당하는 sequence를 찾음.\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        \n",
        "        # sequence가 속하는 example을 찾는다.\n",
        "        example_index = overflow_to_sample_mapping[i]\n",
        "        answers = examples[\"answers\"][example_index]\n",
        "        \n",
        "        # 텍스트에서 answer의 시작점, 끝점\n",
        "        answer_start_offset = answers[\"answer_start\"][0]\n",
        "        answer_end_offset = answer_start_offset + len(answers[\"text\"][0])\n",
        "\n",
        "        # 텍스트에서 현재 span의 시작 토큰 인덱스\n",
        "        token_start_index = 0\n",
        "        while sequence_ids[token_start_index] != 1:\n",
        "            token_start_index += 1\n",
        "        \n",
        "        # 텍스트에서 현재 span 끝 토큰 인덱스\n",
        "        token_end_index = len(input_ids) - 1\n",
        "        while sequence_ids[token_end_index] != 1:\n",
        "            token_end_index -= 1\n",
        "\n",
        "        # answer가 현재 span을 벗어났는지 체크\n",
        "        if not (offsets[token_start_index][0] <= answer_start_offset and offsets[token_end_index][1] >= answer_end_offset):\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # token_start_index와 token_end_index를 answer의 시작점과 끝점으로 옮김\n",
        "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= answer_start_offset:\n",
        "                token_start_index += 1\n",
        "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "            while offsets[token_end_index][1] >= answer_end_offset:\n",
        "                token_end_index -= 1\n",
        "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c864e99-c24d-4c88-ae21-a7bda6c9b8f2",
      "metadata": {
        "id": "5c864e99-c24d-4c88-ae21-a7bda6c9b8f2"
      },
      "outputs": [],
      "source": [
        "def prepare_validation_features(examples):\n",
        "    tokenized_examples = mrc_tokenizer(\n",
        "        examples['question'],\n",
        "        examples['context'],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_seq_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1\n",
        "\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "19267460-c7c2-4ff3-8be1-23ee271c6f0e",
      "metadata": {
        "id": "19267460-c7c2-4ff3-8be1-23ee271c6f0e"
      },
      "source": [
        "## cleansing competition data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5968fe8d-aaae-4962-a51f-fc7dad771d32",
      "metadata": {
        "id": "5968fe8d-aaae-4962-a51f-fc7dad771d32",
        "outputId": "0af2eb8d-8de0-495f-a24e-f4f8627bf969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers'],\n",
              "    num_rows: 3952\n",
              "})"
            ]
          },
          "execution_count": 249,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bac1527-c508-420b-8cc8-dc21d3ac6004",
      "metadata": {
        "id": "9bac1527-c508-420b-8cc8-dc21d3ac6004",
        "outputId": "ccf90068-8ac8-40ed-da40-514874ff8d07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers', 'id'],\n",
              "    num_rows: 240\n",
              "})"
            ]
          },
          "execution_count": 250,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_datasets_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2343a8bc-d755-410a-bd6d-aae205455506",
      "metadata": {
        "id": "2343a8bc-d755-410a-bd6d-aae205455506"
      },
      "outputs": [],
      "source": [
        "base_context_list = train_datasets_base['context']\n",
        "base_question_list =train_datasets_base['question']\n",
        "base_answer_list = train_datasets_base['answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec62e65-cea6-4d5b-b897-c6b2e309c6da",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1a1258ef9fe2453896000cb32acd9a91"
          ]
        },
        "id": "2ec62e65-cea6-4d5b-b897-c6b2e309c6da",
        "outputId": "53a8a630-f335-40a9-d02d-804fc657a96c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a1258ef9fe2453896000cb32acd9a91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3952.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clean_base_context_list = get_clean_wikipedia_text_v4(base_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2a34e4-7735-4b94-a9d1-c228642019c0",
      "metadata": {
        "id": "9d2a34e4-7735-4b94-a9d1-c228642019c0"
      },
      "outputs": [],
      "source": [
        "new_answer_list = []\n",
        "\n",
        "for answer,context in zip(base_answer_list,clean_base_context_list):\n",
        "    \n",
        "    new_answer = {}\n",
        "    \n",
        "    answer_text = answer['text'][0]\n",
        "    \n",
        "    answer_start = [context.index(answer_text)]\n",
        "    \n",
        "    new_answer['answer_start']=answer_start\n",
        "    new_answer['text'] = [answer_text]\n",
        "    \n",
        "    new_answer_list.append(new_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32484daf-eded-42de-97f3-699e4808a5b9",
      "metadata": {
        "id": "32484daf-eded-42de-97f3-699e4808a5b9"
      },
      "outputs": [],
      "source": [
        "data_dict = {'answers':new_answer_list,'question':base_question_list,'context':clean_base_context_list}\n",
        "    \n",
        "f = Features({'context': Value(dtype='string', id=None),\n",
        " 'question': Value(dtype='string', id=None),\n",
        " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)})\n",
        "    \n",
        "train_datasets_final = DatasetDict({'train': Dataset.from_dict(data_dict, features=f)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da73e1b-242b-4fb2-b1f5-007cd9558bee",
      "metadata": {
        "id": "1da73e1b-242b-4fb2-b1f5-007cd9558bee"
      },
      "outputs": [],
      "source": [
        "train_datasets_base = train_datasets_final['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67a99868-0403-4617-a881-88054b15be55",
      "metadata": {
        "id": "67a99868-0403-4617-a881-88054b15be55",
        "outputId": "f06ea10f-68a4-48fa-e327-1623ec8335fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers'],\n",
              "    num_rows: 3952\n",
              "})"
            ]
          },
          "execution_count": 90,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "32115958-f278-4e09-9785-cb608b1ab383",
      "metadata": {
        "id": "32115958-f278-4e09-9785-cb608b1ab383"
      },
      "source": [
        "## cleansing competition valid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3328d11d-08ea-4216-8cc0-88f3b83f96b0",
      "metadata": {
        "id": "3328d11d-08ea-4216-8cc0-88f3b83f96b0"
      },
      "outputs": [],
      "source": [
        "base_context_list = valid_datasets_base['context']\n",
        "base_question_list =valid_datasets_base['question']\n",
        "base_answer_list = valid_datasets_base['answers']\n",
        "base_id_list = valid_datasets_base['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f5b7b3-e281-441d-b1df-1867d5b89581",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6892d90c438c46999701619e9602f2bf"
          ]
        },
        "id": "b7f5b7b3-e281-441d-b1df-1867d5b89581",
        "outputId": "4af7924b-2ffb-4261-ac60-ad4aa2204935"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6892d90c438c46999701619e9602f2bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clean_base_context_list = get_clean_wikipedia_text_v4(base_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d88d72e1-114a-453e-bcbc-2f869126db96",
      "metadata": {
        "id": "d88d72e1-114a-453e-bcbc-2f869126db96"
      },
      "outputs": [],
      "source": [
        "new_answer_list = []\n",
        "\n",
        "for answer,context in zip(base_answer_list,clean_base_context_list):\n",
        "    \n",
        "    new_answer = {}\n",
        "    \n",
        "    answer_text = answer['text'][0]\n",
        "    \n",
        "    answer_start = [context.index(answer_text)]\n",
        "    \n",
        "    new_answer['answer_start']=answer_start\n",
        "    new_answer['text'] = [answer_text]\n",
        "    \n",
        "    new_answer_list.append(new_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc009d1-f8e3-44e3-8e4a-6ee7e06c624a",
      "metadata": {
        "id": "2bc009d1-f8e3-44e3-8e4a-6ee7e06c624a"
      },
      "outputs": [],
      "source": [
        "data_dict = {'answers':new_answer_list,'question':base_question_list,'context':clean_base_context_list,'id':base_id_list}\n",
        "    \n",
        "f = Features({'context': Value(dtype='string', id=None),\n",
        " 'question': Value(dtype='string', id=None),\n",
        " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
        "'id': Value(dtype='string', id=None)\n",
        "             })\n",
        "    \n",
        "valid_datasets_final = DatasetDict({'valid': Dataset.from_dict(data_dict, features=f)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dadcfbf3-da72-44f6-b9e4-2f915ebbdd96",
      "metadata": {
        "id": "dadcfbf3-da72-44f6-b9e4-2f915ebbdd96"
      },
      "outputs": [],
      "source": [
        "valid_datasets_base = valid_datasets_final['valid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3abe39-35e8-4549-b1d0-7a8f001c5e51",
      "metadata": {
        "id": "eb3abe39-35e8-4549-b1d0-7a8f001c5e51",
        "outputId": "ea1107ca-9ee1-4fd9-f155-edb9a02432cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'question', 'answers', 'id'],\n",
              "    num_rows: 240\n",
              "})"
            ]
          },
          "execution_count": 96,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_datasets_base"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2743247d-4ce6-4042-8e14-0000b50cc402",
      "metadata": {
        "id": "2743247d-4ce6-4042-8e14-0000b50cc402"
      },
      "source": [
        "## tokenizing & preprocessing mrc dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8711e9-b602-4425-ace7-496349606a88",
      "metadata": {
        "id": "9b8711e9-b602-4425-ace7-496349606a88"
      },
      "outputs": [],
      "source": [
        "#tokenizer\n",
        "\n",
        "mrc_model_name = 'monologg/koelectra-base-v3-discriminator'\n",
        "mrc_tokenizer = AutoTokenizer.from_pretrained(mrc_model_name)\n",
        "\n",
        "#mecab = Mecab()\n",
        "\n",
        "#def tokenize(text):\n",
        "    #return mecab.morphs(text)\n",
        "\n",
        "#mrc_tokenizer = tokenize\n",
        "#dense_tokenizer = tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd020a77-62c9-4a1b-a1e7-4c1625f0d172",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b97ca729e96249a7a1102686e30b2e14",
            "63fbfd29e42640ccad580a58fdfacc72",
            "29f8dd55cb674ea2ac0b061b800da8fc",
            "6db23ac7e68d482eab15fc0b2488a0ee"
          ]
        },
        "id": "fd020a77-62c9-4a1b-a1e7-4c1625f0d172",
        "outputId": "c4b6f079-3fda-4a66-ec51-b51abb043304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b97ca729e96249a7a1102686e30b2e14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#0', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63fbfd29e42640ccad580a58fdfacc72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#1', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29f8dd55cb674ea2ac0b061b800da8fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#2', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6db23ac7e68d482eab15fc0b2488a0ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#3', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#preprocessing train dataset competition\n",
        "\n",
        "column_names = train_datasets_base.column_names\n",
        "\n",
        "train_dataset = train_datasets_base.map(\n",
        "            prepare_train_features,\n",
        "            batched=True,\n",
        "            num_proc=preprocessing_num_workers,\n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824347b8-be38-49eb-a70b-61f0bcec375a",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2db819b8050a48f88feff978e0ac9628",
            "9963c6d580764b31ac36fc637ed96032",
            "c06d268cbf3c4b098f8f605571ef2c0a",
            "387be0de95654281b0383d05f46e539f"
          ]
        },
        "id": "824347b8-be38-49eb-a70b-61f0bcec375a",
        "outputId": "92db68d5-c675-4095-b6f3-5ae911fac80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db819b8050a48f88feff978e0ac9628",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#0', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9963c6d580764b31ac36fc637ed96032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#1', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c06d268cbf3c4b098f8f605571ef2c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#2', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "387be0de95654281b0383d05f46e539f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='#3', max=1.0, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#preprocessing validation dataset competition\n",
        "\n",
        "column_names = valid_datasets_base.column_names\n",
        "\n",
        "eval_dataset = valid_datasets_base.map(\n",
        "            prepare_validation_features,\n",
        "            batched=True,\n",
        "           num_proc=preprocessing_num_workers,\n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc22cf06-ecee-4dde-8677-be567f2ea6b5",
      "metadata": {
        "id": "fc22cf06-ecee-4dde-8677-be567f2ea6b5",
        "outputId": "98135784-93ac-46ff-a647-ff63ac50fb50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80311"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c170bf-f79e-453c-bdbb-373b861012ac",
      "metadata": {
        "id": "06c170bf-f79e-453c-bdbb-373b861012ac",
        "outputId": "9dc8a2bd-f403-4c59-a50b-28a29bbec3f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "533"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b06d84-61bb-4665-acaf-1d1045facd0e",
      "metadata": {
        "id": "82b06d84-61bb-4665-acaf-1d1045facd0e",
        "outputId": "4c4e88e7-42f1-4919-fb63-289b416fa90f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n",
              "    num_rows: 186544\n",
              "})"
            ]
          },
          "execution_count": 256,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5ed60e-28d7-469a-b39b-3037b1c7de23",
      "metadata": {
        "id": "3b5ed60e-28d7-469a-b39b-3037b1c7de23",
        "outputId": "e588325c-712e-4975-b1c4-f7149a99cfdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'example_id', 'input_ids', 'offset_mapping', 'token_type_ids'],\n",
              "    num_rows: 11487\n",
              "})"
            ]
          },
          "execution_count": 257,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "47ac7baf-ca30-464c-89ed-4b82d6819eb0",
      "metadata": {
        "id": "47ac7baf-ca30-464c-89ed-4b82d6819eb0"
      },
      "source": [
        "## concatenation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f364aee-6abe-42ae-b405-187ff41a7243",
      "metadata": {
        "id": "2f364aee-6abe-42ae-b405-187ff41a7243"
      },
      "outputs": [],
      "source": [
        "#concatenation for retraining\n",
        "\n",
        "train_datasets_base = concatenate_datasets([train_datasets_base,valid_datasets_base])\n",
        "\n",
        "train_datasets_korquad = concatenate_datasets([train_datasets_korquad,valid_datasets_korquad])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d31ad7-a58a-4358-95ab-44d24fdec582",
      "metadata": {
        "id": "17d31ad7-a58a-4358-95ab-44d24fdec582",
        "outputId": "8f9502c5-933c-4671-9146-589ceed11f47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
              "    num_rows: 4192\n",
              "})"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71110a99-62df-4ad7-96c0-0f0d72bd479d",
      "metadata": {
        "id": "71110a99-62df-4ad7-96c0-0f0d72bd479d",
        "outputId": "898ae856-14fb-4edc-f3b4-7f41e80908e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 66181\n",
              "})"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datasets_korquad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d6acb3-2161-4402-917e-914cf19c11c3",
      "metadata": {
        "id": "67d6acb3-2161-4402-917e-914cf19c11c3",
        "outputId": "cec50963-bc0f-41d3-abb6-a37f0f17fdc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at input/data/data/train_dataset/train/cache-e4a4143b9734ad1d.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at input/data/data/train_dataset/train/cache-a6046d86ae6d2246.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at input/data/data/train_dataset/train/cache-d39d153864f9a2a5.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at input/data/data/train_dataset/train/cache-a0c48ef3437204c0.arrow\n"
          ]
        }
      ],
      "source": [
        "#preprocesing train dataset\n",
        "\n",
        "column_names = train_datasets_base.column_names\n",
        "\n",
        "train_dataset = train_datasets_base.map(\n",
        "            prepare_train_features,\n",
        "            batched=True,\n",
        "            num_proc=preprocessing_num_workers,\n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38c2ac8-2801-4428-beb6-7abc48737bd6",
      "metadata": {
        "id": "a38c2ac8-2801-4428-beb6-7abc48737bd6",
        "outputId": "4973129e-c5d9-4bfd-a6ca-d79df16734fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7/cache-6c3a160c20cac49b.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7/cache-5e9601b1774289ed.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7/cache-2ebd36ebf6ce3745.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7/cache-7d4ea920bd238c37.arrow\n"
          ]
        }
      ],
      "source": [
        "#preprocessing korquad dataset\n",
        "\n",
        "column_names = train_datasets_korquad.column_names\n",
        "\n",
        "train_dataset_korquad = train_datasets_korquad.map(\n",
        "            prepare_train_features,\n",
        "            batched=True,\n",
        "            num_proc=preprocessing_num_workers,\n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd026c7b-1b92-47c0-9efd-6dd40cad4ebb",
      "metadata": {
        "id": "bd026c7b-1b92-47c0-9efd-6dd40cad4ebb",
        "outputId": "c102788f-4dba-4915-d864-52b53d45412f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8572"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422eaef4-9223-4615-abd1-7df658028bcc",
      "metadata": {
        "id": "422eaef4-9223-4615-abd1-7df658028bcc",
        "outputId": "9f5e13aa-2f0a-430f-854c-4bd3a2fd84c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n",
              "    num_rows: 7836\n",
              "})"
            ]
          },
          "execution_count": 99,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357f8822-5aee-4a15-8348-7e8ff55b9538",
      "metadata": {
        "id": "357f8822-5aee-4a15-8348-7e8ff55b9538",
        "outputId": "0cc123f2-9f6e-466f-ea2e-01adc3f00d73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76737"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset_korquad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ddcd323-b539-4afc-bc38-eecf3e7ab1f7",
      "metadata": {
        "id": "7ddcd323-b539-4afc-bc38-eecf3e7ab1f7",
        "outputId": "c9fa14e5-98b2-46cb-e62a-126da350a12d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n",
              "    num_rows: 76737\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset_korquad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41d38ef-b35d-4973-a5ab-43beb4ea1d07",
      "metadata": {
        "id": "c41d38ef-b35d-4973-a5ab-43beb4ea1d07",
        "outputId": "e4afd247-e53c-4385-99f6-3cce9b7f69fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "85309"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#full dataset\n",
        "\n",
        "train_dataset = concatenate_datasets([train_dataset,train_dataset_korquad])\n",
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a405c39-4224-47f0-a5d3-140d4aa5e758",
      "metadata": {
        "id": "1a405c39-4224-47f0-a5d3-140d4aa5e758",
        "outputId": "1be9062a-9e3b-4407-a314-8054ae893112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n",
              "    num_rows: 85309\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b3946462-b103-411d-840a-a4455341d79f",
      "metadata": {
        "id": "b3946462-b103-411d-840a-a4455341d79f"
      },
      "source": [
        "## Dense embedding retrieval"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "002e4bbb-abd8-4a4d-ae12-4ebddfb59be1",
      "metadata": {
        "id": "002e4bbb-abd8-4a4d-ae12-4ebddfb59be1"
      },
      "source": [
        "## prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23550373-cfa0-4c94-a39b-e4b9c08768eb",
      "metadata": {
        "id": "23550373-cfa0-4c94-a39b-e4b9c08768eb"
      },
      "outputs": [],
      "source": [
        "# tokenizer\n",
        "\n",
        "dense_encoder_name = 'kykim/bert-kor-base'\n",
        "dense_tokenizer = BertTokenizerFast.from_pretrained(dense_encoder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1dfd61-6c7e-4d85-8bf2-feeb979ded6a",
      "metadata": {
        "id": "9b1dfd61-6c7e-4d85-8bf2-feeb979ded6a"
      },
      "outputs": [],
      "source": [
        "#dataset\n",
        "\n",
        "q_seqs = dense_tokenizer(train_datasets_base['question'],padding='max_length',truncation=True, return_tensors='pt')\n",
        "\n",
        "p_seqs = dense_tokenizer(train_datasets_base['context'],padding='max_length',truncation=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596fb3c6-c5e9-45b9-b759-009f4d6fed1b",
      "metadata": {
        "id": "596fb3c6-c5e9-45b9-b759-009f4d6fed1b"
      },
      "outputs": [],
      "source": [
        "train_dataset_dense = TensorDataset(p_seqs['input_ids'],p_seqs['attention_mask'],p_seqs['token_type_ids'],\n",
        "                             q_seqs['input_ids'],q_seqs['attention_mask'],q_seqs['token_type_ids'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "79218f46-daeb-45a3-9354-4d2fd9b2c893",
      "metadata": {
        "id": "79218f46-daeb-45a3-9354-4d2fd9b2c893"
      },
      "source": [
        "## define dense encoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109bb13e-1617-414b-9b2e-5d585a20b6d0",
      "metadata": {
        "id": "109bb13e-1617-414b-9b2e-5d585a20b6d0"
      },
      "outputs": [],
      "source": [
        "#define dense retrieval class\n",
        "\n",
        "class DenseRetrieval(BertPreTrainedModel):\n",
        "    def __init__(self,config):\n",
        "        super(DenseRetrieval,self).__init__(config)\n",
        "        \n",
        "        self.bert = BertModel(config)\n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        \n",
        "        outputs = self.bert(input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        \n",
        "        pooled_output = outputs[1]\n",
        "        \n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febaac94-83ad-4af0-adb0-6e11c810515e",
      "metadata": {
        "id": "febaac94-83ad-4af0-adb0-6e11c810515e",
        "outputId": "220910c4-79a7-442d-88a0-f23fc445c31b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing DenseRetrieval: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing DenseRetrieval from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DenseRetrieval from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing DenseRetrieval: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing DenseRetrieval from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DenseRetrieval from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "p_encoder = DenseRetrieval.from_pretrained(dense_encoder_name).cuda()\n",
        "q_encoder = DenseRetrieval.from_pretrained(dense_encoder_name).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b1d5b4-bef3-4499-b3dc-94b604ed6fd5",
      "metadata": {
        "id": "a6b1d5b4-bef3-4499-b3dc-94b604ed6fd5"
      },
      "outputs": [],
      "source": [
        "#load saved model\n",
        "\n",
        "p_encoder = torch.load('p_encoder_kobert_full_ai_hub.pth').cuda()\n",
        "q_encoder = torch.load('q_encoder_kobert_full_ai_hub.pth').cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c62a48f-459b-46ea-bc94-e56952a27294",
      "metadata": {
        "id": "7c62a48f-459b-46ea-bc94-e56952a27294",
        "outputId": "5543d1f5-e5bd-4545-e90c-07581beb836d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU enabled\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('GPU enabled')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a1a5f521-ab7d-41da-846b-dc481901c969",
      "metadata": {
        "id": "a1a5f521-ab7d-41da-846b-dc481901c969"
      },
      "source": [
        "## training Dense encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dfdf1bb-0d23-492e-a81c-10498cc04f40",
      "metadata": {
        "id": "6dfdf1bb-0d23-492e-a81c-10498cc04f40"
      },
      "outputs": [],
      "source": [
        "def train(args, dataset, p_model, q_model):\n",
        "    \n",
        "    #dataloader\n",
        "    \n",
        "    train_sampler = RandomSampler(dataset)\n",
        "    train_dataloader = DataLoader(dataset, sampler = train_sampler, batch_size = args.per_device_train_batch_size)\n",
        "    \n",
        "    #optimizer\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params':[p for n,p in p_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':args.weight_decay},\n",
        "        {'params':[p for n,p in p_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay':0.0},\n",
        "        {'params':[p for n,p in q_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':args.weight_decay},\n",
        "        {'params':[p for n,p in q_model.named_parameters() if any(nd in n for nd in no_decay)],'weight_decay':0.0}\n",
        "    ]\n",
        "    \n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr = args.learning_rate, eps = args.adam_epsilon)\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps*args.num_train_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=args.warmup_steps,num_training_steps=t_total)\n",
        "    \n",
        "    global_step = 0\n",
        "    \n",
        "    p_model.zero_grad()\n",
        "    q_model.zero_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    train_iterator = trange(int(args.num_train_epochs), desc='Epoch')\n",
        "    \n",
        "    for _ in train_iterator:\n",
        "        \n",
        "        epoch_iterator = notebook.tqdm(train_dataloader,desc='Iteration')\n",
        "        \n",
        "        for step,batch in enumerate(epoch_iterator):\n",
        "            #q_encoder.train()\n",
        "            #p_encoder.train()\n",
        "            q_model.train()\n",
        "            p_model.train()\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                batch = tuple(t.cuda() for t in batch)\n",
        "                \n",
        "            p_inputs = {'input_ids':batch[0],\n",
        "                       'attention_mask':batch[1],\n",
        "                       'token_type_ids':batch[2]}\n",
        "            \n",
        "            q_inputs = {'input_ids':batch[3],\n",
        "                       'attention_mask':batch[4],\n",
        "                       'token_type_ids':batch[5]}\n",
        "            \n",
        "            p_outputs = p_model(**p_inputs) #(batch_size,emb_dim) #현재 question이랑 대응하는 passage 1개(positive sample)+나머지는 대응하지 않는 batchsize-1개(negative sample)\n",
        "            q_outputs = q_model(**q_inputs) #(batch_size,emb_dim)\n",
        "            \n",
        "            #in-batch negative?? negative sample은 minimize하고 positive sample은 maximize하는 방법?\n",
        "            #이건 생각 좀 많이 해봐야겠는데.. \n",
        "            sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs,0,1))\n",
        "            \n",
        "            #diagonal한 위치에 존재하는 positive sample\n",
        "            targets = torch.arange(0,args.per_device_train_batch_size).long()\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.to('cuda')\n",
        "                \n",
        "            sim_scores = F.log_softmax(sim_scores,dim=1)\n",
        "            \n",
        "            loss = F.nll_loss(sim_scores,targets) \n",
        "            \n",
        "            print(loss)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            q_model.zero_grad()\n",
        "            p_model.zero_grad()\n",
        "            global_step += 1\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "    return p_model,q_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199175e2-9a7a-4655-a125-fa67bc1af8c7",
      "metadata": {
        "id": "199175e2-9a7a-4655-a125-fa67bc1af8c7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(output_dir='dense_retireval',\n",
        "                        evaluation_strategy='epoch',\n",
        "                        learning_rate=2e-5,\n",
        "                        per_device_train_batch_size=16,\n",
        "                        per_device_eval_batch_size=16,\n",
        "                        num_train_epochs=2,\n",
        "                        weight_decay=0.01,\n",
        "                        save_strategy='no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1a69eb-11d6-4565-8bcc-27084957a559",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1c954d1df53c44c9b98cf4fcb73fd1cf"
          ]
        },
        "collapsed": true,
        "id": "aa1a69eb-11d6-4565-8bcc-27084957a559",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6c52573c-7011-4792-a440-ab7e2f5bd47f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "p_encoder,q_encoder = train(args, train_dataset_dense,p_encoder,q_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193f90c9-7338-4927-a1df-c1a478fce4ac",
      "metadata": {
        "id": "193f90c9-7338-4927-a1df-c1a478fce4ac"
      },
      "outputs": [],
      "source": [
        "#save dense encdoer\n",
        "\n",
        "torch.save(p_encoder,'p_encoder_kobert_full_ai_hub.pth')\n",
        "torch.save(q_encoder,'q_encoder_kobert_full_ai_hub.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8d349129-39c2-45f1-a5f3-c7ba8a80812d",
      "metadata": {
        "id": "8d349129-39c2-45f1-a5f3-c7ba8a80812d"
      },
      "source": [
        "## Evaluation dense encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6fe2b2b-dbf3-4b19-baf5-784b47c140c5",
      "metadata": {
        "id": "f6fe2b2b-dbf3-4b19-baf5-784b47c140c5"
      },
      "outputs": [],
      "source": [
        "valid_corpus = list(example['context'] for example in valid_datasets_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1c4475-b606-4b6b-9cff-5e4b8930cd34",
      "metadata": {
        "id": "bf1c4475-b606-4b6b-9cff-5e4b8930cd34"
      },
      "outputs": [],
      "source": [
        "eval_query = valid_datasets_base['question']\n",
        "eval_ground_truth = valid_datasets_base['context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae03dba5-845a-499e-907c-ce314d5ef36f",
      "metadata": {
        "id": "ae03dba5-845a-499e-907c-ce314d5ef36f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "eval_q_seqs = dense_tokenizer(eval_query,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
        "eval_p_seqs = dense_tokenizer(eval_ground_truth,padding='max_length',truncation=True, return_tensors='pt').to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a856f55-01db-44ea-92b7-8ce9aa958cad",
      "metadata": {
        "id": "5a856f55-01db-44ea-92b7-8ce9aa958cad",
        "outputId": "abe6481c-0d5b-4f3b-a501-b5757508005f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([240, 768]) torch.Size([240, 768])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    p_encoder.eval()\n",
        "    q_encoder.eval()\n",
        "    \n",
        "    q_embs = q_encoder(**eval_q_seqs).to('cpu')\n",
        "    \n",
        "    p_embs = p_encoder(**eval_p_seqs).to('cpu')\n",
        "\n",
        "    print(p_embs.size(),q_embs.size()) #(passage 개수, emb_size),(question개수,emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab2a2cb-293f-48f0-904e-f76444c7232c",
      "metadata": {
        "id": "2ab2a2cb-293f-48f0-904e-f76444c7232c"
      },
      "outputs": [],
      "source": [
        "#find top-10\n",
        "\n",
        "accuracy = 0.0\n",
        "k = 10\n",
        "\n",
        "for i,q_emb in enumerate(q_embs):\n",
        "    \n",
        "    dot_product_scores = torch.matmul(q_emb,torch.transpose(p_embs,0,1)) \n",
        "    rank= torch.sort(dot_product_scores,descending=True).indices\n",
        "    \n",
        "    for j in range(k):\n",
        "        if valid_corpus[rank[j]] == eval_ground_truth[i]:\n",
        "            accuracy += 1\n",
        "            break\n",
        "\n",
        "eval_accuracy = accuracy/len(eval_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35aa9aae-f034-4f61-89fa-a90edf0680ba",
      "metadata": {
        "id": "35aa9aae-f034-4f61-89fa-a90edf0680ba",
        "outputId": "1ff1c45c-2c12-4436-daa7-6fa69031fa73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9791666666666666\n"
          ]
        }
      ],
      "source": [
        "print(eval_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6af4d76f-6551-4269-a8cf-0f2cc19f162a",
      "metadata": {
        "id": "6af4d76f-6551-4269-a8cf-0f2cc19f162a"
      },
      "source": [
        "## Define MRC model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20250049-57f3-4b93-93e5-fa6bb2aa45d2",
      "metadata": {
        "id": "20250049-57f3-4b93-93e5-fa6bb2aa45d2",
        "outputId": "fc964e4d-db38-4101-8885-6709452b6c48"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'mrc_model_koelectra_base_v3_discrim_aihub_korquad_save.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-279-33c8b443a7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmrc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mrc_model_koelectra_base_v3_discrim_aihub_korquad_save.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mrc_model_koelectra_base_v3_discrim_aihub_korquad_save.pth'"
          ]
        }
      ],
      "source": [
        "#load model\n",
        "\n",
        "mrc_model = torch.load('mrc_model_koelectra_base_v3_discrim_aihub_korquad_save.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1721cc1-be1e-4350-b1d7-26ff5791afbe",
      "metadata": {
        "id": "c1721cc1-be1e-4350-b1d7-26ff5791afbe"
      },
      "outputs": [],
      "source": [
        "def post_processing_function(examples, features, predictions,training_args):\n",
        "    # Post-processing: we match the start logits and end logits to answers in the original context.\n",
        "    predictions = postprocess_qa_predictions(\n",
        "        examples=examples,\n",
        "        features=features,\n",
        "        predictions=predictions,\n",
        "        version_2_with_negative=False,\n",
        "        n_best_size=n_best_size,\n",
        "        max_answer_length=max_answer_length,\n",
        "        null_score_diff_threshold=0.0,\n",
        "        output_dir=training_args.output_dir,\n",
        "        is_world_process_zero=trainer.is_world_process_zero(),\n",
        "    )\n",
        "    \n",
        "    # Format the result to the format the metric expects.\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
        "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in valid_datasets_base] #change dataset name\n",
        "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aaf7c16-c5a9-47b4-a5f3-719b9e174a14",
      "metadata": {
        "id": "3aaf7c16-c5a9-47b4-a5f3-719b9e174a14"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e28cf5-5d3b-4622-9359-287b0cdea77d",
      "metadata": {
        "id": "01e28cf5-5d3b-4622-9359-287b0cdea77d"
      },
      "outputs": [],
      "source": [
        "mrc_model_name = 'monologg/koelectra-base-v3-discriminator'\n",
        "mrc_tokenizer = AutoTokenizer.from_pretrained(mrc_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69a08fb-89eb-4405-a876-639dfd41c87f",
      "metadata": {
        "id": "e69a08fb-89eb-4405-a876-639dfd41c87f",
        "outputId": "6469fe8d-488b-49c5-f356-aeac0cd6e04f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "file koelectra-base-v3-finetuned-korquad/config.json not found\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Can't load config for 'koelectra-base-v3-finetuned-korquad'. Make sure that:\n\n- 'koelectra-base-v3-finetuned-korquad' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'koelectra-base-v3-finetuned-korquad' is the correct path to a directory containing a config.json file\n\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# File, but it doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: file koelectra-base-v3-finetuned-korquad/config.json not found",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-331-7080028ca11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m config = AutoConfig.from_pretrained(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'koelectra-base-v3-finetuned-korquad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m mrc_model = AutoModelForQuestionAnswering.from_pretrained(\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \"\"\"\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             )\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load config for 'koelectra-base-v3-finetuned-korquad'. Make sure that:\n\n- 'koelectra-base-v3-finetuned-korquad' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'koelectra-base-v3-finetuned-korquad' is the correct path to a directory containing a config.json file\n\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    mrc_model_name\n",
        ")\n",
        "\n",
        "mrc_model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "    mrc_model_name,\n",
        "    config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f71f59-cfc6-42c4-a874-4e5a4b3a6a93",
      "metadata": {
        "id": "31f71f59-cfc6-42c4-a874-4e5a4b3a6a93"
      },
      "outputs": [],
      "source": [
        "#train argument\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"outputs\",\n",
        "    do_train=True, \n",
        "    do_eval=True, \n",
        "    learning_rate=3e-5,\n",
        "    fp16=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='no',\n",
        "    run_name='yun8'\n",
        "    #eval_steps=100,\n",
        "    #evaluation_strategy=\"steps\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b037d24-d5f1-4e2b-89e0-4ceb011de5d1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "1b037d24-d5f1-4e2b-89e0-4ceb011de5d1",
        "outputId": "d828c178-6e91-4b71-bbdd-766fca786037"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:115r2zuu) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 8221<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/opt/ml/wandb/run-20210520_030627-115r2zuu/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/opt/ml/wandb/run-20210520_030627-115r2zuu/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">yun8</strong>: <a href=\"https://wandb.ai/yundaehyuck/huggingface/runs/115r2zuu\" target=\"_blank\">https://wandb.ai/yundaehyuck/huggingface/runs/115r2zuu</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:115r2zuu). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">faithful-forest-68</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/yundaehyuck/uncategorized\" target=\"_blank\">https://wandb.ai/yundaehyuck/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/yundaehyuck/uncategorized/runs/us0hssj6\" target=\"_blank\">https://wandb.ai/yundaehyuck/uncategorized/runs/us0hssj6</a><br/>\n",
              "                Run data is saved locally in <code>/opt/ml/wandb/run-20210520_030740-us0hssj6</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 8254<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/opt/ml/wandb/run-20210520_030740-us0hssj6/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/opt/ml/wandb/run-20210520_030740-us0hssj6/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">faithful-forest-68</strong>: <a href=\"https://wandb.ai/yundaehyuck/uncategorized/runs/us0hssj6\" target=\"_blank\">https://wandb.ai/yundaehyuck/uncategorized/runs/us0hssj6</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#training MRC model with competition data\n",
        "wandb.login()\n",
        "wandb.init()\n",
        "\n",
        "trainer =  QuestionAnsweringTrainer(\n",
        "    model=mrc_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    eval_examples=valid_datasets_base,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=mrc_tokenizer,\n",
        "    post_process_function=post_processing_function,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "31557167-c98b-4c59-b78a-f57d4c1542fd",
      "metadata": {
        "id": "31557167-c98b-4c59-b78a-f57d4c1542fd"
      },
      "source": [
        "## train and evaluation MRC model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1872a24f-a2a6-4bed-a9c5-c3a379849014",
      "metadata": {
        "id": "1872a24f-a2a6-4bed-a9c5-c3a379849014",
        "outputId": "cef97d45-1b56-422d-e338-ffdde87b0064"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='69954' max='69954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [69954/69954 2:35:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.364600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.408700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.416600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.378900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.388800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.385000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.391600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.396100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.394900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.381200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>1.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>1.379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.397300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>1.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.390700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>1.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.410100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>1.391300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>1.371400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.416300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>1.367000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.388900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>1.399600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>1.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>1.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>1.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.390200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>1.391200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>1.387900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>1.369000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.366200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>1.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>1.349600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>1.374400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>1.380100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>1.380600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>1.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>1.345200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>1.314800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>1.329200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>1.316200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>1.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>1.328200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>1.324700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>1.358500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>1.353500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>1.307500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>1.322600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>1.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>1.328500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>1.301600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>1.324800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>1.344300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31500</td>\n",
              "      <td>1.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>1.348000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>1.339400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>1.319800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>1.338100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>1.337200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>1.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>1.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>1.323900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>1.343700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>1.321700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>1.305900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37500</td>\n",
              "      <td>1.335700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>1.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38500</td>\n",
              "      <td>1.335000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>1.321100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39500</td>\n",
              "      <td>1.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>1.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>1.336700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>1.339900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>1.327800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>1.309100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>1.325500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>1.323700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>1.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>1.322500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>1.336600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>1.316400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45500</td>\n",
              "      <td>1.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>1.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46500</td>\n",
              "      <td>1.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>1.312000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47500</td>\n",
              "      <td>1.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>1.279100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48500</td>\n",
              "      <td>1.301400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49000</td>\n",
              "      <td>1.293500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49500</td>\n",
              "      <td>1.294000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>1.297000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50500</td>\n",
              "      <td>1.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51000</td>\n",
              "      <td>1.289400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51500</td>\n",
              "      <td>1.285700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52000</td>\n",
              "      <td>1.292100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52500</td>\n",
              "      <td>1.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53000</td>\n",
              "      <td>1.296700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53500</td>\n",
              "      <td>1.278900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54000</td>\n",
              "      <td>1.280900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54500</td>\n",
              "      <td>1.279100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55000</td>\n",
              "      <td>1.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55500</td>\n",
              "      <td>1.285100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56000</td>\n",
              "      <td>1.287200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56500</td>\n",
              "      <td>1.270700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57000</td>\n",
              "      <td>1.282600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57500</td>\n",
              "      <td>1.298600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58000</td>\n",
              "      <td>1.284900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58500</td>\n",
              "      <td>1.269400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59000</td>\n",
              "      <td>1.278300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59500</td>\n",
              "      <td>1.282500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>1.289800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60500</td>\n",
              "      <td>1.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61000</td>\n",
              "      <td>1.295300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61500</td>\n",
              "      <td>1.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62000</td>\n",
              "      <td>1.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62500</td>\n",
              "      <td>1.294800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63000</td>\n",
              "      <td>1.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63500</td>\n",
              "      <td>1.293400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64000</td>\n",
              "      <td>1.280900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64500</td>\n",
              "      <td>1.282700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65000</td>\n",
              "      <td>1.291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65500</td>\n",
              "      <td>1.275600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66000</td>\n",
              "      <td>1.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66500</td>\n",
              "      <td>1.297300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67000</td>\n",
              "      <td>1.282600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67500</td>\n",
              "      <td>1.280900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68000</td>\n",
              "      <td>1.278300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68500</td>\n",
              "      <td>1.281800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69000</td>\n",
              "      <td>1.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69500</td>\n",
              "      <td>1.282000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_result = trainer.train() #training|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bc8d62-6781-4f7c-a372-9c01cf37a889",
      "metadata": {
        "id": "76bc8d62-6781-4f7c-a372-9c01cf37a889",
        "outputId": "c498975b-7a40-4ae7-da37-0f263997beaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=69954, training_loss=1.3339420855957018, metrics={'train_runtime': 9320.4686, 'train_samples_per_second': 7.505, 'total_flos': 1.4484037044621312e+17, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 779022, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 6965806, 'init_mem_gpu_peaked_delta': 512, 'train_mem_cpu_alloc_delta': 425329921, 'train_mem_gpu_alloc_delta': 899784192, 'train_mem_cpu_peaked_delta': 7275759, 'train_mem_gpu_peaked_delta': 3590787072})"
            ]
          },
          "execution_count": 277,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54750bf3-f6eb-4814-a714-73b7f94b312c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8e93520cb0e94eb6aa4ea2211b61d162"
          ]
        },
        "id": "54750bf3-f6eb-4814-a714-73b7f94b312c",
        "outputId": "38e10e7b-ec39-4ff2-bf5d-3e9ae6a7c8b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1436' max='1436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1436/1436 00:44]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e93520cb0e94eb6aa4ea2211b61d162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 69954 < 69955; dropping {'train/exact_match': 37.083333333333336, 'train/f1': 44.3331450956451, 'train/epoch': 3.0}.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "metrics = trainer.evaluate() #evaluation|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "265f2348-63e9-4d56-92c4-87c7555d2a0e",
      "metadata": {
        "id": "265f2348-63e9-4d56-92c4-87c7555d2a0e"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "\n",
        "torch.save(mrc_model,'mrc_model_koelectra_base_v3_discrim_korquad_aihub_1epoch_retrain.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5929da85-8a60-4da6-9985-106d339969a3",
      "metadata": {
        "id": "5929da85-8a60-4da6-9985-106d339969a3"
      },
      "source": [
        "## Final Open domain question answering"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f7140d27-e807-4b79-800b-9756ef7f3e40",
      "metadata": {
        "id": "f7140d27-e807-4b79-800b-9756ef7f3e40"
      },
      "source": [
        "## inference funtion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07bd37f-e2e1-4a35-82bb-b10c553c7a5f",
      "metadata": {
        "id": "c07bd37f-e2e1-4a35-82bb-b10c553c7a5f"
      },
      "outputs": [],
      "source": [
        "stopwords = ['','요새','유독','가끔','틀림없이','때로','필수','최소한','최소','오로지','어차피','다소','이미','만약에','줄곧','꼭','종종','약간','자칫','너무','아예','반드시','비록','한때','만약','무조건',\"릴리안느의 폭정에 반기를 들었기 때문이다.하지만 그냥 죽이기엔 그를 따르는 자가 너무\",\"집단 극화를 거쳐 받아들여진 신념은 개인의 정체성을 형성하는 요소가 된다. 때로\",\n",
        "                                                        '어쩔','때때로','왜냐하면','대략','있었','급격히','적어도','점차','만일','언젠가','꾸준히','굳이','이따금','심지어','오직','너무나','감히','어쨌든','절대로','괜찮다고','문득','가끔 (대략','설마','괜찮',\"너무 많은걸 알게된 오드리는 횡설수설했고 남자들 역시 별다른 소득이 없자 순순히\",\"왜냐하면 내가 생각\",'서서히',\n",
        "                                                        '최소화하여 수성에 접근하기 위해서는 필수','기꺼이','결코','근데','어느덧','우선','비밀리에','순순히','마땅히','절대',\"비록 난폭할지라도 어찌 감히\",\"식민지의 항만 방어를 위해 요새\",\"왜냐하면 내가 생각하는 일을 아주 중지해 버린다면 다음 순간\",\"하루에 토끼 310마리를 잡았으며 꿩, 너구리, 사슴은 그 수를 헤아릴 수 없을 정도\",\n",
        "                                                        \"아무래도 좋다\\\"라고 장자는 말한다. '앎'에는 어떤 확실한 판단은 없으니까, 생각해도 어쩔\",'차츰','일부러','쉽사리',\"너무 많았고 알렌을 시켜 암살한다.\",\"내가 생각할 동안이다. 왜냐하면\",\"다소 포괄적으로 활용되고 있는데 이를 정의할 때 가장 중요한 요소는 학습자이다. 게임이나 시뮬레이션에는 학습 목적\",\n",
        "                                                        \"가덕수로를 따라 올라가야 하는 곳이며 그 곳에 일본군들은 눌차왜성\",'아무래도',\"너무나 힘든 세상에 도날드 덕은 암소를 죽여 고기를 먹으려고 한다. 그것을 말린 구피와 미키. 어느덧\",\"변경 변화점에 집중되어 이루어져야 한다. 만약\",\"너무 많았고 알렌을 시켜 암살한다. :릴리안느에게는 약혼자 마론왕국\",\"다케다는\",\n",
        "                                                         \"주류 기독교 교파들은 메시아 유대교를 기독교의 한 종파로 받아들인다 메시아 유대교의 몇몇 지지자들\",\"대포를 해안포로 활용한 것은 16세기 유럽에서 시작되었다. 유럽 본토와 식민지의 항만 방어를 위해 요새\",\"비록 되어 여러분으로 완성된다는 것을 결코 잊지 않겠습니다. 감사합니다.}} 한번 문 사건은 절대\",\n",
        "                                                         \"장소에 있지 않았으나 다른 이들로부터 그 내용을 전해들은 것이다. 곳샬크는, '역사가는 이따금\",\"만약 갑의 가치가 800, 을의 피해는 500일 때도 코스의 정리는 성립한다. 비록\",\"대중들의 독재인가?”라는 하나의 문제 제기는 이미\",\"비록 당장은 진나라의 세력이 강해 점령지의 군민들을 힘으로 누르고 있어 감히 반기를 들지 못하지만, 만일\",\n",
        "                                                         \"레온하르트가 자주 릴리안느의 폭정에 반기를 들었기 때문이다.하지만 그냥 죽이기엔 그를 따르는 자가 너무\",\"이따금 소문에 의한 증거를 사용할 수 있음'을 지적한다. 어쨌거나, 2차 목격자\",\"점차 약화하였으며, '닉슨 독트린' 이후로 급격히\",\"학습 게임과 시뮬레이션이라는 용어는 다소\",\"괜찮다고 말했다. 행인은 괜찮지 않다고\",\n",
        "                                                         \"최소한 500이상을 받으면 되기 때문에, 500~ 800 사이에서 갑은 이를 기꺼이\",\"오직 십자가의 무조건\",\"너무 많았고 알렌을 시켜 암살한다. :릴리안느\",\"항만 방어를 위해 요새\",'대뜸','너무 많았고 알렌','곧잘',\"내부 비평이라 한다. R. J. 샤퍼(Shafer)는 '외부 비평은 이따금\",\"방어를 위해 요새\",\"때로는 서로 경쟁하고, 때로\",\n",
        "                                                         \"비록 되어 여러분으로 완성된다는 것을 결코\",\"유럽 본토와 식민지의 항만 방어를 위해 요새\",\"생각할 동안이다. 왜냐하면\",\"휘발성 물질은 무엇인가 학습 게임과 시뮬레이션이라는 용어는 다소\",\"각본가로서 먹고 살기 어려울 것이라는 생각 때문에, 꾸준히\",'베다는','감각기에',\"너무 많았고 알렌을 시켜 암살한다. :릴리안느에게는 약혼자 마론왕국의 젊은 왕 카일 마론\"\n",
        "                                                        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3dcc72-e261-4a8b-a7f0-494619d8227d",
      "metadata": {
        "id": "0f3dcc72-e261-4a8b-a7f0-494619d8227d"
      },
      "outputs": [],
      "source": [
        "#passage dense embedding\n",
        "def document_embedding(p_encoder,corpus,tokenizer):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        p_encoder.eval()\n",
        "        \n",
        "        p_embs=[]\n",
        "\n",
        "        for p in notebook.tqdm(corpus):\n",
        "            p_seqs = tokenizer(p,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
        "            p_emb = p_encoder(**p_seqs).to('cpu').numpy()\n",
        "            del p_seqs\n",
        "            torch.cuda.empty_cache()\n",
        "            p_embs.append(p_emb)\n",
        "            \n",
        "    p_embs = torch.Tensor(p_embs).squeeze()\n",
        "    \n",
        "    return p_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee171c22-106e-448b-8f60-1aab7d73b6da",
      "metadata": {
        "id": "ee171c22-106e-448b-8f60-1aab7d73b6da"
      },
      "outputs": [],
      "source": [
        "#define get test dataset function\n",
        "\n",
        "def prepare_test_dataset(test_dataset,contexts,query_passage_score,rank):\n",
        "    \n",
        "    context_list = []\n",
        "    score_list = []\n",
        "    id_score_list = []\n",
        "\n",
        "    for _,context_id,score in notebook.tqdm(query_passage_score):\n",
        "        context_list.append(contexts[context_id[rank]])\n",
        "        score_list.append(score[rank])\n",
        "    \n",
        "    test_dataset = test_dataset['validation']\n",
        "    test_id_list = test_dataset['id']\n",
        "    test_query_list = test_dataset['question']\n",
        "    \n",
        "    \n",
        "    for a,b in zip(test_id_list,score_list):\n",
        "        id_score_list.append((a,b))\n",
        "        \n",
        "    \n",
        "    test_dict = {'id':test_id_list,'question':test_query_list,'context':context_list}\n",
        "    \n",
        "    f = Features({'context': Value(dtype='string', id=None),\n",
        "                      'id': Value(dtype='string', id=None),\n",
        "                      'question': Value(dtype='string', id=None)})\n",
        "    \n",
        "    test_data = DatasetDict({'test': Dataset.from_dict(test_dict, features=f)})\n",
        "    \n",
        "    raw_test_dataset = test_data['test']\n",
        "    \n",
        "    pad_on_right = mrc_tokenizer.padding_side == \"right\"\n",
        "\n",
        "    test_dataset = raw_test_dataset.map(\n",
        "        prepare_test_features,\n",
        "        batched=True,\n",
        "        remove_columns=raw_test_dataset.column_names\n",
        "    )\n",
        "    \n",
        "    return raw_test_dataset,test_dataset,id_score_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde8e7fd-70cc-4d39-b83f-2c058c1f4093",
      "metadata": {
        "id": "bde8e7fd-70cc-4d39-b83f-2c058c1f4093"
      },
      "outputs": [],
      "source": [
        "def prepare_test_dataset_multiple(test_dataset,contexts,query_passage_score):\n",
        "    \n",
        "    context_list = []\n",
        "\n",
        "    for _,context_id,_ in notebook.tqdm(query_passage_score):\n",
        "        \n",
        "        context = ''\n",
        "        \n",
        "        for idx in context_id:\n",
        "            context = context + ' ' + contexts[idx]\n",
        "        \n",
        "        context_list.append(context)\n",
        "    \n",
        "    test_dataset = test_dataset['validation']\n",
        "    test_id_list = test_dataset['id']\n",
        "    test_query_list = test_dataset['question']\n",
        "        \n",
        "    \n",
        "    test_dict = {'id':test_id_list,'question':test_query_list,'context':context_list}\n",
        "    \n",
        "    f = Features({'context': Value(dtype='string', id=None),\n",
        "                      'id': Value(dtype='string', id=None),\n",
        "                      'question': Value(dtype='string', id=None)})\n",
        "    \n",
        "    test_data = DatasetDict({'test': Dataset.from_dict(test_dict, features=f)})\n",
        "    \n",
        "    raw_test_dataset = test_data['test']\n",
        "    \n",
        "    pad_on_right = mrc_tokenizer.padding_side == \"right\"\n",
        "\n",
        "    test_dataset = raw_test_dataset.map(\n",
        "        prepare_test_features,\n",
        "        batched=True,\n",
        "        remove_columns=raw_test_dataset.column_names\n",
        "    )\n",
        "    \n",
        "    return raw_test_dataset,test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d54713f4-fb50-419b-b482-b31489c191a2",
      "metadata": {
        "id": "d54713f4-fb50-419b-b482-b31489c191a2"
      },
      "outputs": [],
      "source": [
        "def find_retrieve_score(example_id,id_score_list):\n",
        "    \n",
        "    for ex_id,score in id_score_list:\n",
        "        if example_id == ex_id:\n",
        "            return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd4f750-87b3-4b7a-97bb-75cfa1aea456",
      "metadata": {
        "id": "5dd4f750-87b3-4b7a-97bb-75cfa1aea456"
      },
      "outputs": [],
      "source": [
        "#define get_relevant_document function\n",
        "\n",
        "def get_relevant_doc(q_encoder,query_list,p_embs,k=1): \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        q_encoder.eval()\n",
        "        \n",
        "        q_seqs_list = dense_tokenizer(query_list,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
        "        \n",
        "        q_embs = q_encoder(**q_seqs_list).to('cpu')\n",
        "        \n",
        "        del q_seqs_list\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        query_passage_score = []\n",
        "        \n",
        "        for i,q_emb in notebook.tqdm(enumerate(q_embs)):\n",
        "    \n",
        "            dot_product_scores = torch.matmul(q_emb,torch.transpose(p_embs,0,1)) \n",
        "            rank,score= torch.sort(dot_product_scores,descending=True).indices,torch.sort(dot_product_scores,descending=True).values\n",
        "            query_passage_score.append((query_list[i],rank[:k],score[:k]))\n",
        "\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87fb43f-8f77-4af1-af49-86fbd2f20b8e",
      "metadata": {
        "id": "f87fb43f-8f77-4af1-af49-86fbd2f20b8e"
      },
      "outputs": [],
      "source": [
        "def get_relevant_dense_doc_from_sparse(q_encoder,query_list,p_embs,query_passage_score_sparse,k=1): \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        q_encoder.eval()\n",
        "        \n",
        "        q_seqs_list = dense_tokenizer(query_list,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
        "        \n",
        "        q_embs = q_encoder(**q_seqs_list).to('cpu')\n",
        "        \n",
        "        del q_seqs_list\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        query_passage_score = []\n",
        "        \n",
        "        for i,a in notebook.tqdm(enumerate(query_passage_score_sparse)):\n",
        "            \n",
        "            query,doc_id,doc_score = a\n",
        "    \n",
        "            dot_product_scores = torch.matmul(q_embs[i],torch.transpose(p_embs[doc_id],0,1)) \n",
        "            rank,score= torch.sort(dot_product_scores,descending=True).indices,torch.sort(dot_product_scores,descending=True).values\n",
        "            query_passage_score.append((query,doc_id[rank[:k]],score[:k]))\n",
        "\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c0b5b6-3faa-4cd1-acfb-85f3a30ab2ad",
      "metadata": {
        "id": "21c0b5b6-3faa-4cd1-acfb-85f3a30ab2ad"
      },
      "outputs": [],
      "source": [
        "#define get_relevant_document_sparse function\n",
        "\n",
        "def get_relevant_doc_sparse(sp_matrix, vectorizer, query_list,k=1): \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        query_passage_score = []\n",
        "        \n",
        "        for query in notebook.tqdm(query_list):\n",
        "            \n",
        "            query_vec= vectorizer.transform([query])\n",
        "            \n",
        "            result = query_vec * sp_matrix.T\n",
        "            \n",
        "            sorted_result = np.argsort(-result.data)\n",
        "            doc_scores = result.data[sorted_result]\n",
        "            doc_ids = result.indices[sorted_result]\n",
        "            \n",
        "\n",
        "            query_passage_score.append((query,doc_ids[:k],doc_scores[:k]))\n",
        "\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea8aa14-9e79-4cc5-8804-310904530dd8",
      "metadata": {
        "id": "aea8aa14-9e79-4cc5-8804-310904530dd8"
      },
      "outputs": [],
      "source": [
        "#define get_relevant_document_concat function\n",
        "\n",
        "def get_relevant_doc_concat(q_encoder,p_embs,sp_matrix,vectorizer,query_list,k=1):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        q_encoder.eval()\n",
        "        \n",
        "        q_seqs_list = dense_tokenizer(query_list,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
        "        \n",
        "        q_embs = q_encoder(**q_seqs_list).to('cpu')\n",
        "        \n",
        "        del q_seqs_list\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        query_passage_score = []\n",
        "        \n",
        "        for q_emb,query in notebook.tqdm(zip(q_embs,query_list)):\n",
        "    \n",
        "            dot_product_scores_dense = torch.matmul(q_emb,torch.transpose(p_embs,0,1))\n",
        "            \n",
        "            query_vec= vectorizer.transform([query])\n",
        "            \n",
        "            dot_product_scores_sparse = torch.tensor((query_vec * sp_matrix.T).toarray())\n",
        "            \n",
        "            #dot_product_scores = (dot_product_scores_dense/sum(dot_product_scores_dense)) + (dot_product_scores_sparse.squeeze()/sum(dot_product_scores_sparse.squeeze()))\n",
        "            \n",
        "            dot_product_zscores_dense = ((dot_product_scores_dense-torch.mean(dot_product_scores_dense))/torch.std(dot_product_scores_dense))\n",
        "            \n",
        "            dot_product_zscores_sparse = ((dot_product_scores_sparse.squeeze()-torch.mean(dot_product_scores_sparse.squeeze()))/torch.std(dot_product_scores_sparse.squeeze()))\n",
        "            \n",
        "            dot_product_scores = dot_product_zscores_dense+dot_product_zscores_sparse\n",
        "            \n",
        "            rank,score= torch.sort(dot_product_scores,descending=True).indices,torch.sort(dot_product_scores,descending=True).values\n",
        "            \n",
        "            query_passage_score.append((query,rank[:k],score[:k]))\n",
        "            \n",
        "    \n",
        "    return query_passage_score\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7350d5-a7e9-49e2-af3c-5ecf05df46cf",
      "metadata": {
        "id": "ee7350d5-a7e9-49e2-af3c-5ecf05df46cf"
      },
      "outputs": [],
      "source": [
        "#define get_answer_from_context function\n",
        "\n",
        "def get_answer_from_context(context, test_dataset, id_score_list, model):\n",
        "    \n",
        "    example_id = test_dataset['example_id']\n",
        "    \n",
        "    retrieve_score = find_retrieve_score(example_id,id_score_list)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': torch.tensor([test_dataset['input_ids']], dtype=torch.long).to('cuda'),\n",
        "            'attention_mask': torch.tensor([test_dataset['attention_mask']], dtype=torch.long).to('cuda'),\n",
        "            'token_type_ids': torch.tensor([test_dataset['token_type_ids']], dtype=torch.long).to('cuda')\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        start_logits = outputs.start_logits[0].cpu().numpy()\n",
        "        softmax_start = F.softmax(torch.tensor(start_logits),dim=0).cpu().numpy()\n",
        "        end_logits = outputs.end_logits[0].cpu().numpy()\n",
        "        softmax_end = F.softmax(torch.tensor(end_logits),dim=0).cpu().numpy()\n",
        "        \n",
        "        offset_mapping = test_dataset[\"offset_mapping\"]\n",
        "\n",
        "\n",
        "        # Gather the indices the best start/end logits:\n",
        "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        \n",
        "\n",
        "        valid_answers = []\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                # to part of the input_ids that are not in the context.\n",
        "                if (\n",
        "                    start_index >= len(offset_mapping)\n",
        "                    or end_index >= len(offset_mapping)\n",
        "                    or offset_mapping[start_index] is None\n",
        "                    or offset_mapping[end_index] is None\n",
        "                ):\n",
        "                    continue\n",
        "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                    continue\n",
        "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    \n",
        "                    if context[start_char: end_char] in stopwords:\n",
        "                        pass\n",
        "                    elif '[UNK]' in context[start_char: end_char]:\n",
        "                        pass\n",
        "                    else:\n",
        "                        valid_answers.append(\n",
        "                            {\n",
        "                                #\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                'score': softmax_start[start_index] * softmax_end[end_index] + retrieve_score,\n",
        "                                \"text\": context[start_char: end_char],\n",
        "                                'id' : example_id\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "        #valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0, 'id':example_id}\n",
        "\n",
        "        \n",
        "        \n",
        "    return best_answer\n",
        "    #return valid_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae6f1bc-1d5a-4c2a-8c98-3968471c7197",
      "metadata": {
        "id": "7ae6f1bc-1d5a-4c2a-8c98-3968471c7197"
      },
      "outputs": [],
      "source": [
        "def feature_per_example(raw_test_dataset,test_dataset):\n",
        "    \n",
        "    example_id_to_index = {k: i for i, k in enumerate(raw_test_dataset[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    \n",
        "    for i, feature in enumerate(notebook.tqdm(test_dataset)):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "    \n",
        "    return features_per_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae4e891-55e6-43c2-bcc2-13547ee1a1fa",
      "metadata": {
        "id": "0ae4e891-55e6-43c2-bcc2-13547ee1a1fa"
      },
      "outputs": [],
      "source": [
        "def get_answer_from_multiple_context(context, test_dataset, model):\n",
        "    \n",
        "    example_id = test_dataset['example_id']\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': torch.tensor([test_dataset['input_ids']], dtype=torch.long).to('cuda'),\n",
        "            'attention_mask': torch.tensor([test_dataset['attention_mask']], dtype=torch.long).to('cuda'),\n",
        "            'token_type_ids': torch.tensor([test_dataset['token_type_ids']], dtype=torch.long).to('cuda')\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        start_logits = outputs.start_logits[0].cpu().numpy()\n",
        "        softmax_start = F.softmax(torch.tensor(start_logits),dim=0).cpu().numpy()\n",
        "        end_logits = outputs.end_logits[0].cpu().numpy()\n",
        "        softmax_end = F.softmax(torch.tensor(end_logits),dim=0).cpu().numpy()\n",
        "        \n",
        "        offset_mapping = test_dataset[\"offset_mapping\"]\n",
        "        \n",
        "        # Gather the indices the best start/end logits:\n",
        "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        \n",
        "\n",
        "        valid_answers = []\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                # to part of the input_ids that are not in the context.\n",
        "                if (\n",
        "                    start_index >= len(offset_mapping)\n",
        "                    or end_index >= len(offset_mapping)\n",
        "                    or offset_mapping[start_index] is None\n",
        "                    or offset_mapping[end_index] is None\n",
        "                ):\n",
        "                    continue\n",
        "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                    continue\n",
        "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    \n",
        "                    if context[start_char: end_char] in stopwords:\n",
        "                        pass\n",
        "                    elif '[UNK]' in context[start_char: end_char]:\n",
        "                        pass\n",
        "                    else:\n",
        "                        valid_answers.append(\n",
        "                            {\n",
        "                                #\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                'score': softmax_start[start_index] + softmax_end[end_index],\n",
        "                                \"text\": context[start_char: end_char],\n",
        "                                'id' : example_id\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "        #valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0, 'id':example_id}\n",
        "\n",
        "        \n",
        "        \n",
        "    return best_answer\n",
        "    #return valid_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c8584c-55db-4626-96fb-4e169b9d3a04",
      "metadata": {
        "id": "63c8584c-55db-4626-96fb-4e169b9d3a04"
      },
      "outputs": [],
      "source": [
        "#define ensemble three function\n",
        "\n",
        "def get_answer_from_context_ensemble_five(context,test_dataset, id_score_list, model1, model2, model3,model4,model5):\n",
        "    \n",
        "    example_id = test_dataset['example_id']\n",
        "    \n",
        "    retrieve_score = find_retrieve_score(example_id,id_score_list)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model1.eval()\n",
        "        model2.eval()\n",
        "        model3.eval()\n",
        "        model4.eval()\n",
        "        model5.eval()\n",
        "        \n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': torch.tensor([test_dataset['input_ids']], dtype=torch.long).to('cuda'),\n",
        "            'attention_mask': torch.tensor([test_dataset['attention_mask']], dtype=torch.long).to('cuda'),\n",
        "            'token_type_ids': torch.tensor([test_dataset['token_type_ids']], dtype=torch.long).to('cuda')\n",
        "        }\n",
        "\n",
        "        outputs1 = model1(**inputs)\n",
        "        outputs2 = model2(**inputs)\n",
        "        outputs3 = model3(**inputs)\n",
        "        outputs4 = model4(**inputs)\n",
        "        outputs5 = model5(**inputs)\n",
        "\n",
        "        start_logits1 = outputs1.start_logits[0].cpu().numpy()\n",
        "        softmax_start1 = F.softmax(torch.tensor(start_logits1),dim=0).cpu().numpy()\n",
        "        end_logits1 = outputs1.end_logits[0].cpu().numpy()\n",
        "        softmax_end1 = F.softmax(torch.tensor(end_logits1),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits2 = outputs2.start_logits[0].cpu().numpy()\n",
        "        softmax_start2 = F.softmax(torch.tensor(start_logits2),dim=0).cpu().numpy()\n",
        "        end_logits2 = outputs2.end_logits[0].cpu().numpy()\n",
        "        softmax_end2 = F.softmax(torch.tensor(end_logits2),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits3 = outputs3.start_logits[0].cpu().numpy()\n",
        "        softmax_start3 = F.softmax(torch.tensor(start_logits3),dim=0).cpu().numpy()\n",
        "        end_logits3 = outputs3.end_logits[0].cpu().numpy()\n",
        "        softmax_end3 = F.softmax(torch.tensor(end_logits3),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits4 = outputs4.start_logits[0].cpu().numpy()\n",
        "        softmax_start4 = F.softmax(torch.tensor(start_logits4),dim=0).cpu().numpy()\n",
        "        end_logits4 = outputs4.end_logits[0].cpu().numpy()\n",
        "        softmax_end4 = F.softmax(torch.tensor(end_logits4),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits5 = outputs5.start_logits[0].cpu().numpy()\n",
        "        softmax_start5 = F.softmax(torch.tensor(start_logits5),dim=0).cpu().numpy()\n",
        "        end_logits5 = outputs5.end_logits[0].cpu().numpy()\n",
        "        softmax_end5 = F.softmax(torch.tensor(end_logits5),dim=0).cpu().numpy()\n",
        "        \n",
        "        \n",
        "        softmax_start = (softmax_start1+softmax_start2+softmax_start3+softmax_start4+softmax_start5)/5\n",
        "        softmax_end = (softmax_end1+softmax_end2+softmax_end3+softmax_end4+softmax_end5)/5\n",
        "        \n",
        "        \n",
        "        offset_mapping = test_dataset[\"offset_mapping\"]\n",
        "\n",
        "\n",
        "        # Gather the indices the best start/end logits:\n",
        "        start_indexes = np.argsort(softmax_start)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(softmax_end)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        \n",
        "\n",
        "        valid_answers = []\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                # to part of the input_ids that are not in the context.\n",
        "                if (\n",
        "                    start_index >= len(offset_mapping)\n",
        "                    or end_index >= len(offset_mapping)\n",
        "                    or offset_mapping[start_index] is None\n",
        "                    or offset_mapping[end_index] is None\n",
        "                ):\n",
        "                    continue\n",
        "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                    continue\n",
        "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    \n",
        "                    if context[start_char: end_char] in stopwords:\n",
        "                        pass\n",
        "                    elif '[UNK]' in context[start_char: end_char]:\n",
        "                        pass\n",
        "                    else:\n",
        "                        valid_answers.append(\n",
        "                            {\n",
        "                                #\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                'score': softmax_start[start_index] * softmax_end[end_index],# retrieve_score,\n",
        "                                \"text\": context[start_char: end_char],\n",
        "                                'id' : example_id\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "        #valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0, 'id':example_id}\n",
        "\n",
        "        \n",
        "        \n",
        "    return best_answer\n",
        "    #return valid_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbf0489-7b18-4bdc-8302-6da7f2a38424",
      "metadata": {
        "id": "8bbf0489-7b18-4bdc-8302-6da7f2a38424"
      },
      "outputs": [],
      "source": [
        "def get_answer_from_multiple_context_ensemble_five(context,\n",
        "                                                    test_dataset, model1, model2, model3, model4):\n",
        "    \n",
        "    example_id = test_dataset['example_id']\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model1.eval()\n",
        "        model2.eval()\n",
        "        model3.eval()\n",
        "        model4.eval()\n",
        "        #model5.eval()\n",
        "        \n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': torch.tensor([test_dataset['input_ids']], dtype=torch.long).to('cuda'),\n",
        "            'attention_mask': torch.tensor([test_dataset['attention_mask']], dtype=torch.long).to('cuda'),\n",
        "            'token_type_ids': torch.tensor([test_dataset['token_type_ids']], dtype=torch.long).to('cuda')\n",
        "        }\n",
        "\n",
        "        outputs1 = model1(**inputs)\n",
        "        outputs2 = model2(**inputs)\n",
        "        outputs3 = model3(**inputs)\n",
        "        outputs4 = model4(**inputs)\n",
        "        #outputs5 = model5(**inputs)\n",
        "\n",
        "        start_logits1 = outputs1.start_logits[0].cpu().numpy()\n",
        "        softmax_start1 = F.softmax(torch.tensor(start_logits1),dim=0).cpu().numpy()\n",
        "        end_logits1 = outputs1.end_logits[0].cpu().numpy()\n",
        "        softmax_end1 = F.softmax(torch.tensor(end_logits1),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits2 = outputs2.start_logits[0].cpu().numpy()\n",
        "        softmax_start2 = F.softmax(torch.tensor(start_logits2),dim=0).cpu().numpy()\n",
        "        end_logits2 = outputs2.end_logits[0].cpu().numpy()\n",
        "        softmax_end2 = F.softmax(torch.tensor(end_logits2),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits3 = outputs3.start_logits[0].cpu().numpy()\n",
        "        softmax_start3 = F.softmax(torch.tensor(start_logits3),dim=0).cpu().numpy()\n",
        "        end_logits3 = outputs3.end_logits[0].cpu().numpy()\n",
        "        softmax_end3 = F.softmax(torch.tensor(end_logits3),dim=0).cpu().numpy()\n",
        "        \n",
        "        start_logits4 = outputs4.start_logits[0].cpu().numpy()\n",
        "        softmax_start4 = F.softmax(torch.tensor(start_logits4),dim=0).cpu().numpy()\n",
        "        end_logits4 = outputs4.end_logits[0].cpu().numpy()\n",
        "        softmax_end4 = F.softmax(torch.tensor(end_logits4),dim=0).cpu().numpy()\n",
        "        \n",
        "        #start_logits5 = outputs5.start_logits[0].cpu().numpy()\n",
        "        #softmax_start5 = F.softmax(torch.tensor(start_logits5),dim=0).cpu().numpy()\n",
        "        #end_logits5 = outputs5.end_logits[0].cpu().numpy()\n",
        "        #softmax_end5 = F.softmax(torch.tensor(end_logits5),dim=0).cpu().numpy()\n",
        "        \n",
        "        \n",
        "        softmax_start = (softmax_start1+softmax_start2+softmax_start3+softmax_start4)/4\n",
        "        softmax_end = (softmax_end1+softmax_end2+softmax_end3+softmax_end4)/4\n",
        "        \n",
        "        \n",
        "        offset_mapping = test_dataset[\"offset_mapping\"]\n",
        "\n",
        "        # Gather the indices the best start/end logits:\n",
        "        start_indexes = np.argsort(softmax_start)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(softmax_end)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "        \n",
        "\n",
        "        valid_answers = []\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                # to part of the input_ids that are not in the context.\n",
        "                if (\n",
        "                    start_index >= len(offset_mapping)\n",
        "                    or end_index >= len(offset_mapping)\n",
        "                    or offset_mapping[start_index] is None\n",
        "                    or offset_mapping[end_index] is None\n",
        "                ):\n",
        "                    continue\n",
        "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                if (end_index < start_index) or (end_index - start_index + 1 > max_answer_length):\n",
        "                    continue\n",
        "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    \n",
        "                    if context[start_char: end_char] in stopwords:\n",
        "                        pass\n",
        "                    elif '[UNK]' in context[start_char: end_char]:\n",
        "                        pass\n",
        "                        \n",
        "                    #elif len(context[start_char: end_char]) > 35:\n",
        "                        #continue\n",
        "                    else:\n",
        "                        valid_answers.append(\n",
        "                            {\n",
        "                                #\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                'score': softmax_start[start_index] + softmax_end[end_index],\n",
        "                                \"text\": context[start_char: end_char],\n",
        "                                'id' : example_id\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "        #valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0, 'id':example_id}\n",
        "\n",
        "        \n",
        "        \n",
        "    return best_answer\n",
        "    #return valid_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f271a11a-da04-485d-90ad-523128b9a5b7",
      "metadata": {
        "id": "f271a11a-da04-485d-90ad-523128b9a5b7"
      },
      "outputs": [],
      "source": [
        "def prepare_test_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = mrc_tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fdb8eb-7947-445c-a681-10f92ac8cd57",
      "metadata": {
        "id": "a8fdb8eb-7947-445c-a681-10f92ac8cd57"
      },
      "outputs": [],
      "source": [
        "def write_prediction_dict(raw_test_dataset,test_dataset,id_score_list,features_per_example):\n",
        "    \n",
        "    prediction_dict = {}\n",
        "    \n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        \n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_context(raw_test_dataset[example_index]['context'], test_dataset[index], id_score_list, mrc_model)\n",
        "        \n",
        "            try:\n",
        "\n",
        "                 if len(prediction_dict[answer['id']])==2:\n",
        "\n",
        "                    if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                        prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "            except KeyError:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "                \n",
        "    \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e143f85-2ef5-43b7-afc0-efb22c228e1e",
      "metadata": {
        "id": "5e143f85-2ef5-43b7-afc0-efb22c228e1e"
      },
      "outputs": [],
      "source": [
        "def write_prediction_dict_multiple(raw_test_dataset, test_dataset, features_per_example):\n",
        "    \n",
        "    prediction_dict = {}\n",
        "        \n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        \n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_multiple_context(raw_test_dataset[example_index]['context'], test_dataset[index], mrc_model)\n",
        "        \n",
        "            try:\n",
        "\n",
        "                 if len(prediction_dict[answer['id']])==2:\n",
        "\n",
        "                    if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                        prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "            except KeyError:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "                \n",
        "    \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5be0fa71-89cf-452a-8b5a-3cb99bf222e0",
      "metadata": {
        "id": "5be0fa71-89cf-452a-8b5a-3cb99bf222e0"
      },
      "outputs": [],
      "source": [
        "def write_prediction_dict_ensemble_five(raw_test_dataset, test_dataset, id_score_list, features_per_example):\n",
        "    \n",
        "    prediction_dict = {}\n",
        "\n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_context_ensemble_five(raw_test_dataset[example_index]['context'], test_dataset[index], id_score_list, mrc_model1,mrc_model2,mrc_model3,\n",
        "                                                           mrc_model4,mrc_model5)\n",
        "\n",
        "            try:\n",
        "\n",
        "                 if len(prediction_dict[answer['id']])==2:\n",
        "\n",
        "                    if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                        prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "            except KeyError:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "                \n",
        "    \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bb258d-61d1-46fb-873b-6fb021579a01",
      "metadata": {
        "id": "23bb258d-61d1-46fb-873b-6fb021579a01"
      },
      "outputs": [],
      "source": [
        "def write_prediction_dict_ensemble_five_multiple(raw_test_dataset, test_dataset, features_per_example):\n",
        "    \n",
        "    prediction_dict = {}\n",
        "    \n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        \n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_multiple_context_ensemble_five(raw_test_dataset[example_index]['context'], test_dataset[index], mrc_model1, mrc_model2, mrc_model3,\n",
        "                                                                    mrc_model4)\n",
        "            try:\n",
        "\n",
        "                 if len(prediction_dict[answer['id']])==2:\n",
        "\n",
        "                    if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                        prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "            except KeyError:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "\n",
        "                \n",
        "    \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd5e4fd-51b0-4263-b450-b151c86bfb19",
      "metadata": {
        "id": "8dd5e4fd-51b0-4263-b450-b151c86bfb19"
      },
      "outputs": [],
      "source": [
        "def rewrite_prediction_dict(prediction_dict,raw_test_dataset,test_dataset,id_score_list,features_per_example):\n",
        "    \n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        \n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_context(raw_test_dataset[example_index]['context'], test_dataset[index], id_score_list, mrc_model)\n",
        "        \n",
        "\n",
        "            if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "                \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709ef365-841b-4136-a9b7-f5c108aa57d9",
      "metadata": {
        "id": "709ef365-841b-4136-a9b7-f5c108aa57d9"
      },
      "outputs": [],
      "source": [
        "def rewrite_prediction_dict_ensemble_five(prediction_dict,raw_test_dataset,test_dataset,id_score_list,features_per_example):\n",
        "    \n",
        "    for example_index, _ in enumerate(notebook.tqdm(raw_test_dataset)):\n",
        "\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        \n",
        "        for index in feature_indices:\n",
        "\n",
        "            answer = get_answer_from_context_ensemble_five(raw_test_dataset[example_index]['context'], test_dataset[index], id_score_list, mrc_model1,mrc_model2,mrc_model3,\n",
        "                                                           mrc_model4)\n",
        "        \n",
        "            \n",
        "\n",
        "            if answer['score'] > prediction_dict[answer['id']][1]:\n",
        "\n",
        "                prediction_dict[answer['id']] = (answer['text'],answer['score'])\n",
        "                \n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dda6e52-02ad-4d07-a69a-669ed11a48d9",
      "metadata": {
        "id": "0dda6e52-02ad-4d07-a69a-669ed11a48d9"
      },
      "outputs": [],
      "source": [
        "def final_inference(k,contexts,query_passage_score):\n",
        "    \n",
        "    for rank in range(k):\n",
        "\n",
        "        if rank == 0:\n",
        "\n",
        "            test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "            raw_test_dataset,test_dataset,id_score_list = prepare_test_dataset(test_dataset,contexts,query_passage_score,rank)\n",
        "            \n",
        "            features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "\n",
        "            prediction_dict = write_prediction_dict(raw_test_dataset,test_dataset,id_score_list,features_per_example)\n",
        "            \n",
        "\n",
        "        else:\n",
        "\n",
        "            test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "            raw_test_dataset,test_dataset,id_score_list = prepare_test_dataset(test_dataset,contexts,query_passage_score,rank)\n",
        "            \n",
        "            features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "\n",
        "            prediction_dict = rewrite_prediction_dict(prediction_dict,raw_test_dataset,test_dataset,id_score_list,features_per_example)\n",
        "\n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a6ee6c-9dbf-4623-baa3-97aaf98d7434",
      "metadata": {
        "id": "04a6ee6c-9dbf-4623-baa3-97aaf98d7434"
      },
      "outputs": [],
      "source": [
        "def final_inference_multiple(contexts,query_passage_score):\n",
        "\n",
        "    test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "    raw_test_dataset, test_dataset = prepare_test_dataset_multiple(test_dataset,contexts,query_passage_score)\n",
        "\n",
        "    features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "    \n",
        "    prediction_dict = write_prediction_dict_multiple(raw_test_dataset,test_dataset,features_per_example)\n",
        "\n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e47e8ac-f214-498c-aa65-fdc05d68ed99",
      "metadata": {
        "id": "6e47e8ac-f214-498c-aa65-fdc05d68ed99"
      },
      "outputs": [],
      "source": [
        "def final_inference_ensemble_five(k,contexts,query_passage_score):\n",
        "    \n",
        "    for rank in range(k):\n",
        "\n",
        "        if rank == 0:\n",
        "\n",
        "            test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "            raw_test_dataset,test_dataset,id_score_list = prepare_test_dataset(test_dataset,contexts,query_passage_score,rank)\n",
        "            \n",
        "            features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "\n",
        "            prediction_dict = write_prediction_dict_ensemble_five(raw_test_dataset,test_dataset,id_score_list,features_per_example)\n",
        "            \n",
        "\n",
        "        else:\n",
        "\n",
        "            test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "            raw_test_dataset,test_dataset,id_score_list = prepare_test_dataset(test_dataset,contexts,query_passage_score,rank)\n",
        "            \n",
        "            features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "\n",
        "            prediction_dict = rewrite_prediction_dict_ensemble_five(prediction_dict,raw_test_dataset,test_dataset,id_score_list,features_per_example)\n",
        "\n",
        "    return prediction_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7bd7a4-ea1f-4f67-b5de-c5ef5bb1eddc",
      "metadata": {
        "id": "3c7bd7a4-ea1f-4f67-b5de-c5ef5bb1eddc"
      },
      "outputs": [],
      "source": [
        "def final_inference_ensemble_five_multiple(contexts,query_passage_score):\n",
        "    \n",
        "    test_dataset = load_from_disk('input/data/data/test_dataset')\n",
        "\n",
        "    raw_test_dataset, test_dataset = prepare_test_dataset_multiple(test_dataset,contexts,query_passage_score)\n",
        "\n",
        "    features_per_example = feature_per_example(raw_test_dataset,test_dataset)\n",
        "    \n",
        "    prediction_dict = write_prediction_dict_ensemble_five_multiple(raw_test_dataset, test_dataset, features_per_example)\n",
        "\n",
        "    return prediction_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e2352a2d-0e3b-46da-85f3-faa5bc66515b",
      "metadata": {
        "id": "e2352a2d-0e3b-46da-85f3-faa5bc66515b"
      },
      "source": [
        "## prepare question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df2da77-740f-4272-9ea4-13c2661e37b4",
      "metadata": {
        "id": "4df2da77-740f-4272-9ea4-13c2661e37b4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_dataset = load_from_disk('input/data/data/test_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671598b3-1d6a-4de2-bfc4-fe9ac75ab7a6",
      "metadata": {
        "id": "671598b3-1d6a-4de2-bfc4-fe9ac75ab7a6",
        "outputId": "22470aee-462d-4239-a526-10137272d3d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'question'],\n",
              "        num_rows: 600\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 378,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b3f7d5-4d51-4120-8848-ca6b9354b977",
      "metadata": {
        "id": "55b3f7d5-4d51-4120-8848-ca6b9354b977",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b558815b-953e-4460-a216-68e1eb255f84",
      "metadata": {
        "id": "b558815b-953e-4460-a216-68e1eb255f84"
      },
      "outputs": [],
      "source": [
        "test_query_list = test_dataset['question']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4da8bea-7df8-4881-a636-8f4e9aa17762",
      "metadata": {
        "id": "d4da8bea-7df8-4881-a636-8f4e9aa17762"
      },
      "outputs": [],
      "source": [
        "test_id_list = test_dataset['id']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c53a6003-0ad2-4bd8-b86b-2521c6400ed9",
      "metadata": {
        "id": "c53a6003-0ad2-4bd8-b86b-2521c6400ed9"
      },
      "source": [
        "## prepare context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e943ba0-a4b4-4da2-a12d-2e4c604fbe64",
      "metadata": {
        "id": "7e943ba0-a4b4-4da2-a12d-2e4c604fbe64",
        "outputId": "4f8d99b2-ff15-473b-b856-1262849d5205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lengths of unique contexts : 56737\n"
          ]
        }
      ],
      "source": [
        "with open('input/data/data/wikipedia_documents.json', \"r\") as f:\n",
        "    wiki = json.load(f)\n",
        "\n",
        "    contexts = list(dict.fromkeys([v['text'] for v in wiki.values()])) # set 은 매번 순서가 바뀌므로\n",
        "    print(f\"Lengths of unique contexts : {len(contexts)}\")\n",
        "    ids = list(range(len(contexts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48960694-bf3d-45bd-877a-7f4d4deb1e98",
      "metadata": {
        "id": "48960694-bf3d-45bd-877a-7f4d4deb1e98"
      },
      "outputs": [],
      "source": [
        "clean_context_list = contexts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "97226348-4834-4f45-95aa-b6f23f80db5c",
      "metadata": {
        "id": "97226348-4834-4f45-95aa-b6f23f80db5c"
      },
      "source": [
        "## preprocessing wikipedia context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cd0adb-75c7-4a97-a3ab-af4050ef6be8",
      "metadata": {
        "id": "86cd0adb-75c7-4a97-a3ab-af4050ef6be8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def clean_context(data):\n",
        "    \n",
        "    #remove special character\n",
        "    \n",
        "    pattern = '[-=+#/,\\?:^$@*.\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》《\\n]' #want to remove pattern\n",
        "    \n",
        "    repl = '' #replace pattern\n",
        " \n",
        "    text = re.sub(pattern = pattern, repl=repl, string=data)\n",
        "    \n",
        "    text = text.replace('\\\\n','')\n",
        "    \n",
        "    text = text.replace('[','')\n",
        "    \n",
        "    text = text.replace(']','')\n",
        "    \n",
        "    text = text.replace('〉','')\n",
        "    \n",
        "    text = text.replace('〈','')\n",
        "    \n",
        "    text = text.replace('｜','')\n",
        "    \n",
        "    text = text.replace('。','')\n",
        "    \n",
        "    text = text.replace('{','')\n",
        "    \n",
        "    text = text.replace('}','')\n",
        "    \n",
        "    text = text.replace('·','')\n",
        "    \n",
        "    text = text.replace('「','')\n",
        "    text = text.replace('」','')\n",
        "    \n",
        "    text = text.replace('『','')\n",
        "    \n",
        "    text = text.replace('–','')\n",
        "    \n",
        "    text = text.replace(\"’\",'')\n",
        "    \n",
        "    text = text.replace('“','')\n",
        "    \n",
        "    text = text.replace('”','')\n",
        " \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bf9d2ec-0203-486e-890b-ee5ad801e133",
      "metadata": {
        "id": "3bf9d2ec-0203-486e-890b-ee5ad801e133",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def remove_newline(data):\n",
        "    \n",
        "    #remove special character\n",
        "    \n",
        "    pattern = '[\\n]' #want to remove pattern\n",
        "    \n",
        "    repl = ' ' #replace pattern\n",
        " \n",
        "    text = re.sub(pattern = pattern, repl=repl, string=data)\n",
        "    \n",
        "    text = text.replace('\\\\n',' ')\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ef7f16-387d-4163-b012-23ed3f1b3cda",
      "metadata": {
        "id": "68ef7f16-387d-4163-b012-23ed3f1b3cda",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def remove_useless_breacket(texts):\n",
        "    \"\"\"\n",
        "    위키피디아 전처리를 위한 함수입니다.\n",
        "    괄호 내부에 의미가 없는 정보를 제거합니다.\n",
        "    아무런 정보를 포함하고 있지 않다면, 괄호를 통채로 제거합니다.\n",
        "    ``수학(,)`` -> ``수학``\n",
        "    ``수학(數學,) -> ``수학(數學)``\n",
        "    \"\"\"\n",
        "    bracket_pattern = re.compile(r\"\\((.*?)\\)\")\n",
        "    preprocessed_text = []\n",
        "    for text in texts:\n",
        "        modi_text = \"\"\n",
        "        text = text.replace(\"()\", \"\")  # 수학() -> 수학\n",
        "        brackets = bracket_pattern.search(text)\n",
        "        if not brackets:\n",
        "            if text:\n",
        "                preprocessed_text.append(text)\n",
        "                continue\n",
        "        replace_brackets = {}\n",
        "        # key: 원본 문장에서 고쳐야하는 index, value: 고쳐져야 하는 값\n",
        "        # e.g. {'2,8': '(數學)','34,37': ''}\n",
        "        while brackets:\n",
        "            index_key = str(brackets.start()) + \",\" + str(brackets.end())\n",
        "            bracket = text[brackets.start() + 1 : brackets.end() - 1]\n",
        "            infos = bracket.split(\",\")\n",
        "            modi_infos = []\n",
        "            for info in infos:\n",
        "                info = info.strip()\n",
        "                if len(info) > 0:\n",
        "                    modi_infos.append(info)\n",
        "            if len(modi_infos) > 0:\n",
        "                replace_brackets[index_key] = \"(\" + \", \".join(modi_infos) + \")\"\n",
        "            else:\n",
        "                replace_brackets[index_key] = \"\"\n",
        "            brackets = bracket_pattern.search(text, brackets.start() + 1)\n",
        "        end_index = 0\n",
        "        for index_key in replace_brackets.keys():\n",
        "            start_index = int(index_key.split(\",\")[0])\n",
        "            modi_text += text[end_index:start_index]\n",
        "            modi_text += replace_brackets[index_key]\n",
        "            end_index = int(index_key.split(\",\")[1])\n",
        "        modi_text += text[end_index:]\n",
        "        modi_text = modi_text.strip()\n",
        "        if modi_text:\n",
        "            preprocessed_text.append(modi_text)\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5a75a8-d08c-4664-bf68-71eb40ca290a",
      "metadata": {
        "id": "2d5a75a8-d08c-4664-bf68-71eb40ca290a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def remove_repeated_spacing(texts):\n",
        "    \"\"\"\n",
        "    두 개 이상의 연속된 공백을 하나로 치환합니다.\n",
        "    ``오늘은    날씨가   좋다.`` -> ``오늘은 날씨가 좋다.``\n",
        "    \"\"\"\n",
        "    preprocessed_text = []\n",
        "    for text in texts:\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        if text:\n",
        "            preprocessed_text.append(text)\n",
        "    return preprocessed_text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "97f4e772-d62c-4b76-9eac-1601040706e9",
      "metadata": {
        "id": "97f4e772-d62c-4b76-9eac-1601040706e9"
      },
      "source": [
        "## embedding context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39be665b-aad3-4d64-83e9-f0cad3c97cc1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f4485dbe9a0847a396564992411f4bf7"
          ]
        },
        "id": "39be665b-aad3-4d64-83e9-f0cad3c97cc1",
        "outputId": "de777de1-ee32-4594-c27c-59b53f0d184e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4485dbe9a0847a396564992411f4bf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55963.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "p_embs = document_embedding(p_encoder,clean_context_list,dense_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "533ad563-7459-457d-b431-77c23681aea7",
      "metadata": {
        "id": "533ad563-7459-457d-b431-77c23681aea7",
        "outputId": "de38e335-c73a-47c2-9c71-6712ac8eae10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([55963, 768])"
            ]
          },
          "execution_count": 226,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_embs.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3eb9700c-52cb-4e61-9104-7c13d2584f3e",
      "metadata": {
        "id": "3eb9700c-52cb-4e61-9104-7c13d2584f3e"
      },
      "source": [
        "## save wiki context embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ccff7f-f65a-41f1-aef5-7efaa3844b40",
      "metadata": {
        "id": "d8ccff7f-f65a-41f1-aef5-7efaa3844b40"
      },
      "outputs": [],
      "source": [
        "#save passage embedding\n",
        "\n",
        "with open('dense_wiki_passage_v4.pkl', 'wb') as f:\n",
        "    pickle.dump(p_embs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f97bdb-7c34-4458-b24f-0133fc41ca56",
      "metadata": {
        "id": "72f97bdb-7c34-4458-b24f-0133fc41ca56"
      },
      "outputs": [],
      "source": [
        "#load passage embedding\n",
        "\n",
        "with open('dense_wiki_passage_v4.pkl', 'rb') as f:\n",
        "    p_embs = pickle.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "08868fb4-8f6e-4ff2-9370-c2e3bf968e3a",
      "metadata": {
        "id": "08868fb4-8f6e-4ff2-9370-c2e3bf968e3a"
      },
      "source": [
        "# define TF-IDF sparse embedding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "13d5c179-25ca-4932-a9f2-4dfab326f776",
      "metadata": {
        "id": "13d5c179-25ca-4932-a9f2-4dfab326f776"
      },
      "source": [
        "# get cleansing wikipedia text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db54b938-313f-42da-97fe-ebd1d1b78aa9",
      "metadata": {
        "id": "db54b938-313f-42da-97fe-ebd1d1b78aa9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#define get clean wikipedia context function\n",
        "\n",
        "def get_clean_wikipedia_text(contexts):\n",
        "    \n",
        "    clean_context_list1 = remove_useless_breacket(contexts)\n",
        "    \n",
        "    clean_context_list2 = []\n",
        "    clean_context_list3 = []\n",
        "    clean_context_list4 = []\n",
        "    clean_context_list5 = []\n",
        "    \n",
        "    \n",
        "    #remove japan text\n",
        "    for context in notebook.tqdm(clean_context_list1):\n",
        "        clean_context_list2.append(remove_language('30A0','30FF',context))\n",
        "\n",
        "    for context in notebook.tqdm(clean_context_list2):\n",
        "        clean_context_list3.append(remove_language('3040','309F',context))\n",
        "        \n",
        "    \n",
        "    #remove china text\n",
        "\n",
        "    for context in notebook.tqdm(clean_context_list3):\n",
        "        clean_context_list4.append(remove_language('4E00','9FBF',context))\n",
        "        \n",
        "    \n",
        "    #remove special character\n",
        "        \n",
        "    for context in notebook.tqdm(clean_context_list4):\n",
        "        clean_context_list5.append(clean_context(context))\n",
        "        \n",
        "    \n",
        "    #remove repeated space\n",
        "    clean_context_list = remove_repeated_spacing(clean_context_list5)\n",
        "    \n",
        "    return clean_context_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819cb960-7a74-41e5-a81c-2019e1b24d7d",
      "metadata": {
        "id": "819cb960-7a74-41e5-a81c-2019e1b24d7d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_clean_wikipedia_text_v2(contexts):\n",
        "    \n",
        "    clean_context_list1 = remove_useless_breacket(contexts)\n",
        "    \n",
        "    clean_context_list2 = []\n",
        "        \n",
        "    #remove special character\n",
        "        \n",
        "    for context in notebook.tqdm(clean_context_list1):\n",
        "        clean_context_list2.append(remove_newline(context))\n",
        "        \n",
        "    \n",
        "    #remove repeated space\n",
        "    clean_context_list = remove_repeated_spacing(clean_context_list2)\n",
        "    \n",
        "    return clean_context_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0fb5d4-bf90-4438-a4f2-72611e39bfee",
      "metadata": {
        "id": "9d0fb5d4-bf90-4438-a4f2-72611e39bfee",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_clean_wikipedia_text_v3(contexts):\n",
        "    \n",
        "    clean_context_list1 = remove_useless_breacket(contexts)\n",
        "            \n",
        "    #remove repeated space\n",
        "    clean_context_list = remove_repeated_spacing(clean_context_list1)\n",
        "    \n",
        "    return clean_context_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ec4698-5b42-4637-9c39-d7071c682b1d",
      "metadata": {
        "id": "e0ec4698-5b42-4637-9c39-d7071c682b1d"
      },
      "outputs": [],
      "source": [
        "def get_clean_wikipedia_text_v4(contexts):\n",
        "    \n",
        "    clean_context_list1 = []\n",
        "        \n",
        "    #remove special character\n",
        "        \n",
        "    for context in notebook.tqdm(contexts):\n",
        "        clean_context_list1.append(remove_newline(context))\n",
        "    \n",
        "    #clean_context_list2 = []\n",
        "    \n",
        "    #for context in notebook.tqdm(clean_context_list1):\n",
        "        #context = context.replace('티폰','튀폰')\n",
        "        #clean_context_list2.append(context)\n",
        "        \n",
        "            \n",
        "    #remove repeated space\n",
        "    clean_context_list = remove_repeated_spacing(clean_context_list1)\n",
        "    \n",
        "    return clean_context_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30da42e0-41ad-4717-a5c8-289ad967a244",
      "metadata": {
        "id": "30da42e0-41ad-4717-a5c8-289ad967a244",
        "outputId": "ea79287c-0f94-45bc-ecec-5ec93df520ba",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lengths of unique contexts : 56737\n"
          ]
        }
      ],
      "source": [
        "#read wikipedia raw context \n",
        "\n",
        "with open('input/data/data/wikipedia_documents.json', \"r\") as f:\n",
        "    wiki = json.load(f)\n",
        "\n",
        "    contexts = list(dict.fromkeys([v['text'] for v in wiki.values()])) # set 은 매번 순서가 바뀌므로\n",
        "    print(f\"Lengths of unique contexts : {len(contexts)}\")\n",
        "    ids = list(range(len(contexts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8dd4d4-fe8a-4738-a720-54c15cba082e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "05d8d410866f41189756854e5a902b34"
          ]
        },
        "id": "0e8dd4d4-fe8a-4738-a720-54c15cba082e",
        "outputId": "c5972f6d-98c0-417e-ccb9-b09817889089",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05d8d410866f41189756854e5a902b34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clean_context_list = get_clean_wikipedia_text_v4(contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07a7e10-9f1d-43d1-b24b-89d5cd8c5d22",
      "metadata": {
        "id": "b07a7e10-9f1d-43d1-b24b-89d5cd8c5d22",
        "outputId": "fee3fcad-20c2-41c3-c5a5-c9920ea1fa88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'티폰(Τυφών)은 그리스 신화에 등장하는 가장 강하고 무서우며, 엄청나게 거대한 거인이다. 영어의 태풍(Typhoon)의 어원이기도 하다.(태풍의 광둥어 발음인 daaih-fùng이 변형된 말이라고도 한다.) 머리에서 허벅지까지가 인간이었지만, 사람의 머리 대신에 눈에서 번갯불와 불꽃을 내뿜을 수 있는 100개의 용의 머리가 돋아나 있었고, 두 개의 대퇴부에서 밑으로는 똬리를 튼 거대한 뱀의 모습을 지니고 있다. 온 몸을 뒤덮고 있는 깃털과 날개는 항상 그 자신이 일으키는 격렬한 폭풍 때문에 휘날리고 있다. 그의 어깨는 하늘에 닿고, 100개의 머리는 우주에 있는 별을 스치며, 두 팔을 벌리면 세계의 동쪽과 서쪽의 끝까지 닿는다고 한다. 그가 날개를 펼치면 태양빛이 비춰지지 않아 세계가 어둠에 잠식된다고 한다. 또한 산과 땅을 찢고 하늘을 가를 정도로 힘이 세고, 그가 불을 뿜으면 그 어떤것도 흔적이 남지 않았다. 아무리 신들이라 해도 이런 튀폰을 감히 당해낼 이가 없었다 한다. 티폰이 한번 지나간 자리에는 나무들이 부러지고 흙이 파헤쳐지고 파괴되며 그 어떤 것들이라도 소멸되버리거나 혹은 불타버려서 그림자조차 남지 않을 정도라고 한다. 대지의 여신 가이아는 제우스가 크로노스를 물리치고 신들의 지배자 자리에 오르자 이에 분노하여 크로노스의 원수를 갚기 위해 그녀의 또 다른 배우자인 타르타로스와 관계를 맺어 그녀의 마지막 자식인 튀폰을 낳았다. 티폰은 가이아의 아들이라는 가설이 좀 더 확실하다. 일설에서 튀폰은 제우스가 바람을 피운 것에 복수하기 위해 헤라가 크로노스로부터 받은 알에서 태어나 델포이의 큰 뱀 파이톤에 의해 키워졌다고도 한다. 어느 쪽이든 튀폰은 무럭무럭 커 가면서 힘이 생기자 제우스를 물리치기 위해 올림포스 산으로 진군하였다. 그에 두려워한 올림포스 신들은 전부 이집트로 도망갔으나, 그 자리를 지킨 아테네의 비웃음에 참을 수 없던 제우스는 다시 올림포스로 돌아왔다. 그러나 튀폰의 힘에 굴복한 제우스는 그에게 힘줄을 잘려 아무힘도 쓸 수 없었다. 그러나 헤르메스와 판 신이 그의 힘줄을 동굴에서 찾아 돌려준 뒤 튀폰의 머리를 번갯불로 맞추어, 곧바로 에트나 산을 던져 가둬버렸다. 에트나산이 분화할 때면 튀폰이 움직이기 시작한 거라고 사람들은 믿었다.'"
            ]
          },
          "execution_count": 371,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_context_list[5397]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "050fa62d-c7b2-4e63-8361-4fbacb3ba2c8",
      "metadata": {
        "id": "050fa62d-c7b2-4e63-8361-4fbacb3ba2c8"
      },
      "outputs": [],
      "source": [
        "clean_context_list[5397]=clean_context_list[5397].replace('티폰','튀폰')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "713bd003-924d-48f5-98d5-78a5f747921e",
      "metadata": {
        "id": "713bd003-924d-48f5-98d5-78a5f747921e"
      },
      "outputs": [],
      "source": [
        "clean_context_list = list(set(clean_context_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2060fd72-1e63-4aa4-8500-aa10bf2ef84f",
      "metadata": {
        "id": "2060fd72-1e63-4aa4-8500-aa10bf2ef84f",
        "outputId": "7662224b-2884-4e76-cdbd-934d4ed9e132"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55963"
            ]
          },
          "execution_count": 374,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b240e00-8b9f-4cba-aa66-da2e35770f5c",
      "metadata": {
        "id": "2b240e00-8b9f-4cba-aa66-da2e35770f5c"
      },
      "outputs": [],
      "source": [
        "test_query_list[0] = test_query_list[0].replace(\"유령'\",\"'유령'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4d9ba2-7a1e-4139-83bd-55857f8b59eb",
      "metadata": {
        "id": "eb4d9ba2-7a1e-4139-83bd-55857f8b59eb",
        "outputId": "151ec58f-1a4e-46d4-a53d-6c7814160b4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'유령'은 어느 행성에서 지구로 왔는가?\""
            ]
          },
          "execution_count": 383,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_query_list[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "883b7b47-ff25-41f7-82a4-56ffb7d3bfd2",
      "metadata": {
        "id": "883b7b47-ff25-41f7-82a4-56ffb7d3bfd2"
      },
      "source": [
        "# define term frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f0e2a3-fc70-4575-bded-7c4d613e9a55",
      "metadata": {
        "id": "19f0e2a3-fc70-4575-bded-7c4d613e9a55"
      },
      "outputs": [],
      "source": [
        "#define compute raw count term frequency in one passage\n",
        "\n",
        "def compute_tf_score(context,vocab):\n",
        "    \n",
        "    tf_passage = []\n",
        "    \n",
        "    tokenized_passage = sparse_tokenizer.morphs(context)\n",
        "    \n",
        "    for term in vocab.keys():\n",
        "        tf_passage.append(tokenized_passage.count(term))\n",
        "        \n",
        "    \n",
        "    return tf_passage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c5ba51-1000-42e0-addd-9eb8f311e1a3",
      "metadata": {
        "id": "20c5ba51-1000-42e0-addd-9eb8f311e1a3"
      },
      "outputs": [],
      "source": [
        "tf_context_passage = compute_tf_score(clean_context_list[0],vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ce2b9f-bce6-4e47-86c2-b40eb361d297",
      "metadata": {
        "id": "f5ce2b9f-bce6-4e47-86c2-b40eb361d297",
        "outputId": "1fa9a804-f1e8-4fb2-97e1-0ce19ec9667b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "292340"
            ]
          },
          "execution_count": 97,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tf_context_passage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "455b33c2-b526-4a81-ae2a-e05c41b0f734",
      "metadata": {
        "id": "455b33c2-b526-4a81-ae2a-e05c41b0f734",
        "outputId": "78ef0d91-aa51-405c-d4bc-88ff273daf60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8, 2, 9, 5, 5, 1, 1, 1, 1, 3, 5, 1, 1, 2, 2, 3, 3, 5, 1, 1, 1, 3, 9, 7, 9, 9, 5, 1, 1, 1, 3, 3, 1, 1, 2, 1, 2, 2, 1, 1, 1, 7, 2, 1, 1, 1, 3, 1, 5, 1, 1, 3, 3, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "print(tf_context_passage[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935d7640-beac-41af-ab49-6785c13f0532",
      "metadata": {
        "id": "935d7640-beac-41af-ab49-6785c13f0532"
      },
      "outputs": [],
      "source": [
        "def compute_log_tf_score(context,vocab):\n",
        "    \n",
        "    sparse_emb = []\n",
        "    \n",
        "    tf_passage = compute_tf_score(context,vocab)\n",
        "\n",
        "    for raw_count in tf_passage:\n",
        "        sparse_emb.append(np.log(1+raw_count))\n",
        "\n",
        "    sparse_emb = torch.tensor(sparse_emb)\n",
        "    \n",
        "    return sparse_emb\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafe8429-6670-4331-9d46-1cb5f6d91bc3",
      "metadata": {
        "id": "cafe8429-6670-4331-9d46-1cb5f6d91bc3"
      },
      "outputs": [],
      "source": [
        "tf_context_passage = compute_log_tf_score(clean_context_list[0],vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9addbb-b0b3-4143-81c5-4e016e0c5313",
      "metadata": {
        "id": "fc9addbb-b0b3-4143-81c5-4e016e0c5313",
        "outputId": "f73037de-5287-404c-fc72-9571049968ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2.1972, 1.0986, 2.3026, 1.7918, 1.7918, 0.6931, 0.6931, 0.6931, 0.6931,\n",
              "        1.3863, 1.7918, 0.6931, 0.6931, 1.0986, 1.0986, 1.3863, 1.3863, 1.7918,\n",
              "        0.6931, 0.6931, 0.6931, 1.3863, 2.3026, 2.0794, 2.3026, 2.3026, 1.7918,\n",
              "        0.6931, 0.6931, 0.6931, 1.3863, 1.3863, 0.6931, 0.6931, 1.0986, 0.6931,\n",
              "        1.0986, 1.0986, 0.6931, 0.6931, 0.6931, 2.0794, 1.0986, 0.6931, 0.6931,\n",
              "        0.6931, 1.3863, 0.6931, 1.7918, 0.6931, 0.6931, 1.3863, 1.3863, 1.0986,\n",
              "        1.0986, 1.0986, 1.0986, 1.0986, 0.6931, 1.0986, 0.6931, 0.6931, 0.6931,\n",
              "        0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
              "        1.0986, 0.6931, 0.6931, 1.6094, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
              "        0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
              "        0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 1.0986, 1.0986, 0.6931, 0.6931,\n",
              "        1.0986], dtype=torch.float64)"
            ]
          },
          "execution_count": 102,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_context_passage[:100]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c3565443-e5ca-4a1a-ba7e-d157dd4978b7",
      "metadata": {
        "id": "c3565443-e5ca-4a1a-ba7e-d157dd4978b7"
      },
      "source": [
        "# define inverse document frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726c6b66-a1c7-43de-a9e0-e5e1eec4fe4c",
      "metadata": {
        "id": "726c6b66-a1c7-43de-a9e0-e5e1eec4fe4c"
      },
      "outputs": [],
      "source": [
        "def document_frequency(contexts,term):\n",
        "    \n",
        "    df_score = 0\n",
        "    \n",
        "    for context in contexts:\n",
        "        \n",
        "        #document = sparse_tokenizer.morphs(context)\n",
        "        \n",
        "        if term in context:\n",
        "            \n",
        "            df_score += 1\n",
        "    \n",
        "    return df_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdea8428-3e98-464c-ae73-53b6fdf03acd",
      "metadata": {
        "id": "fdea8428-3e98-464c-ae73-53b6fdf03acd"
      },
      "outputs": [],
      "source": [
        "def compute_log_idf_score(contexts,vocab):\n",
        "    \n",
        "    sparse_emb = []\n",
        "    \n",
        "    total_document = len(contexts)\n",
        "    \n",
        "    for term in notebook.tqdm(vocab.keys()):\n",
        "        \n",
        "        df_score_term = document_frequency(contexts,term)\n",
        "        \n",
        "        sparse_emb.append(np.log(total_document/(1+df_score_term)))\n",
        "        \n",
        "    sparse_emb = torch.tensor(sparse_emb)\n",
        "    \n",
        "    return sparse_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bba0ae-a925-4cbf-a1c5-4acec9f77fda",
      "metadata": {
        "id": "88bba0ae-a925-4cbf-a1c5-4acec9f77fda"
      },
      "outputs": [],
      "source": [
        "sparse_emb = compute_log_idf_score(clean_context_list,vocab)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3672f4b2-0772-42e4-8c2a-7282438b35a7",
      "metadata": {
        "id": "3672f4b2-0772-42e4-8c2a-7282438b35a7"
      },
      "source": [
        "# sparse retrieval using TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54968922-7a6a-44c4-9fd3-481e207c98d5",
      "metadata": {
        "id": "54968922-7a6a-44c4-9fd3-481e207c98d5"
      },
      "outputs": [],
      "source": [
        "sparse_tokenizer = Mecab()\n",
        "\n",
        "def mecab_tokenize(text):\n",
        "    \n",
        "    return sparse_tokenizer.morphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4358b05-a03e-4c51-af67-a63485af3486",
      "metadata": {
        "id": "b4358b05-a03e-4c51-af67-a63485af3486"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=mecab_tokenize, ngram_range=(1,2),sublinear_tf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9728954-5776-42a5-a715-378e8be09b39",
      "metadata": {
        "id": "c9728954-5776-42a5-a715-378e8be09b39",
        "outputId": "00449bc3-8aea-4017-fb13-0d5ec308af0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ],
      "source": [
        "vectorizer.fit(clean_context_list)\n",
        "\n",
        "sp_matrix = vectorizer.transform(clean_context_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4f42f8-40e7-4f12-be5a-c1fdeb337cb0",
      "metadata": {
        "id": "8a4f42f8-40e7-4f12-be5a-c1fdeb337cb0",
        "outputId": "040ae999-7d0b-4b2d-ed1c-c93b87edfe98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(56737, 3896368)"
            ]
          },
          "execution_count": 75,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sp_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5e79b4-41db-417f-b22b-f69b0c4c5603",
      "metadata": {
        "id": "3b5e79b4-41db-417f-b22b-f69b0c4c5603",
        "outputId": "30cc41c2-05b4-46d1-8e29-b0e7b51b881c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         TF-IDF\n",
            "널리 받   0.147180\n",
            "개 나라   0.146110\n",
            "인 승인   0.135684\n",
            "나열 하   0.134132\n",
            "째 부분   0.126279\n",
            "를 나열   0.124468\n",
            "이 목록   0.117880\n",
            "나열     0.115657\n",
            "목록     0.111317\n",
            "다고 여기  0.109008\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(sp_matrix[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3aa6a26-764e-455c-8afa-190e0013f221",
      "metadata": {
        "id": "d3aa6a26-764e-455c-8afa-190e0013f221"
      },
      "outputs": [],
      "source": [
        "query_vec = vectorizer.transform([test_query_list[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25ab642-9aeb-4a03-9641-c0a7292a8bcd",
      "metadata": {
        "id": "f25ab642-9aeb-4a03-9641-c0a7292a8bcd",
        "outputId": "59674e44-b6fd-4b03-a721-21cf425e64ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 56737)"
            ]
          },
          "execution_count": 62,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = query_vec * sp_matrix.T\n",
        "result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe42773f-a452-4df2-9000-0bf331f6d7a6",
      "metadata": {
        "id": "fe42773f-a452-4df2-9000-0bf331f6d7a6",
        "outputId": "cfcc41d9-92c6-4340-d82d-5d334ebe14f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(55562,)"
            ]
          },
          "execution_count": 74,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3479483-2306-4d05-b582-0e117d278ccc",
      "metadata": {
        "id": "e3479483-2306-4d05-b582-0e117d278ccc",
        "outputId": "02789a1f-d8c5-4458-c522-392b2268eb1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 56737])"
            ]
          },
          "execution_count": 75,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(result.toarray()).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5091b099-5eb6-4416-aede-659223f38f95",
      "metadata": {
        "id": "5091b099-5eb6-4416-aede-659223f38f95"
      },
      "outputs": [],
      "source": [
        "sorted_result = np.argsort(-result.data)\n",
        "doc_scores = result.data[sorted_result]\n",
        "doc_ids = result.indices[sorted_result]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51cb5b32-8368-4c58-bc82-97f00909375a",
      "metadata": {
        "id": "51cb5b32-8368-4c58-bc82-97f00909375a",
        "outputId": "093658a0-9984-455b-bb50-6d5bf5a6dff4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.07068501, 0.06176537, 0.055114  , 0.05395561, 0.05392631,\n",
              "        0.0538449 , 0.05332264, 0.05276092, 0.05193748, 0.05108912]),\n",
              " array([45971, 17229, 53819, 22606, 38423, 41094, 11868, 24508, 38450,\n",
              "        39470], dtype=int32))"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k=10\n",
        "doc_scores[:k], doc_ids[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716cfbab-2487-4cd3-81a2-ff0efa65b149",
      "metadata": {
        "collapsed": true,
        "id": "716cfbab-2487-4cd3-81a2-ff0efa65b149",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "81e74c8c-76d1-4185-8214-85e955886959",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Search query]\n",
            " 유령'은 어느 행성에서 지구로 왔는가? \n",
            "\n",
            "Top-1 passage with score 0.0707\n",
            "The Impossible Planet KBS 방영 제목 블랙홀의 저주는 영국의 SF 드라마 닥터 후 시리즈 2의 여덟 번째 에피소드이다 2006년 6월 3일 영국에서 처음 방송되었으며 The Satan Pit과 함께 2부작으로 된 에피소드 중 전편에 해당된다 줄거리는 타디스가 우연히 어느 행성 위에 건설된 기지 내부에 착륙하는 것부터 시작된다 그 행성은 블랙홀 주변을 공전하고 있었는데 블랙홀 속으로 빨려들어가지 않는다는 것은 닥터도 어리둥절할 정도로 불가사의한 상황이었다 그 기지에서는 행성의 공전을 가능케 하는 알수없는 에너지 근원지를 찾아 지하로 파내려가는 작업을 하고 있었는데 인류 제국에 이익이 되지 않을까 싶어서였다 그러나 그곳에는 먼 옛날의 악마가 살고 있었다는 것이 밝혀지고 마침내 깨어나고 만다 \n",
            "\n",
            "Top-2 passage with score 0.0618\n",
            "HD 40307 b의 질량은 적어도 지구의 42배 수준인데 기존 가스 행성에 비하면 매우 가벼우며 슈퍼지구로 분류된다 이 행성은 어머니 항성 HD 40307을 43일에 1회 공전하며 항성으로부터의 거리는 0047 천문단위 정도이다 행성의 공전궤도 이심률은 0에 가까운데 이는 행성이 항성으로부터 원형에 가까운 궤도를 유지한다는 의미이다HD 40307의 중원소 함량은 다른 외계 행성을 거느린 항성들에 비해 낮은 편이다 이 사실은 “항성이 태어날 때의 중원소 함량이 자신의 강착 원반으로부터 가스 행성이나 암석 행성이 탄생할지 아닐지 여부를 결정짓는다”라는 가설을 지지한다 \n",
            "\n",
            "Top-3 passage with score 0.0551\n",
            "니스 모형Nice model Nice은 태양계의 역학적 진화에 대한 하나의 모형으로 2005년 모형이 처음 개발된 코트다쥐르 천문대의 위치인 프랑스의 도시 니스의 이름을 땄다 니스 모형은 목성형 행성이 원시 행성계 원반의 소멸 이후 기존의 밀집 분포에서 행성 전이를 통해 현재의 위치로 옮겨갔다는 내용으로 태양계 형성에 대한 기존 모형과 다르다 행성 전이는 후기 대폭격 오르트 구름의 형성 카이퍼대와 목성 트로이군의 형성 공명 해왕성 바깥 천체의 존재에 대한 설명을 위해 도입되었다 니스 모형은 관측되는 태양계의 모습 대부분을 재현해낼 수 있어 현재 가장 가능성이 높은 모형으로 받아들여지고 있으나 이후 연구에서 지구형 행성과 소행성의 궤도 등 니스 모형에서의 예측과 현재 태양계의 차이가 발견되어 모형 일부가 수정되었다 \n",
            "\n",
            "Top-4 passage with score 0.0540\n",
            "글리제 581 g는 천칭자리 방향으로 지구로부터 약 205광년 떨어진 적색 왜성 글리제 581 주위를 돌고 있는 외계 행성이다 글리제 581 g는 글리제 581 주위를 도는 행성으로는 여섯 번째로 발견되었다 릭카네기 외계행성 서베이에서 글리제 581을 10년 넘게 관측한 끝에 2010년 9월 말 g의 존재를 발표했다연구 결과 g는 항성으로부터 너무 멀지도 너무 가깝지도 않아 생명체가 살기에 꼭 알맞은 골디락스 영역에서 처음으로 발견된 행성으로 인류가 최초로 발견한 또 다른 지구의 조건을 갖춘 행성이라고 할 수 있다 만약 이 행성 표면이 딱딱한 돌로 이루어져 있다면 액체 상태의 물이 표면에 존재할 가능성이 있다 글리제 581g의 질량은 지구의 3143배로 슈퍼지구로 부를 수 있으며 어머니 별을 37일 주기로 공전한다상대적으로 짧은 관측 시간만으로도 지구에서 이처럼 가까운 곳에서 골디락스 행성을 발견했다는 점으로 미루어 천문학자들은 생명체가 살 수 있는 행성을 거느린 항성의 비율이 전체 중 10퍼센트보다 클 것으로 예상하고 있다 캘리포니아 공과대학에 의해 운영되고 있는 NASA의 제트 추진 연구소가 골디락스 행성을 찾는 케플러 계획을 전담하고 있다 \n",
            "\n",
            "Top-5 passage with score 0.0539\n",
            "이 행성은 발견일 기준으로 누적된 발견사례 중에서도 매우 중요한 천체로 평가받았다 글리제 1132 b는 대기 조성물 바람의 속도 일몰시 어머니 별의 색 등을 쉽게 예측할 수 있다 이는 글리제 1132 b가 발견된 외계 행성 중에서 지구에 매우 가까우며 어머니 별의 크기가 작기 때문에태양의 21 별의 빛이 줄어드는 정도를 보다 쉽게 파악할 수 있기 때문이다 행성의 크기는 지구보다 약 16 가량 커서 약 1만 4806km이다 크기는 지구와 비슷하지만 특징은 금성과 비슷하다 어머니 별과의 거리가 225만km 로 가까운 편이여서 온도는 섭씨 232도에 달할 것으로 예상되기 때문에 물이 존재할 가능성은 희박하지만 대기가 존재할 가능성은 크다고 보고되었다 글리제 1132 b는 단위면적당 지구의 약 19배 복사 에너지를 받는다 이로부터 계산한 글리제 1132 b의 대기 상층부 온도는 금성보다 뜨거우며 지표면으로 하강할수록 온도는 더 올라갈 것이다 2017년 4월에 글리제 1132 b 에 대기가 존재한다는 사실이 확인되었다 현재까지 알려진 대기가 존재하는 행성 중에 가장 지구와 유사하다 \n",
            "\n",
            "Top-6 passage with score 0.0538\n",
            "고전적인 열적 탈출 메커니즘 가운데 하나로 진스 탈출 이 있다 기체 분자의 평균 속도는 온도에 따라 결정되지만 분자들끼리 충돌하면서 운동 에너지를 얻거나 잃는 과정에서 개별 분자의 속력은 크게 달라질 수 있다 분자들의 운동 에너지의 분포는 맥스웰 분포로 기술할 수 있다 운동 에너지와 분자의 질량을 알면 E_\\frac 12mv2 식으로부터 속도를 구할 수 있다맥스웰 분포의 긴 꼬리 부분에 해당되는 속도로 움직이는 분자들은 탈출 속도에 다다를 수 있는데 이런 분자가 대기권에서 평균자유이동경로가 높이척도 수준에 달하는 높이까지 올라간다면 대기를 벗어날 수 있다기체 분자의 질량이 클수록 주어진 온도에서 그 분자들의 평균속도가 낮으므로 탈출 속도 수준으로 빨라질 가능성도 낮아진다수소가 이산화탄소보다 더 쉽게 대기를 빠져나가는 이유가 바로 이 때문이다 또한 행성의 질량이 클수록 탈출 속도도 커져서 빠져나가기가 어려워진다 지구 대기에는 수소와 헬륨이 별로 없는데 반해 거대 가스 행성에는 여전히 많은 것도 바로 이런 이유 때문이다 행성과 그 행성이 공전하고 있는 별 사이의 거리도 중요한 요인이다 별에서 가까운 행성에서는 대기가 더 뜨겁기 때문에 분자들의 속도 분포가 더 높은 쪽으로 치우치게 되어 탈출할 가능성이 높다 별에서 멀리 떨어진 행성에서는 대기가 더 차가우므로 속도가 낮은 쪽으로 분포하게 되어 탈출 가능성이 낮다 토성의 위성인 타이탄은 지구에 비해 작지만 태양에서 멀기 때문에 대기가 더 두껍다압력과 온도가 충분히 높은 대기에서는 “유체역학적인 탈출”이라는 다른 탈출 메커니즘으로 대기를 탈출할 수 있다 열 에너지가 누적되어 생기는 압력의 차이 때문에 대기가 바람 불듯 우주로 흘러나가 버리는 방식이다 이런 경우에는 일반적으로 대기를 빠져나가기 힘든 무거운 분자도 같이 쓸려나갈 수 있다 유체역학적인 탈출은 일부 뜨거운 목성HD 209458 b HD 189733 b이나 뜨거운 해왕성GJ 436 b을 비롯하여 행성 가까이 있는 태양계 밖 행성에서 관찰된 바 있다 \n",
            "\n",
            "Top-7 passage with score 0.0533\n",
            "HD 40307은 분광형 K의 주계열성으로 남반구의 화가자리 방향으로 지구에서 42광년 떨어진 곳에 있다 HD로 시작하는 명칭에서 알 수 있듯 이 별은 헨리 드레이퍼 목록에 실려 있다 이 별의 질량은 우리 태양보다 근소하게 작다 겉보기 등급은 717로 맨눈으로 볼 수는 없다 HD 40307은 케이프 사진소천성표 등재작업이 한참이던 1900년 경 관측되었다 HD 40307은 최소 6개 외계 행성을 거느리고 있다 2008년 이 별 주위를 도는 행성 세 개가 발견되었다 2012년 세 개의 행성이 추가로 발견되었다 이들 중 HD 40307 g는 생명체 거주가능 영역 안을 돌고 있는 슈퍼지구로 공전주기는 지구시간으로 약 200일이며 표면에 액체 물이 존재하고 있을지도 모른다 추가 관측을 통해 더 자세한 정보가 알려져야 이 행성이 생명체가 살법한 장소인지가 판가름날 것이다 \n",
            "\n",
            "Top-8 passage with score 0.0528\n",
            "닥터 에그맨이 에그 플래닛 파크라는 놀이공원을 지었다는 소식에 소닉 더 헤지호그와 마일즈 테일즈 파우어는 그곳으로 향한다 그곳에서 에그맨이 위습의 에너지를 이용해 세뇌 레이저를 만들어 지구에 발사하려고 한다는 것을 알아냈다 그 뒤 놀이공원에 있는 행성들이 모두 에그맨이 이쪽으로 소환한 것이라는 걸 알게 된다소닉은 이 소환을 위한 장치를 모두 정지시켰으나 이미 에너지는 충분히 모인 상태였기 때문에 에그맨은 지구를 향해 세뇌 레이저를 발사한다 그러나 세뇌 레이저는 망가진 상태였기 때문에 폭발하여 여파로 놀이공원이 파괴되기 시작한다소닉과 테일즈는 지구로 돌아가려 하나 에그맨이 그 앞을 막아 소닉은 먼저 테일즈를 지구로 보내고 에그맨을 상대한다 에그맨을 성공적으로 막았지만 폭발에 휩쓸리고 마는데 위습들이 소닉을 지구로 되돌려 주어서 무사히 귀환한다그 뒤 소닉이 계속 소환 장치를 정지하고 있는데도 에그맨이 에너지를 채울 수 있는 수단이었던 마더 위습이 세뇌된 상태로 소닉을 가로막는다 소닉은 슈퍼 소닉으로 변신하여 그녀를 원래대로 되돌려놓고 마더 위습은 위습과 함께 자신들의 행성으로 돌아간다 \n",
            "\n",
            "Top-9 passage with score 0.0519\n",
            "서브지구subEarth는 지구와 금성보다 질량이 확연하게 작은 행성이다 태양계에서 이에 해당하는 천체로는 수성과 화성이 있다 서브지구는 외계행성 중에서도 발견하기가 가장 까다로운 천체인데 이는 질량과 크기가 작아 아주 작은 크기의 신호만을 만들어내므로 이를 포착하기가 어렵기 때문이다 하지만 의외로 최초로 발견된 외계행성은 서브지구로 밀리초펄서 PSR B125712를 돌고 있다케플러 우주선의 발사로 서브지구를 찾아내는 분야에 새로운 장이 열렸다 2012년 1월 10일 케플러 우주선은 평범한 별 케플러42를 도는 서브지구 셋을 발견했다 케플러는 2014년 6월까지 지구보다 작은 것으로 검증된 행성 45개를 추려냈는데 그 중 17개는 질량이 지구의 80 미만이었다 검증되지는 않았으나 후보군에 속한 천체로는 총 310개가 이름을 올렸고 이 중 135개는 반지름이 지구의 80 퍼센트 미만이었다 보통 서브지구는 질량이 작아 중력과 자기장의 힘 모두 빈약하기 때문에 항성의 복사에너지에 대기를 쉽게 잃어버릴 것이다 \n",
            "\n",
            "Top-10 passage with score 0.0511\n",
            "거대 행성은 무겁고 거대한 행성으로 수소와 헬륨으로 이루어진 두꺼운 대기를 가진다 이들은 밀하고 용융된 암석 요소의 핵을 가지고 있거나 충분히 뜨겁다면 핵이 완전히 녹아 행성 곳곳에 비산되었을 것이다 목성과 토성거대 기체 행성과 같은 전통적인 거대 행성에서 수소와 헬륨은 행성의 질량 대부분을 차지하는데 비해 천왕성과 해왕성에서는 오로지 외곽층만을 이루는 대신에 물과 암모니아 메테인이 주를 차지한다 때문에 이들은 거대 얼음 행성으로 표현된다외계 행성 중에서 뜨거운 목성과 뜨거운 해왕성은 별과 매우 가까이서 공전하는 거대 행성이다 때문에 이들은 높은 표면온도를 가진다 뜨거운 목성은 우주 망원경이 등장하기 전까지 지상의 기구를 통해 상대적으로 탐지하기 쉬워 가장 흔하게 발견되는 외계 행성이었다거대 행성은 흔히 고체로 이루어진 표면이 없다고 일컬어 지나 표면이 되는 기체가 행성의 중심으로부터 거리가 증가함에 따라 옅게 더욱 옅어져 끝내 행성간 매질과 구분이 불가능할 정도가 되면서 표면이 완전히 없다고 말하는 것이 더 정확하다 그러므로 거대 행성으로의 착륙은 행성의 크기와 중심핵의 조성에 따라 여부가 달라진다 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"[Search query]\\n\", test_query_list[0], \"\\n\")\n",
        "\n",
        "for i in range(k):\n",
        "    print(\"Top-%d passage with score %.4f\" % (i + 1, doc_scores[i]))\n",
        "    doc_id = doc_ids[i]\n",
        "    print(clean_context_list[doc_id], \"\\n\") #set을 한 이유가 여기 있었네 중복이 있어서 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6f1000ab-58e8-402e-a92d-405ea4054989",
      "metadata": {
        "id": "6f1000ab-58e8-402e-a92d-405ea4054989"
      },
      "source": [
        "## get relevant document using bm25 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0025ac6b-a9e8-4bfb-90c9-177c8590b348",
      "metadata": {
        "id": "0025ac6b-a9e8-4bfb-90c9-177c8590b348"
      },
      "outputs": [],
      "source": [
        "sparse_tokenizer = Mecab()\n",
        "\n",
        "def mecab_tokenize(text):\n",
        "    \n",
        "    return sparse_tokenizer.morphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6dea37-3bda-484f-990c-5e31efa03261",
      "metadata": {
        "id": "fa6dea37-3bda-484f-990c-5e31efa03261"
      },
      "outputs": [],
      "source": [
        "def get_relevant_doc_bm25(clean_context_list,test_query_list,k):\n",
        "    \n",
        "    tokenized_context = [mecab_tokenize(context) for context in notebook.tqdm(clean_context_list)]\n",
        "    \n",
        "    bm25 = BM25Okapi(tokenized_context)\n",
        "    \n",
        "    query_passage_score = []\n",
        "        \n",
        "    for query in notebook.tqdm(test_query_list):\n",
        "        \n",
        "        tokenized_query = mecab_tokenize(query)\n",
        "        \n",
        "        scores = torch.tensor(bm25.get_scores(tokenized_query))\n",
        "        \n",
        "        rank,score= torch.sort(scores,descending=True).indices,torch.sort(scores,descending=True).values\n",
        "        \n",
        "        query_passage_score.append((query,rank[:k],score[:k]))\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687181ad-22a6-4d22-8ac8-d67f0f044704",
      "metadata": {
        "id": "687181ad-22a6-4d22-8ac8-d67f0f044704"
      },
      "outputs": [],
      "source": [
        "def get_relevant_doc_bm25L(clean_context_list,test_query_list,k):\n",
        "    \n",
        "    tokenized_context = [mecab_tokenize(context) for context in notebook.tqdm(clean_context_list)]\n",
        "    \n",
        "    bm25 = BM25L(tokenized_context)\n",
        "    \n",
        "    query_passage_score = []\n",
        "        \n",
        "    for query in notebook.tqdm(test_query_list):\n",
        "        \n",
        "        tokenized_query = mecab_tokenize(query)\n",
        "        \n",
        "        scores = torch.tensor(bm25.get_scores(tokenized_query))\n",
        "        \n",
        "        rank,score= torch.sort(scores,descending=True).indices,torch.sort(scores,descending=True).values\n",
        "        \n",
        "        query_passage_score.append((query,rank[:k],score[:k]))\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9bd96d-48af-45c6-afb5-8da5381366c5",
      "metadata": {
        "id": "de9bd96d-48af-45c6-afb5-8da5381366c5"
      },
      "outputs": [],
      "source": [
        "def get_relevant_doc_bm25plus(clean_context_list,test_query_list,k):\n",
        "    \n",
        "    tokenized_context = [mecab_tokenize(context) for context in notebook.tqdm(clean_context_list)]\n",
        "    \n",
        "    bm25 = BM25Plus(tokenized_context)\n",
        "    \n",
        "    query_passage_score = []\n",
        "        \n",
        "    for query in notebook.tqdm(test_query_list):\n",
        "        \n",
        "        tokenized_query = mecab_tokenize(query)\n",
        "        \n",
        "        scores = torch.tensor(bm25.get_scores(tokenized_query))\n",
        "        \n",
        "        rank,score= torch.sort(scores,descending=True).indices,torch.sort(scores,descending=True).values\n",
        "        \n",
        "        query_passage_score.append((query,rank[:k],score[:k]))\n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5650a7-6ba9-4223-9a61-4a1f8617614c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b96067f897d64da7bcdb676b3f0d8f90",
            "901d41f7007b45abb958b6638333f87b"
          ]
        },
        "id": "4c5650a7-6ba9-4223-9a61-4a1f8617614c",
        "outputId": "046a4d65-7993-4690-8dbe-8f485b599532"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b96067f897d64da7bcdb676b3f0d8f90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55963.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "901d41f7007b45abb958b6638333f87b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_passage_score_bm25 = get_relevant_doc_bm25(clean_context_list,test_query_list,k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b24db01-0a8e-40bd-8df9-f07dfc348f16",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ebfe8c6871924430b4386903bff4bb0a",
            "0fff2550ad62492fbc82df46682775b0"
          ]
        },
        "id": "4b24db01-0a8e-40bd-8df9-f07dfc348f16",
        "outputId": "5206cf2b-cb69-409b-e800-415916433248"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebfe8c6871924430b4386903bff4bb0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55963.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fff2550ad62492fbc82df46682775b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_passage_score_bm25L = get_relevant_doc_bm25L(clean_context_list,test_query_list,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6a22aa-e4e5-41da-8aaa-8aca290ca5aa",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8c7f9f7c715e486686c584cc3af0066c",
            "70d625adeb61419d88a23c367bfe271a"
          ]
        },
        "id": "4c6a22aa-e4e5-41da-8aaa-8aca290ca5aa",
        "outputId": "ec19b1bb-d911-41ca-d712-3bcb3d568cf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c7f9f7c715e486686c584cc3af0066c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55963.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70d625adeb61419d88a23c367bfe271a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_passage_score_bm25plus = get_relevant_doc_bm25plus(clean_context_list,test_query_list,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba96ce0-9230-4221-b604-6b88255af783",
      "metadata": {
        "id": "6ba96ce0-9230-4221-b604-6b88255af783",
        "outputId": "e09fe10e-c1ac-4345-b124-3a5b79f767e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('제2캐나다기갑여단이 상륙한 곳은?',\n",
              " tensor([53965, 38191, 28170, 38931,  5746, 10133, 46331, 16697, 45536, 52098,\n",
              "         20085, 41922,  8714, 46860, 20205, 54101, 38220, 28314,  4636, 43249]),\n",
              " tensor([66.8892, 58.6919, 56.0010, 55.6272, 54.1833, 53.8530, 51.5529, 50.9585,\n",
              "         50.5867, 49.2934, 46.2545, 45.7278, 45.0299, 43.0670, 42.4185, 40.9491,\n",
              "         40.4398, 39.9208, 39.9062, 39.5890], dtype=torch.float64))"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_passage_score_bm25[598]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b093932-377f-4c84-b4c6-99a0255ae439",
      "metadata": {
        "id": "2b093932-377f-4c84-b4c6-99a0255ae439",
        "outputId": "b0ff6235-4419-4ab7-9008-abeb7e488aee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('제2캐나다기갑여단이 상륙한 곳은?',\n",
              " tensor([37116, 24529,  8699, 18919, 55238]),\n",
              " tensor([684.6677, 588.6879, 470.4238, 438.8907, 428.4706], dtype=torch.float64))"
            ]
          },
          "execution_count": 387,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_passage_score_bm25L[598]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65185b5c-8f86-41fd-b6ea-b307365f7c13",
      "metadata": {
        "id": "65185b5c-8f86-41fd-b6ea-b307365f7c13",
        "outputId": "2236d2e6-adf9-4f7c-8c52-ec9aefabf5f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('제2캐나다기갑여단이 상륙한 곳은?',\n",
              " tensor([10960,  2098, 21367, 26402, 51103, 45549, 17820, 17527, 20194, 31214,\n",
              "          3646, 17652, 36330, 28979, 24950, 39127,  1413, 38588, 23120, 14529]),\n",
              " tensor([74.7134, 68.1146, 61.8993, 61.7824, 61.5399, 61.0321, 60.7731, 60.5152,\n",
              "         60.3628, 60.0577, 59.1899, 58.7794, 58.6195, 58.3924, 57.4568, 56.7246,\n",
              "         55.9776, 55.8603, 55.6965, 55.3557], dtype=torch.float64))"
            ]
          },
          "execution_count": 652,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_passage_score_bm25plus[598]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e37ed9d5-81b1-4101-ac2b-abf18635c9ad",
      "metadata": {
        "id": "e37ed9d5-81b1-4101-ac2b-abf18635c9ad"
      },
      "source": [
        "## concatenation sparse and dense passage vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f682cf37-82f8-40d9-ac5f-0be0b41d24e4",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "22e7a831d0d34e078ce7607c09dc0978"
          ]
        },
        "id": "f682cf37-82f8-40d9-ac5f-0be0b41d24e4",
        "outputId": "69ecaa61-6ce4-4fba-e7f8-be9b478825c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22e7a831d0d34e078ce7607c09dc0978",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "k=50\n",
        "\n",
        "query_passage_score = get_relevant_doc_concat(q_encoder,p_embs,sp_matrix,vectorizer,test_query_list,k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b7dd2c-f26b-48d4-8a19-cc896a254776",
      "metadata": {
        "id": "c6b7dd2c-f26b-48d4-8a19-cc896a254776",
        "outputId": "d0e595c1-fb00-44bb-f29c-62b725010425"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('제2캐나다기갑여단이 상륙한 곳은?',\n",
              " tensor([39532, 52694, 39519, 39518, 52695, 52874, 39592, 31628, 39535, 39533,\n",
              "         52693, 52875, 39787, 39521, 39520, 39418, 39550, 39531, 39584, 19145,\n",
              "         17525, 39790, 24709, 40358, 39789, 39514, 45772, 46098, 52877, 36835,\n",
              "         52700, 49810, 39099, 53742, 39809, 52876, 40440, 18507, 37852, 39399,\n",
              "         42259, 33445, 53739,  4473, 33444, 55349, 44417,  7797, 36150, 39587]),\n",
              " tensor([47.9594, 35.6455, 31.6161, 30.3620, 30.2213, 29.9415, 28.3232, 28.2927,\n",
              "         27.8151, 27.2074, 27.0227, 25.9576, 25.8486, 25.2052, 22.6478, 21.7638,\n",
              "         21.0442, 19.7188, 19.4975, 19.0694, 19.0117, 18.8128, 18.5482, 18.4788,\n",
              "         18.4722, 18.2397, 17.9573, 16.5311, 16.2054, 16.1500, 15.9964, 15.7212,\n",
              "         15.5857, 15.5220, 15.4210, 15.1123, 15.0782, 15.0356, 15.0154, 14.8798,\n",
              "         14.8703, 14.6522, 14.4927, 14.2984, 13.9865, 13.9750, 13.9075, 13.8468,\n",
              "         13.8140, 13.6262], dtype=torch.float64))"
            ]
          },
          "execution_count": 230,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_passage_score[598]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0ed3ea-63eb-4adf-acd8-0f787194e8a3",
      "metadata": {
        "id": "2d0ed3ea-63eb-4adf-acd8-0f787194e8a3"
      },
      "outputs": [],
      "source": [
        "def get_relevant_doc_dense_bm25(query_passage_score_bm25,query_passage_score_dense):\n",
        "    \n",
        "    query_passage_score=[]\n",
        "    \n",
        "    for a,b in notebook.tqdm(zip(query_passage_score_bm25,query_passage_score_dense)):\n",
        "        \n",
        "        query = a[0]\n",
        "        \n",
        "        bm25_passage = list(a[1][:15].numpy())\n",
        "        dense_passage = list(b[1][:15].numpy())\n",
        "        \n",
        "        score = []\n",
        "        score = torch.tensor(score)\n",
        "        \n",
        "        bm25_passage.extend(dense_passage)\n",
        "        \n",
        "        bm25_passage = torch.tensor(list(set(bm25_passage)))\n",
        "        \n",
        "        query_passage_score.append((query,bm25_passage,score))\n",
        "        \n",
        "    \n",
        "    return query_passage_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1470bd0a-583d-41ad-b6b8-011dda449e2e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1edddbe928f5412f863156c485892335"
          ]
        },
        "id": "1470bd0a-583d-41ad-b6b8-011dda449e2e",
        "outputId": "0b2d6191-da64-436e-cc93-1115a5188388"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1edddbe928f5412f863156c485892335",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query_passage_score = get_relevant_doc_dense_bm25(query_passage_score_bm25,query_passage_score_bm25plus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7773f4b0-5c6a-4753-9ed4-accc02c15ba0",
      "metadata": {
        "id": "7773f4b0-5c6a-4753-9ed4-accc02c15ba0",
        "outputId": "0784b8e3-f587-4930-bf9f-f0d91c127f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('루이가 사망하게 될 원인은 무엇인가?',\n",
              " tensor([ 4992, 38931, 33947, 54302, 35373, 42677, 39999, 24640, 42049,  9553,\n",
              "         31313, 46294,    88, 11226,  2270, 41696, 10340, 40804, 22767, 52733]),\n",
              " tensor([]))"
            ]
          },
          "execution_count": 705,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_passage_score[300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa259e5-3b09-4574-8ebb-c3360df851dc",
      "metadata": {
        "id": "1aa259e5-3b09-4574-8ebb-c3360df851dc"
      },
      "outputs": [],
      "source": [
        "#save passage embedding\n",
        "\n",
        "with open('query_passage_score_k20_bm25.pkl', 'wb') as f:\n",
        "    pickle.dump(query_passage_score_bm25, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f623c347-29a6-4914-a270-a5aa860c68b0",
      "metadata": {
        "id": "f623c347-29a6-4914-a270-a5aa860c68b0"
      },
      "outputs": [],
      "source": [
        "with open('query_passage_score_k20_bm25.pkl', 'rb') as f:\n",
        "    query_passage_score = pickle.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e667b538-0724-4d82-9891-297f8b93d499",
      "metadata": {
        "id": "e667b538-0724-4d82-9891-297f8b93d499"
      },
      "source": [
        "# final inference by single passage method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11fadb7-69ff-4603-8afb-da5198ec3c21",
      "metadata": {
        "id": "c11fadb7-69ff-4603-8afb-da5198ec3c21"
      },
      "outputs": [],
      "source": [
        "pad_on_right = mrc_tokenizer.padding_side == \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80002ec9-16e7-4a24-8061-aa1de4bffab9",
      "metadata": {
        "id": "80002ec9-16e7-4a24-8061-aa1de4bffab9"
      },
      "outputs": [],
      "source": [
        "k=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf13ca7-dc72-4fe3-a95d-fcdd5dbfe963",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "45220abcf3da47d182439ae305594923",
            "1d6e4adb6f3d45b9a4bb8fae5b6653bb",
            "ae7aaf10cb8f4c8cb40d6eef92c1f56a",
            "968872c9742d4697a5a3fd3411a8d867",
            "944761f1b39141a691bda1f79def26d2",
            "6f9e9a7a7303464d9ea927da05070065",
            "86d4ec137cb54d83b67f1b9733e9ad50",
            "ed706df41f6d439aae2c2ce56123278e",
            "8b912b844b9446459698ec382aec6cd4",
            "e29f5f9ac5c24e2eb73ad2882993661b",
            "6a0d15e3ba594ba5b0686b361c8eb352",
            "247d015bfafe438c8443cc033c2fd7b5",
            "2f23faeca5e8443988529b9cb6090d2d",
            "47d6be98a16040b5ae1fc801fcbbf759",
            "d3a4b828a4b549529605c074348881a7",
            "672d9ddc7b7a476d9acd1c2b5d6b3cb8",
            "702e1d6a7ced4774ac32118c28711b43",
            "14161c50a06744e1af47e0035e9078f6",
            "e6ff5bae8f404055ad5fdc165347108c",
            "d98ade987e1a46a2a1a25cec6cfe2e9a",
            "870a5657c86d42c0b9333bc9edd66946",
            "318bc0807fc1464d9ef556d0aa9259af",
            "39d06e7903e0447e811982dc1a0e24a5",
            "abb89df3355a48d782406114bd6c644a",
            "219c6bc1a3a848ec937cc00791396bbf",
            "40419b4641524edc971cca799157c42d",
            "24feda2c65b54a7b90c356c9d49ce0ce",
            "2d8114e26b9f433c93b175576254a8ad",
            "32e8b103119045e8a4f04c4d49c625a3",
            "d15eb2455ef9425f90c88efb6aebb51a",
            "ed943a8f450e4ba4bb350446e1a8da51",
            "bca2ca6315994ffdae956ad79fa9a2d3",
            "171a1888bdad4123ab657c1a0e9971e1",
            "7cbf8a8110554c978a08a4ac70ed0412",
            "ef31c42750fe445e866d76c4719b115b",
            "fea950911ec9466d813151490e08c294",
            "73a97aa7d4d9401ca0a709a41e51a4a1",
            "72092cdd28ea49d4896cba653b3114c0",
            "8c853f96894846a6aa3e8e60d2b46e23",
            "ee1ab009747b4849a885d2261af719a8",
            "7d5732306f554a789bcef8c99b678762",
            "324913b2069d4ddf836da249c13bf652",
            "7b39a1659a724be88f8784be63746c6d",
            "8240462ab68147199a493433e63b427a",
            "e30098cf051b4c13a1e545da60fe0547",
            "301caf420b7046fba3a1599ed703f4d1",
            "0c99491b896543aeac5bbf5e94a7f00e",
            "5dd8e7b583bc4307bb8de7c7c5057864",
            "16dfea7e79ae456f95a3f71b76317664",
            "5c00e9eca92e4ff39ada980adf70512e",
            "22539366313c4e74927772c6279f8add",
            "5f9d1eb9828b4061947479b64b8e5d21",
            "5e515391774848a38730f9f8f2b191e0",
            "9234d8cee15f4641adf46fb9f4a2bdd5",
            "a9ab04cdedbf477e8d048bcf74acd933",
            "86207d28501d4d2aadcc3d664c467113",
            "0afe4e3cfe8843ba8d1db4b3b434fe90",
            "aed72a5181e64289a26b1e7eba93c39a",
            "89e4987160574f729892e379efb76427",
            "f3c9f4ad727f419bbedc0b963e363e33",
            "b8b19032ed354e3ba09985b3b9763ec1",
            "5a940c2e8989436088caf068861cc84c",
            "95f4a20208e54e33a5222e12760bed66",
            "37f5418f8ca745988648b08d7d6652a4",
            "33abd141635e4782907b766147786c67",
            "42a91256b49e467f80d5d47a034af599",
            "ee8d04c495e0426bb4e9f1ea5198bff6",
            "5061a29fc4684b7497659f3c51f3c34f",
            "dbbcdb9c9a544f5eb52c05dccf0fdf36",
            "4e6fd659c4bd49e3a4e6720b1176bac7",
            "8038125f2f9d46fda6bb921a5746d04e",
            "0762e79b202140c2af798485d34d44a8",
            "670a912b9eca46db9f28246ee104b3cc",
            "29a133d98d9f46aaa48e7c816936849f",
            "dfb92880284146d68a11b84fbcbab266",
            "4812692e5d0c48a6a20a1f5587de261f",
            "855dea92bb134016882e25db4d39bd9d",
            "a0317cd37f614d698a07828535a423d4",
            "15f74b7a5a26471f94997574ee60b85e",
            "fb1aae598379407ba55860296ba4ebad",
            "2acc9143399543c08b1ad9ebaf300abb",
            "95631d2bc4e541e79f883e7383187eef",
            "57806a1e3867470992f8477ccccc1e33",
            "0f83a7cddf414c869f61d3fefb04c1cc",
            "de394d48960940e1a7ba1d9339b3f641",
            "fbe305a2fc2848669444030f451193e4",
            "e3947ae84b6541da8a1a606e4e59ef8a",
            "f437fc96031b40f38db4bdad04b6698d",
            "5a5f9cf941a74bc6b86b001477e3b4a8",
            "4e4d02de1d414d3997ff91040882395e",
            "7ff3c22457cf467b8a79880e2b0f1f66",
            "4a700ddb99db47ceabad6a717df3d920",
            "5fe681a6013f4ff4a84dfb3ce1d66f91",
            "efa64e5447ac4db1a9d8993dbea3f32e",
            "074936da159d4182b945ca57b53d1d6e",
            "db1392f65edc4a8e98ef06fdc3b9d1d1",
            "bd5f2e764d434005b8231c5b01306a99",
            "114221e53b96498586e0587cc8dfd8b1",
            "5eb24e0f70474cafb82296cda5e9630c",
            "f2df75279c3f4912abd9d4a0c8470cf5",
            "d4a3ef4c1bd94fd586278d82d9e0ae17",
            "f6a477abad844da3846f0222e5601997",
            "01e4b39c2268428a9cff6ab382d376c2",
            "16c978f7bc3f4452b110192ce5f6dcfe",
            "f9210fbcc8b64434b0567024d3fbae1a",
            "563950b3f1bf4d88a23a80dbb641cd76",
            "3d4ea78281164124aac0730ce5c1abb3",
            "f13757f663e34634a9bdf2e09eaeb1ea",
            "32970e3fad484893aaefa44f6d4d5d20",
            "af018359b20e492ca83848d05177d6e1",
            "f796bed1bc684848935fb9677a599dec",
            "29dc5bc692ad4157b4314442ee004398",
            "e96ed73182044ab0ab36e27963086358",
            "db982d23f80b401cbc5e42ad86a46e80",
            "7b37299b5b7645f794673759d23b8f01",
            "ecc3ea7b5a9c41b0b5cc896ab10b2b1e",
            "22853535c3a9499da1791ff88fd9673a",
            "410a8cac85a94f0591d44e66b81522c7",
            "d52ebd74e33744baa08be567e36bb71d",
            "a0734a1e19cd4d96bbd900c431e2c92f",
            "61ae0586a15c46ffb4c1135f2cda5f8e",
            "b1a1c7ea46b34cf3920ca07227bdd120",
            "852dba229a1f4ece9377e250777aba30",
            "d5e7e655ffbc4b98b676e9cd087a64dd",
            "f0998f0b205c4397b9618c7e6935ad46",
            "c39df7e5463e4d51b51f6342ded81826",
            "3689f175a8f447fa909fee1a56dd990f",
            "f7850b69053d4513b24ea2cc2c5ade51",
            "ea29a3c28cc24986b192c38cd8db80e6",
            "455ea552ad804067acd7be158a8ced6c",
            "2a3e8aa4e2604597be17bb1a968dbefb",
            "678b096f5d4b47e5bc137a2620ed8d8a",
            "2eacce01ab674b899aeba841494b18cc",
            "becbe2e062fc4be1876db3556c88d561",
            "12882430178447e0b78d17bd3b71b84a",
            "56800e2ee9f94ec7bbf4161e79a08a7e",
            "fa8b7c5fd0da4a8cb7c647d81e40015c",
            "f3c3e83adfea4ad3929932ddecf1479b",
            "812386cbd2c84411a41f20b67e135e24",
            "4341dc63c782409c84f2e0f09a327705",
            "8b94e1b351574153b19fe52a0a9dd90d",
            "c14c257db0e1483cadc733adf2758506",
            "e7febf18129d4eb1b39c3742cd56091c",
            "b120d52defbf4282addb7631e71f2090",
            "4cb72e93c3a746a58b7f6df645fc1290",
            "655ebd2648f749acb39215959c8bce7e",
            "a836ae1926894cb0920fcd4eb371440f",
            "9316cf3253e84e2391f4293ddc19361e",
            "f66a5cea6e034e3280461a2c4d5ce895",
            "aef50d392ec04e6c8fe14be0a5827953",
            "c478f9f40df6419eb56202d228c52b3f",
            "1d36e93188104ad0bddea95ec5639293",
            "d9f1a0e8f78a42fd8dfdacbaf9169c93",
            "f02edeb2b2cb49278686173d598c2158",
            "643b512ae6e24abb8e48083aa12ed686",
            "a5dc568c82fb4bc6b27cd27765259bcb",
            "e6a3ef72db4d4570b5e2138569d5d8b5",
            "9ea49d285c354b66ad0de4ac4f64aa7e",
            "a960a9e4336542b0b0323a30ad094e36",
            "312c8697d43c4e3b903eb345fca8723f",
            "e3718fb38719433da07c900cfaab4576",
            "7dd65b2f17334c95898606c278b0aa47",
            "ebfb841c42154c0abcf5ceaf5c9383d7",
            "542caef2271847388b82daecfca85279",
            "fee29380acda413eb50489a90cf07300",
            "ebbd5eca37574822a95695d6702bff40",
            "857553dae93747b4a2cda78b36665e59",
            "86bf0a08cf0b4f2296a4bd43d4ebff27",
            "eaf07c423fbd43b59f510a659909fa42",
            "42f434322a9f4ab0b3ce1440f3440540",
            "5fea7abdc89a4d2fbfbc13038c4a97e5",
            "481a18d169b34c9da726c3548668b1f3",
            "277261ac51df41019c1c15476ac7073d",
            "08eaea4e70d746ae963caa85efe723ad",
            "22b239070aec4213b445254bb3523d51",
            "506b7e5682204dc48a483515354bf5a3",
            "2ef0c73557a143639742f12902e4e533",
            "8b036121001a4420a2237c2232a3a83c",
            "76fd4d150f4a4e16982e2fe442a88ccb",
            "0821c099254d4b54937b799aa0c041c1",
            "a413f567f5cc476ab11e536027840f18",
            "64d17b04024948bc98ae9eeaf892282c",
            "89cdff647ae342c4b2a96817644d02ea",
            "c7325cd4c7424e3595d66078fa7a6cb2",
            "08ffa17cf29a4821bf822f2940f652f5",
            "dc520fa345d349fe963e71f8bd2f349b",
            "59c785248e524382b4c2011024668677",
            "1f905fc604424353b8f935655c13f94c",
            "7ed580b88bdb406c9dbb60849b9eddcd",
            "1986bff7482540e28db6f39542fcc27c",
            "21a9e5e3339f472cba8e0707578d9d69",
            "1fc20e68e4b84c0d8003e734ae735cb9",
            "a979df99fa87416a8a1c3e4f3a88fe38",
            "2d9db24ffdaa43d6be66051afe213a77",
            "655c9f60c1d14544be7c397530b4aec5",
            "033f368334c84556ba43d8be71096075",
            "8a0648f52959491e86dfb2e808cc3307",
            "6f27c675f4054187b497d517478792b7",
            "72789893d2b54cc283c16e4340894107",
            "26245ecee8a14319baf8c6228e9c74cb"
          ]
        },
        "collapsed": true,
        "id": "daf13ca7-dc72-4fe3-a95d-fcdd5dbfe963",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b0255eb8-18c7-4683-cfcb-b880210f2583",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prediction_dict = final_inference(k,clean_context_list,query_passage_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c5cd5f76-22cf-4614-9312-f220da759351",
      "metadata": {
        "id": "c5cd5f76-22cf-4614-9312-f220da759351"
      },
      "source": [
        "# final ensemble inference by single passage method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c83d1def-ccae-405c-8bb6-fd4bed62f8ef",
      "metadata": {
        "id": "c83d1def-ccae-405c-8bb6-fd4bed62f8ef"
      },
      "outputs": [],
      "source": [
        "pad_on_right = mrc_tokenizer.padding_side == \"right\"\n",
        "\n",
        "k=50\n",
        "\n",
        "mrc_model1 = torch.load('mrc_model_koelectra_base_v3_discrim_full_aihub.pth').cuda()\n",
        "\n",
        "mrc_model2 = torch.load('mrc_model_koelectra_base_v3_discrim_korquad_aihub_1epoch_retrain.pth').cuda()\n",
        "\n",
        "mrc_model3 = torch.load('mrc_model_koelectra_base_v3_discrim_concat_retrain.pth').cuda()\n",
        "\n",
        "mrc_model4 = torch.load('mrc_model_koelectra_base_v3_discrim_full_concat.pth').cuda()\n",
        "\n",
        "mrc_model5 = torch.load('mrc_model_koelectra_base_v3_discrim_korquad_retrain.pth').cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230eecec-2b67-48bd-9102-5602025e4858",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3034992c8364460b9ef43a0ea92bac8c",
            "9aa02cf1a6294d9b87d378f611193969",
            "66097ae9b14a4f0f87e789bb22ed5b70",
            "256822905ebd436e96fe4b7233702612",
            "e77006a6cb764913b37282a9859887cd",
            "0c450188186144ef9fe43c183f87e2e4",
            "2b24c8da18ed4bccada41797bb0872e4",
            "1fed35fe2ef544a3b8ae910aac289cfd",
            "5143ee852a1e436b80a207ef77c13911",
            "1c51c9f57e2b439ab72b13f489119f3b",
            "2ba2648e22024591881638b2441ba5ac",
            "e56d82906be447c08b9c11878dc5c278",
            "60951353b4134087b23754bffa6bfccb",
            "95c996a6629347e8a53e41bb7d47ce85",
            "4a50a55766924af5bec2617acd6c65fb",
            "c50cf5ec67be43d888a8be21b26171cb",
            "2a5efeed836f4cbdb8801d117ee431ca",
            "c480d19cc64c49ffb335b03cd742370b",
            "5380343f0788417387035773389227cd",
            "61753db9742945ecbc13acc564d05020",
            "49e4a119c8c34db0ab7371fbe6518a34",
            "ea158fd982dd44f2bd09285d7a68b735",
            "3f56641bc05b4a47a13ef6598623e2a3",
            "ccf26231e2b24c639038a784e9e67f52",
            "03e1720c3b7c4712acafd8821d727390",
            "8f3cdf97ad5b464d8063535c105b0661",
            "d7aa16920812463eab546e211a501c80",
            "e25a8a2ac7e944b99ead21ce0494db60",
            "8842609917b045678a32d408bc4f903f",
            "f57193f01a684a7bb1612b08dd066d49",
            "08f05def3b61420d9755f042af1e3f13",
            "b08dddae85094f34a06e62341942c499",
            "f4c576ae6f2e488a8bd1f21f77b0760f",
            "e807d1ff9e604b8aa0e2e611d5e76d5b",
            "b17ea010ce404249aa2559c541a2ad95",
            "ff656bec5dce49508825a8899fccb248",
            "c969b228ef2c42729bc94d39b5753fa0",
            "4762f626ac52417d91a4a83421358abd",
            "18357ba59c2c4cd79001fcad4c3d8cfa",
            "ce4e633de9484e5e96a9e0a0bdab852c",
            "fae66d7ecafa4d8082a7c17b6570d7d3",
            "5c386b7326fd4205a214318df4f1ecf0",
            "cedbc74d1cd44b2989d2613b50602dc8",
            "fd20d9fae60045299d6163095a1c009e",
            "77043eca5caa4ae5afa735cc8ee4054c",
            "516ead137efb413cb93de3ae9e6d317e",
            "427c58f70ab740b5b94dad61b2e0b6ca",
            "ff867ee9ce5a484d9c9da6edf72b5b12",
            "0fa25bf05af847bfb118f9e3e02166b4",
            "8919c777c28b495a8e5ba339dfbadc6b",
            "30dfdcb6ddaf479da13c1493c300211a",
            "34b246f2d1664c0694d06cf8afcd2603",
            "e3e013fe3ae0433caaa035660652e61b",
            "7721d1823589498db0e6b9bcc0a0891e",
            "03dbff5534dd46428a966b81551c9737",
            "6141b5f8227448508face3e583a4ae15",
            "d4b7fccd5d53467c9196879accbb09f1",
            "4298e0f9dcb34e3aa2cdcd9041f6aaa3",
            "adaf8850e3ca40b8b78b91604c9123d5",
            "14cf5f76f8944e0ca5dc552fb864fc12",
            "69e572e19c4941b18b5dabf31121a5c9",
            "cafb1e4ea37e495081bc0fc220fde8d7",
            "f24a7a6505e54208b556e58d35bf8c04",
            "ffecf4f00b7c4f04bbaab6b627ef7c72",
            "cc64d33861fa4a41a57a27a47d5b4c50",
            "cd52853fba2543ec80942317b475718f",
            "71fa7ff3cc6141e7a2d6d2c22433aa13",
            "5a67bcfbbe424c42912fd918b5ff416b",
            "2fee69d357e74213997b0c801034b06a",
            "ddbd29253b1f41c8a6b4f9e5e31cb960",
            "adfb29e1c76745c98b8fff531c3d9c09",
            "c9fb78dc32cf4c8c8576f9821ecd203c",
            "5ab8a496affd4acdacc38a8808c9f331",
            "3c460194cc08493ebb1730b53561f796",
            "34873183f5594ecb9cd3cf9614b7a6f5",
            "054d9c671d544d9a94bef75523a36e79",
            "5271500ec60f4f31832d8f1328996f66",
            "f01f9882011f43638975aa243e95fc24",
            "4a395d5f8b264eeaa3c334808d759af5",
            "fbf580b098b4432d907e1a7d9fd69391",
            "ecb02acd7ce541d7be3a5d6533cf8d43",
            "b32a7008ca874028864009f389ae3bf3",
            "6bf6d7b15f974566aa420e83c066e381",
            "5efcbc8c97b642febc5d1c02e8a173e6",
            "e2db0b441458481ca4bdd8c84d374e51",
            "15af70aeb81b49109dbd604d06e76b61",
            "9f9fc4f3fe854e64bcb9a2b30f092dce",
            "21e12e0fe9d746f1a8bdaa17fc0e2f19",
            "b8e13d0070164b07a5ca9273683111c0",
            "bddc38419a0f43979ce3826061fa0a92",
            "3806f0d073f5434faf93d6193bfc3ad6",
            "fd9ca762b8004e4fb014ff60ebc82eda",
            "b59ab83e6306437480ea3ebefb058b96",
            "fd9208c5bea1482ba87c5f5829aa0eb3",
            "1f3918e1c3894ad2bc8ed0bc7d8b0e93",
            "f70e6cea165c42c58578985191f84c63",
            "38c861757c39406988d3bad457feb208",
            "c85f64544e044b259759040228a27956",
            "2f655d073d3c4f5f92ef794af1b03654",
            "c485f56828de49c4b2e871233b07dcf6",
            "ae8c21fb6b3344a98f344a4d2413eeea",
            "0089c2b0eadf402a8a5a12c68a21a52b",
            "85ed8b5c8fa64160aa49c0878a0278b5",
            "119414875d974a6a8516d770b20fcc0f",
            "558cedb7e6294aa4a0c5ea13e29e8142",
            "ec4b73262cc346c9bbf87cec46780834",
            "e63b313dabac4d4d96dc223500cf9af0",
            "5bf0e67a869941ab97cbc578c66030f6",
            "5e570f3615554b2fbd88c89060014ca3",
            "1d3a712fa1e24c05a26bdeb2532ef922",
            "79414defc31c4e1ca33777f602592bfd",
            "2e533345b09c4847a586380b939e74a6",
            "905328964c1942c5a60cd5d368d16827",
            "dc9878d2194e436784af13637894c18c",
            "7638066a87a344a483f22a4f8006c55a",
            "732f317ecf8c4c6b8efdbfb00a0152e2",
            "e261c887aae64061bc77bd60d36019e6",
            "09d1f5b754d04a878c1b46e4b2592cfe",
            "db68b7b78dbd4c129beeccc5ed5cc263",
            "b44c750af27e4176970b5f50a3677798",
            "ab84b8c03af44851b57bb08a55539cc9",
            "b3ab4058d8fc4483b245bf59e8980971",
            "0bfe2bcf64394b8991507064db17d6df",
            "fdd6f3538aaf47d7bf10aaa16d01227b",
            "cdf5b74775274722bc0923b84f1a97c9",
            "869e971fd9344dfe9f2aa49a54b16a01",
            "8a378a27582a4e27ab0e135232b418da",
            "1d823547a8b641eda9792918b44af0ce",
            "076bd4d465824042b682bef1a6439737",
            "ba74487258114772b970002315bc0ad5",
            "bfe0b80d2e6445a3bddd00d3cf440445",
            "95b43f202c304ad48d5a4f592abe3813",
            "4e8074b866074eaba45f2346cd4b5277",
            "5eae4d8d3f8b4b02bab87e55b1fba927",
            "0c599219c433444097c2d347e6a2038d",
            "e1af98c6d7cd41a383dea434256f3c47",
            "a94731e04e834735a538ad51e27d0f47",
            "b5f5d9168f6e4b5bbd6a3da9d7cea62d",
            "e29c22791c184778a41a82eed68a481d",
            "24186817dd004238a072dbb708e8634b",
            "4ae92e969a644033b337388ff91c137b",
            "80d6929f47774372b4a1d6cff365443e",
            "23eaeeb62fef42c696d59e597947ee16",
            "e36d73c24292467994d4bd61e7edfa67",
            "b9de9a33d14a4b0bb9ad9cf881bc3421",
            "bff3604808274660b753234e78d001d9",
            "18e2b6365a3c435782ead69344b7132b",
            "9bc5c7fa79884ae3a3db189839649979",
            "b6a1a7eba53345d2a25466b338258cf2",
            "661059fbb8c04b0fbff888ceef64e6e7",
            "d92f13378d6a44808c4426d02d564ca6",
            "be4a5104dfba483c952fd110a255e6c0",
            "0c67e18ff05242389e5e1fa51ef608b3",
            "4a1c141bf2724e3395fc2b0f43ed687e",
            "542dd681044249cdacea1e53c8eecbe3",
            "8368cdcfae8248bdb0013eb78d45ffdb",
            "6cea7b0e38624bd597c6c4f8c7914cfc",
            "799176fa114b4540ad8036e35db67685",
            "1cd528b270824a6582866d7b00bff2f4",
            "103d9ed7aaef49b08b3b80785d5328f5",
            "0c79a5c453344c819d574a2b1775ec41",
            "debbc2837b904645923eb0da57345b23",
            "b14bb5c40735401a8a0b24ac6ff629b9",
            "3121e58a765b42ad83480bdf99214599",
            "d52cfe4df65f4656a123b686b927aafe",
            "92ca9f077cc543c1adfcf9d05033183a",
            "68e7d16ac244443b8d7e72aeea14f31f",
            "e623d9f5186f4d9594df42c0fcb3175c",
            "2c0b0c2c2e42418d883e2441a8d2c48e",
            "c1bf50aa6e914bdb8878befff47b6270",
            "ce7145442f84471a86a7168a742d9a5e",
            "f03d64c8992f450eb164cac866db1eff",
            "ad18aee8158f45939a08889f027aaab4",
            "32d6b855f6c340f4b4617a951bf8b547",
            "30fc438677834c4391487fc96e5e7b3c",
            "0f24a2ff607a4e0a92909576d195d1c0",
            "a47694e712224f37aadc25a659b93681",
            "31a585ddbac5405fadc29a2fb6b9812e",
            "13343768a6384e2a955efae5291da507",
            "141a5be618994cd5bfe4ad4ade7fe4a5",
            "795b4c72101d49408a867fc52f0d5dbf",
            "6c76b63e976a4199949230a0ca47f9b8",
            "5488f00c048f4655a2d336e536c3fd60",
            "7f80f4b62f654e36ae71a7e710ac6aa0",
            "d80ff8c03df4498ab876ed38188f0ab2",
            "77626b22888d4b36ba9efd3643060a69",
            "9e66f9a40da2407ca86c19949d3e5f96",
            "34f29e8dc0304cc7a949c12fdc7e8a62",
            "ca79cd98842a4d82a2de590986211022",
            "740aec857f844ffdb77bf827c25c54fa",
            "c21d4cd8d7dd4767b26c81c3cb9a60ef",
            "a55c9fa7cc5d43b29b79efc4a0ce0e0c",
            "f60d4379ef2b45c2acb697e5a434bb65",
            "9305e48d750141b0b022b7440a04753a",
            "8795c4c6f3874bc0b141ef708ec439c9",
            "b98a9e6bf954428395fa989b23f2a13a",
            "ae05893dc6f14577a046ee42387d3832",
            "7c44c30ec4324c36b3c59ba0ce8200ba",
            "efd1b514488c4c1c8b2f11b00dfd77d0",
            "9663762f4a454eac8127580f2901b14f"
          ]
        },
        "collapsed": true,
        "id": "230eecec-2b67-48bd-9102-5602025e4858",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "abb0842b-f3c7-45cd-dd7c-0fc1b8bccb47",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prediction_dict = final_inference_ensemble_five(k,clean_context_list,query_passage_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9590d5ee-ef04-42d0-9109-ad5eecff2439",
      "metadata": {
        "id": "9590d5ee-ef04-42d0-9109-ad5eecff2439"
      },
      "source": [
        "# final prediction using multiple passage method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d39e9c5-1655-4e23-90ff-b004c33a4c98",
      "metadata": {
        "id": "8d39e9c5-1655-4e23-90ff-b004c33a4c98"
      },
      "outputs": [],
      "source": [
        "k=20\n",
        "\n",
        "query_passage_score = query_passage_score_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5827df5d-d141-462c-b60e-b8fd6bc6d442",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9d5b6aae08d4410a835db616c57befd7",
            "8b56cbade7c34ab487e91c12ca1dae41",
            "b5188237d14e489381caa41b7e6b39b2",
            "e60e776655cd4efca1081ee37af8d237"
          ]
        },
        "id": "5827df5d-d141-462c-b60e-b8fd6bc6d442",
        "outputId": "4a2830f6-7253-4064-e0cd-6edf2bea8fa8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d5b6aae08d4410a835db616c57befd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b56cbade7c34ab487e91c12ca1dae41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5188237d14e489381caa41b7e6b39b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=27387.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e60e776655cd4efca1081ee37af8d237",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "pad_on_right = mrc_tokenizer.padding_side == \"right\"\n",
        "\n",
        "mrc_model = torch.load('mrc_model_koelectra_base_v3_discrim_aihub_korquad_noclean_retrain.pth').cuda()\n",
        "\n",
        "prediction_dict = final_inference_multiple(clean_context_list,query_passage_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b5d97d14-b064-4b54-abc9-7257cba6b945",
      "metadata": {
        "id": "b5d97d14-b064-4b54-abc9-7257cba6b945"
      },
      "source": [
        "# final ensemble prediction using multiple passage method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619de5d3-7475-4cb7-a5e6-6df080d75d66",
      "metadata": {
        "id": "619de5d3-7475-4cb7-a5e6-6df080d75d66"
      },
      "outputs": [],
      "source": [
        "pad_on_right = mrc_tokenizer.padding_side == \"right\"\n",
        "\n",
        "mrc_model1 = torch.load('mrc_model_koelectra_base_v3_discrim_full_aihub.pth').cuda()\n",
        "\n",
        "mrc_model2 = torch.load('mrc_model_koelectra_base_v3_discrim_korquad_aihub_1epoch_retrain.pth').cuda()\n",
        "\n",
        "mrc_model3 = torch.load('mrc_model_koelectra_base_v3_discrim_aihub_korquad_noclean_retrain.pth').cuda()\n",
        "\n",
        "mrc_model4 = torch.load('mrc_model_koelectra_base_v3_discrim_korquad_retrain.pth').cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f71f717-08e3-4e2a-befa-fe0e7cfa74ac",
      "metadata": {
        "id": "7f71f717-08e3-4e2a-befa-fe0e7cfa74ac"
      },
      "outputs": [],
      "source": [
        "k=5\n",
        "\n",
        "query_passage_score = query_passage_score_bm25plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391c8fe4-7ed7-4624-84c5-1824ec9af58d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "65b34f76765d431ca22c707001d85adc",
            "3532bb9d9a254524aead72056475cc91",
            "1f4633c4fdec4a24b0695b2abef7602b",
            "6391c77b28d945d294f975230f99497c"
          ]
        },
        "id": "391c8fe4-7ed7-4624-84c5-1824ec9af58d",
        "outputId": "6f571f22-9cdb-40cd-ba8a-b1f335121b1c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65b34f76765d431ca22c707001d85adc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3532bb9d9a254524aead72056475cc91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4633c4fdec4a24b0695b2abef7602b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5828.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6391c77b28d945d294f975230f99497c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_dict = final_inference_ensemble_five_multiple(clean_context_list,query_passage_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f078e3dc-8746-42f6-b6d2-ccd4324f38e3",
      "metadata": {
        "id": "f078e3dc-8746-42f6-b6d2-ccd4324f38e3"
      },
      "source": [
        "# submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41dcd768-aa5e-4a87-ae7b-6d1cb3b48da3",
      "metadata": {
        "id": "41dcd768-aa5e-4a87-ae7b-6d1cb3b48da3"
      },
      "outputs": [],
      "source": [
        "#remove score\n",
        "\n",
        "final_dict = {}\n",
        "\n",
        "for key,value in prediction_dict.items():\n",
        "    \n",
        "    final_dict[key] = value[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58126fb2-44f1-4cc0-bc36-16cedbc242aa",
      "metadata": {
        "id": "58126fb2-44f1-4cc0-bc36-16cedbc242aa",
        "outputId": "74550a8e-ae47-4932-ad76-5148774ff1e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:01.939667, resuming normal operation.\n"
          ]
        }
      ],
      "source": [
        "with open('prediction.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(final_dict, make_file, indent=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364e8fd1-8126-4e3b-ba31-bff6611f41be",
      "metadata": {
        "id": "364e8fd1-8126-4e3b-ba31-bff6611f41be"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mybaseline_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
